[
  {
    "name": "AbstractRNNCell",
    "base": "Layer",
    "docstring": "Abstract object representing an RNN cell.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  This is the base class for implementing RNN cells with custom behavior.\n\n  Every `RNNCell` must have the properties below and implement `call` with\n  the signature `(output, next_state) = call(input, state)`.\n\n  Examples:\n\n  ```python\n    class MinimalRNNCell(AbstractRNNCell):\n\n      def __init__(self, units, **kwargs):\n        self.units = units\n        super(MinimalRNNCell, self).__init__(**kwargs)\n\n      @property\n      def state_size(self):\n        return self.units\n\n      def build(self, input_shape):\n        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                      initializer='uniform',\n                                      name='kernel')\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units),\n            initializer='uniform',\n            name='recurrent_kernel')\n        self.built = True\n\n      def call(self, inputs, states):\n        prev_output = states[0]\n        h = backend.dot(inputs, self.kernel)\n        output = h + backend.dot(prev_output, self.recurrent_kernel)\n        return output, output\n  ```\n\n  This definition of cell differs from the definition used in the literature.\n  In the literature, 'cell' refers to an object with a single scalar output.\n  This definition refers to a horizontal array of such units.\n\n  An RNN cell, in the most abstract setting, is anything that has\n  a state and performs some operation that takes a matrix of inputs.\n  This operation results in an output matrix with `self.output_size` columns.\n  If `self.state_size` is an integer, this operation also results in a new\n  state matrix with `self.state_size` columns.  If `self.state_size` is a\n  (possibly nested tuple of) TensorShape object(s), then it should return a\n  matching structure of Tensors having shape `[batch_size].concatenate(s)`\n  for each `s` in `self.batch_size`.\n  ",
    "arguments": null,
    "abstract": true,
    "outputs": [],
    "inputs": null,
    "file": "keras/layers/recurrent.py",
    "aliases": []
  },
  {
    "name": "Activation",
    "base": "Layer",
    "docstring": "Applies an activation function to an output.\n\n  Args:\n    activation: Activation function, such as `tf.nn.relu`, or string name of\n      built-in activation function, such as \"relu\".\n\n  Usage:\n\n  >>> layer = tf.keras.layers.Activation('relu')\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [0.0, 0.0, 0.0, 2.0]\n  >>> layer = tf.keras.layers.Activation(tf.nn.relu)\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [0.0, 0.0, 0.0, 2.0]\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the batch axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as input.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "activation",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "ActivityRegularization",
    "base": "Layer",
    "docstring": "Layer that applies an update to the cost function based input activity.\n\n  Args:\n    l1: L1 regularization factor (positive float).\n    l2: L2 regularization factor (positive float).\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as input.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "l1",
        "default": 0.0
      },
      {
        "name": "l2",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "Add",
    "base": "_Merge",
    "docstring": "Layer that adds a list of inputs.\n\n  It takes as input a list of tensors,\n  all of the same shape, and returns\n  a single tensor (also of the same shape).\n\n  Examples:\n\n  >>> input_shape = (2, 3, 4)\n  >>> x1 = tf.random.normal(input_shape)\n  >>> x2 = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Add()([x1, x2])\n  >>> print(y.shape)\n  (2, 3, 4)\n\n  Used in a functional model:\n\n  >>> input1 = tf.keras.layers.Input(shape=(16,))\n  >>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1)\n  >>> input2 = tf.keras.layers.Input(shape=(32,))\n  >>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2)\n  >>> # equivalent to `added = tf.keras.layers.add([x1, x2])`\n  >>> added = tf.keras.layers.Add()([x1, x2])\n  >>> out = tf.keras.layers.Dense(4)(added)\n  >>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "AdditiveAttention",
    "base": "BaseDenseAttention",
    "docstring": "Additive attention layer, a.k.a. Bahdanau-style attention.\n\n  Inputs are `query` tensor of shape `[batch_size, Tq, dim]`, `value` tensor of\n  shape `[batch_size, Tv, dim]` and `key` tensor of shape\n  `[batch_size, Tv, dim]`. The calculation follows the steps:\n\n  1. Reshape `query` and `key` into shapes `[batch_size, Tq, 1, dim]`\n     and `[batch_size, 1, Tv, dim]` respectively.\n  2. Calculate scores with shape `[batch_size, Tq, Tv]` as a non-linear\n     sum: `scores = tf.reduce_sum(tf.tanh(query + key), axis=-1)`\n  3. Use scores to calculate a distribution with shape\n     `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.\n  4. Use `distribution` to create a linear combination of `value` with\n     shape `[batch_size, Tq, dim]`:\n     `return tf.matmul(distribution, value)`.\n\n  Args:\n    use_scale: If `True`, will create a variable to scale the attention scores.\n    causal: Boolean. Set to `True` for decoder self-attention. Adds a mask such\n      that position `i` cannot attend to positions `j > i`. This prevents the\n      flow of information from the future towards the past.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n      attention scores.\n\n  Call Args:\n\n    inputs: List of the following tensors:\n      * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n      * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n      * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n        given, will use `value` for both `key` and `value`, which is the\n        most common case.\n    mask: List of the following tensors:\n      * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n        If given, the output will be zero at the positions where\n        `mask==False`.\n      * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n        If given, will apply the mask such that values at positions where\n        `mask==False` do not contribute to the result.\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (no dropout).\n    return_attention_scores: bool, it `True`, returns the attention scores\n      (after masking and softmax) as an additional output argument.\n\n  Output:\n\n    Attention outputs of shape `[batch_size, Tq, dim]`.\n    [Optional] Attention scores after masking and softmax with shape\n      `[batch_size, Tq, Tv]`.\n\n  The meaning of `query`, `value` and `key` depend on the application. In the\n  case of text similarity, for example, `query` is the sequence embeddings of\n  the first piece of text and `value` is the sequence embeddings of the second\n  piece of text. `key` is usually the same tensor as `value`.\n\n  Here is a code example for using `AdditiveAttention` in a CNN+Attention\n  network:\n\n  ```python\n  # Variable-length int sequences.\n  query_input = tf.keras.Input(shape=(None,), dtype='int32')\n  value_input = tf.keras.Input(shape=(None,), dtype='int32')\n\n  # Embedding lookup.\n  token_embedding = tf.keras.layers.Embedding(max_tokens, dimension)\n  # Query embeddings of shape [batch_size, Tq, dimension].\n  query_embeddings = token_embedding(query_input)\n  # Value embeddings of shape [batch_size, Tv, dimension].\n  value_embeddings = token_embedding(value_input)\n\n  # CNN layer.\n  cnn_layer = tf.keras.layers.Conv1D(\n      filters=100,\n      kernel_size=4,\n      # Use 'same' padding so outputs have the same shape as inputs.\n      padding='same')\n  # Query encoding of shape [batch_size, Tq, filters].\n  query_seq_encoding = cnn_layer(query_embeddings)\n  # Value encoding of shape [batch_size, Tv, filters].\n  value_seq_encoding = cnn_layer(value_embeddings)\n\n  # Query-value attention of shape [batch_size, Tq, filters].\n  query_value_attention_seq = tf.keras.layers.AdditiveAttention()(\n      [query_seq_encoding, value_seq_encoding])\n\n  # Reduce over the sequence axis to produce encodings of shape\n  # [batch_size, filters].\n  query_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n      query_seq_encoding)\n  query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n      query_value_attention_seq)\n\n  # Concatenate query and document encodings to produce a DNN input layer.\n  input_layer = tf.keras.layers.Concatenate()(\n      [query_encoding, query_value_attention])\n\n  # Add DNN layers, and create Model.\n  # ...\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "use_scale",
        "default": "True",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "return_attention_scores",
        "default": "False",
        "type": "boolean"
      }
    ],
    "file": "keras/layers/dense_attention.py",
    "aliases": []
  },
  {
    "name": "AlphaDropout",
    "base": "Layer",
    "docstring": "Applies Alpha Dropout to the input.\n\n  Alpha Dropout is a `Dropout` that keeps mean and variance of inputs\n  to their original values, in order to ensure the self-normalizing property\n  even after this dropout.\n  Alpha Dropout fits well to Scaled Exponential Linear Units\n  by randomly setting activations to the negative saturation value.\n\n  Args:\n    rate: float, drop probability (as with `Dropout`).\n      The multiplicative noise will have\n      standard deviation `sqrt(rate / (1 - rate))`.\n    seed: A Python integer to use as random seed.\n\n  Call arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as input.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      },
      {
        "name": "noise_shape",
        "default": "None"
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/noise.py",
    "aliases": []
  },
  {
    "name": "Attention",
    "base": "BaseDenseAttention",
    "docstring": "Dot-product attention layer, a.k.a. Luong-style attention.\n\n  Inputs are `query` tensor of shape `[batch_size, Tq, dim]`, `value` tensor of\n  shape `[batch_size, Tv, dim]` and `key` tensor of shape\n  `[batch_size, Tv, dim]`. The calculation follows the steps:\n\n  1. Calculate scores with shape `[batch_size, Tq, Tv]` as a `query`-`key` dot\n     product: `scores = tf.matmul(query, key, transpose_b=True)`.\n  2. Use scores to calculate a distribution with shape\n     `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.\n  3. Use `distribution` to create a linear combination of `value` with\n     shape `[batch_size, Tq, dim]`:\n     `return tf.matmul(distribution, value)`.\n\n  Args:\n    use_scale: If `True`, will create a scalar variable to scale the attention\n      scores.\n    causal: Boolean. Set to `True` for decoder self-attention. Adds a mask such\n      that position `i` cannot attend to positions `j > i`. This prevents the\n      flow of information from the future towards the past.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n      attention scores.\n\n  Call Args:\n\n    inputs: List of the following tensors:\n      * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n      * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n      * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n        given, will use `value` for both `key` and `value`, which is the\n        most common case.\n    mask: List of the following tensors:\n      * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n        If given, the output will be zero at the positions where\n        `mask==False`.\n      * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n        If given, will apply the mask such that values at positions where\n        `mask==False` do not contribute to the result.\n    return_attention_scores: bool, it `True`, returns the attention scores\n      (after masking and softmax) as an additional output argument.\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (no dropout).\n\n  Output:\n\n    Attention outputs of shape `[batch_size, Tq, dim]`.\n    [Optional] Attention scores after masking and softmax with shape\n      `[batch_size, Tq, Tv]`.\n\n  The meaning of `query`, `value` and `key` depend on the application. In the\n  case of text similarity, for example, `query` is the sequence embeddings of\n  the first piece of text and `value` is the sequence embeddings of the second\n  piece of text. `key` is usually the same tensor as `value`.\n\n  Here is a code example for using `Attention` in a CNN+Attention network:\n\n  ```python\n  # Variable-length int sequences.\n  query_input = tf.keras.Input(shape=(None,), dtype='int32')\n  value_input = tf.keras.Input(shape=(None,), dtype='int32')\n\n  # Embedding lookup.\n  token_embedding = tf.keras.layers.Embedding(input_dim=1000, output_dim=64)\n  # Query embeddings of shape [batch_size, Tq, dimension].\n  query_embeddings = token_embedding(query_input)\n  # Value embeddings of shape [batch_size, Tv, dimension].\n  value_embeddings = token_embedding(value_input)\n\n  # CNN layer.\n  cnn_layer = tf.keras.layers.Conv1D(\n      filters=100,\n      kernel_size=4,\n      # Use 'same' padding so outputs have the same shape as inputs.\n      padding='same')\n  # Query encoding of shape [batch_size, Tq, filters].\n  query_seq_encoding = cnn_layer(query_embeddings)\n  # Value encoding of shape [batch_size, Tv, filters].\n  value_seq_encoding = cnn_layer(value_embeddings)\n\n  # Query-value attention of shape [batch_size, Tq, filters].\n  query_value_attention_seq = tf.keras.layers.Attention()(\n      [query_seq_encoding, value_seq_encoding])\n\n  # Reduce over the sequence axis to produce encodings of shape\n  # [batch_size, filters].\n  query_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n      query_seq_encoding)\n  query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n      query_value_attention_seq)\n\n  # Concatenate query and document encodings to produce a DNN input layer.\n  input_layer = tf.keras.layers.Concatenate()(\n      [query_encoding, query_value_attention])\n\n  # Add DNN layers, and create Model.\n  # ...\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "use_scale",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "return_attention_scores",
        "default": "False",
        "type": "boolean"
      }
    ],
    "file": "keras/layers/dense_attention.py",
    "aliases": []
  },
  {
    "name": "Average",
    "base": "_Merge",
    "docstring": "Layer that averages a list of inputs element-wise.\n\n  It takes as input a list of tensors, all of the same shape, and returns\n  a single tensor (also of the same shape).\n\n  Example:\n\n  >>> x1 = np.ones((2, 2))\n  >>> x2 = np.zeros((2, 2))\n  >>> y = tf.keras.layers.Average()([x1, x2])\n  >>> y.numpy().tolist()\n  [[0.5, 0.5], [0.5, 0.5]]\n\n  Usage in a functional model:\n\n  >>> input1 = tf.keras.layers.Input(shape=(16,))\n  >>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1)\n  >>> input2 = tf.keras.layers.Input(shape=(32,))\n  >>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2)\n  >>> avg = tf.keras.layers.Average()([x1, x2])\n  >>> out = tf.keras.layers.Dense(4)(avg)\n  >>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n\n  Raises:\n    ValueError: If there is a shape mismatch between the inputs and the shapes\n      cannot be broadcasted to match.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "AveragePooling1D",
    "base": "Pooling1D",
    "docstring": "Average pooling for temporal data.\n\n  Downsamples the input representation by taking the average value over the\n  window defined by `pool_size`. The window is shifted by `strides`.  The\n  resulting output when using \"valid\" padding option has a shape of:\n  `output_shape = (input_shape - pool_size + 1) / strides)`\n\n  The resulting output shape when using the \"same\" padding option is:\n  `output_shape = input_shape / strides`\n\n  For example, for strides=1 and padding=\"valid\":\n\n  >>> x = tf.constant([1., 2., 3., 4., 5.])\n  >>> x = tf.reshape(x, [1, 5, 1])\n  >>> x\n  <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\n    array([[[1.],\n            [2.],\n            [3.],\n            [4.],\n            [5.]], dtype=float32)>\n  >>> avg_pool_1d = tf.keras.layers.AveragePooling1D(pool_size=2,\n  ...    strides=1, padding='valid')\n  >>> avg_pool_1d(x)\n  <tf.Tensor: shape=(1, 4, 1), dtype=float32, numpy=\n  array([[[1.5],\n          [2.5],\n          [3.5],\n          [4.5]]], dtype=float32)>\n\n  For example, for strides=2 and padding=\"valid\":\n\n  >>> x = tf.constant([1., 2., 3., 4., 5.])\n  >>> x = tf.reshape(x, [1, 5, 1])\n  >>> x\n  <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\n    array([[[1.],\n            [2.],\n            [3.],\n            [4.],\n            [5.]], dtype=float32)>\n  >>> avg_pool_1d = tf.keras.layers.AveragePooling1D(pool_size=2,\n  ...    strides=2, padding='valid')\n  >>> avg_pool_1d(x)\n  <tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=\n  array([[[1.5],\n          [3.5]]], dtype=float32)>\n\n  For example, for strides=1 and padding=\"same\":\n\n  >>> x = tf.constant([1., 2., 3., 4., 5.])\n  >>> x = tf.reshape(x, [1, 5, 1])\n  >>> x\n  <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\n    array([[[1.],\n            [2.],\n            [3.],\n            [4.],\n            [5.]], dtype=float32)>\n  >>> avg_pool_1d = tf.keras.layers.AveragePooling1D(pool_size=2,\n  ...    strides=1, padding='same')\n  >>> avg_pool_1d(x)\n  <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\n  array([[[1.5],\n          [2.5],\n          [3.5],\n          [4.5],\n          [5.]]], dtype=float32)>\n\n  Args:\n    pool_size: Integer, size of the average pooling windows.\n    strides: Integer, or None. Factor by which to downscale.\n      E.g. 2 will halve the input.\n      If None, it will default to `pool_size`.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n      the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, steps, features)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, features, steps)`.\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      3D tensor with shape `(batch_size, steps, features)`.\n    - If `data_format='channels_first'`:\n      3D tensor with shape `(batch_size, features, steps)`.\n\n  Output shape:\n    - If `data_format='channels_last'`:\n      3D tensor with shape `(batch_size, downsampled_steps, features)`.\n    - If `data_format='channels_first'`:\n      3D tensor with shape `(batch_size, features, downsampled_steps)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "pool_size",
        "default": 2
      },
      {
        "name": "strides",
        "default": "None"
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "channels_last"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/pooling.py",
    "aliases": [
      "AvgPool1D"
    ]
  },
  {
    "name": "AveragePooling2D",
    "base": "Pooling2D",
    "docstring": "Average pooling operation for spatial data.\n\n  Downsamples the input along its spatial dimensions (height and width)\n  by taking the average value over an input window\n  (of size defined by `pool_size`) for each channel of the input.\n  The window is shifted by `strides` along each dimension.\n\n  The resulting output when using `\"valid\"` padding option has a shape\n  (number of rows or columns) of:\n  `output_shape = math.floor((input_shape - pool_size) / strides) + 1`\n  (when `input_shape >= pool_size`)\n\n  The resulting output shape when using the `\"same\"` padding option is:\n  `output_shape = math.floor((input_shape - 1) / strides) + 1`\n\n  For example, for `strides=(1, 1)` and `padding=\"valid\"`:\n\n  >>> x = tf.constant([[1., 2., 3.],\n  ...                  [4., 5., 6.],\n  ...                  [7., 8., 9.]])\n  >>> x = tf.reshape(x, [1, 3, 3, 1])\n  >>> avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),\n  ...    strides=(1, 1), padding='valid')\n  >>> avg_pool_2d(x)\n  <tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n    array([[[[3.],\n             [4.]],\n            [[6.],\n             [7.]]]], dtype=float32)>\n\n  For example, for `stride=(2, 2)` and `padding=\"valid\"`:\n\n  >>> x = tf.constant([[1., 2., 3., 4.],\n  ...                  [5., 6., 7., 8.],\n  ...                  [9., 10., 11., 12.]])\n  >>> x = tf.reshape(x, [1, 3, 4, 1])\n  >>> avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),\n  ...    strides=(2, 2), padding='valid')\n  >>> avg_pool_2d(x)\n  <tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=\n    array([[[[3.5],\n             [5.5]]]], dtype=float32)>\n\n  For example, for `strides=(1, 1)` and `padding=\"same\"`:\n\n  >>> x = tf.constant([[1., 2., 3.],\n  ...                  [4., 5., 6.],\n  ...                  [7., 8., 9.]])\n  >>> x = tf.reshape(x, [1, 3, 3, 1])\n  >>> avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),\n  ...    strides=(1, 1), padding='same')\n  >>> avg_pool_2d(x)\n  <tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n    array([[[[3.],\n             [4.],\n             [4.5]],\n            [[6.],\n             [7.],\n             [7.5]],\n            [[7.5],\n             [8.5],\n             [9.]]]], dtype=float32)>\n\n  Args:\n    pool_size: integer or tuple of 2 integers,\n      factors by which to downscale (vertical, horizontal).\n      `(2, 2)` will halve the input in both spatial dimension.\n      If only one integer is specified, the same window length\n      will be used for both dimensions.\n    strides: Integer, tuple of 2 integers, or None.\n      Strides values.\n      If None, it will default to `pool_size`.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n      the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      4D tensor with shape `(batch_size, rows, cols, channels)`.\n    - If `data_format='channels_first'`:\n      4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n  Output shape:\n    - If `data_format='channels_last'`:\n      4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n    - If `data_format='channels_first'`:\n      4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "pool_size",
        "default": [
          2,
          2
        ]
      },
      {
        "name": "strides",
        "default": "None"
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/pooling.py",
    "aliases": [
      "AvgPool2D"
    ]
  },
  {
    "name": "AveragePooling3D",
    "base": "Pooling3D",
    "docstring": "Average pooling operation for 3D data (spatial or spatio-temporal).\n\n  Downsamples the input along its spatial dimensions (depth, height, and width)\n  by taking the average value over an input window\n  (of size defined by `pool_size`) for each channel of the input.\n  The window is shifted by `strides` along each dimension.\n\n  Args:\n    pool_size: tuple of 3 integers,\n      factors by which to downscale (dim1, dim2, dim3).\n      `(2, 2, 2)` will halve the size of the 3D input in each dimension.\n    strides: tuple of 3 integers, or None. Strides values.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n      the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      5D tensor with shape:\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n      5D tensor with shape:\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\n  Output shape:\n    - If `data_format='channels_last'`:\n      5D tensor with shape:\n      `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n    - If `data_format='channels_first'`:\n      5D tensor with shape:\n      `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n\n  Example:\n\n  ```python\n  depth = 30\n  height = 30\n  width = 30\n  input_channels = 3\n\n  inputs = tf.keras.Input(shape=(depth, height, width, input_channels))\n  layer = tf.keras.layers.AveragePooling3D(pool_size=3)\n  outputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "pool_size",
        "default": [
          2,
          2,
          2
        ]
      },
      {
        "name": "strides",
        "default": "None"
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/pooling.py",
    "aliases": [
      "AvgPool3D"
    ]
  },
  {
    "name": "BatchNormalization",
    "base": "BatchNormalizationBase",
    "docstring": "Layer that normalizes its inputs.\n\n  Batch normalization applies a transformation that maintains the mean output\n  close to 0 and the output standard deviation close to 1.\n\n  Importantly, batch normalization works differently during training and\n  during inference.\n\n  **During training** (i.e. when using `fit()` or when calling the layer/model\n  with the argument `training=True`), the layer normalizes its output using\n  the mean and standard deviation of the current batch of inputs. That is to\n  say, for each channel being normalized, the layer returns\n  `gamma * (batch - mean(batch)) / sqrt(var(batch) + epsilon) + beta`, where:\n\n  - `epsilon` is small constant (configurable as part of the constructor\n  arguments)\n  - `gamma` is a learned scaling factor (initialized as 1), which\n  can be disabled by passing `scale=False` to the constructor.\n  - `beta` is a learned offset factor (initialized as 0), which\n  can be disabled by passing `center=False` to the constructor.\n\n  **During inference** (i.e. when using `evaluate()` or `predict()` or when\n  calling the layer/model with the argument `training=False` (which is the\n  default), the layer normalizes its output using a moving average of the\n  mean and standard deviation of the batches it has seen during training. That\n  is to say, it returns\n  `gamma * (batch - self.moving_mean) / sqrt(self.moving_var + epsilon) + beta`.\n\n  `self.moving_mean` and `self.moving_var` are non-trainable variables that\n  are updated each time the layer in called in training mode, as such:\n\n  - `moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)`\n  - `moving_var = moving_var * momentum + var(batch) * (1 - momentum)`\n\n  As such, the layer will only normalize its inputs during inference\n  *after having been trained on data that has similar statistics as the\n  inference data*.\n\n  Args:\n    axis: Integer, the axis that should be normalized (typically the features\n      axis). For instance, after a `Conv2D` layer with\n      `data_format=\"channels_first\"`, set `axis=1` in `BatchNormalization`.\n    momentum: Momentum for the moving average.\n    epsilon: Small float added to variance to avoid dividing by zero.\n    center: If True, add offset of `beta` to normalized tensor. If False, `beta`\n      is ignored.\n    scale: If True, multiply by `gamma`. If False, `gamma` is not used. When the\n      next layer is linear (also e.g. `nn.relu`), this can be disabled since the\n      scaling will be done by the next layer.\n    beta_initializer: Initializer for the beta weight.\n    gamma_initializer: Initializer for the gamma weight.\n    moving_mean_initializer: Initializer for the moving mean.\n    moving_variance_initializer: Initializer for the moving variance.\n    beta_regularizer: Optional regularizer for the beta weight.\n    gamma_regularizer: Optional regularizer for the gamma weight.\n    beta_constraint: Optional constraint for the beta weight.\n    gamma_constraint: Optional constraint for the gamma weight.\n\n  Call arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode.\n      - `training=True`: The layer will normalize its inputs using the mean and\n        variance of the current batch of inputs.\n      - `training=False`: The layer will normalize its inputs using the mean and\n        variance of its moving statistics, learned during training.\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape` (tuple of\n    integers, does not include the samples axis) when using this layer as the\n    first layer in a model.\n\n  Output shape:\n    Same shape as input.\n\n  Reference:\n    - [Ioffe and Szegedy, 2015](https://arxiv.org/abs/1502.03167).\n\n  **About setting `layer.trainable = False` on a `BatchNormalization` layer:**\n\n  The meaning of setting `layer.trainable = False` is to freeze the layer,\n  i.e. its internal state will not change during training:\n  its trainable weights will not be updated\n  during `fit()` or `train_on_batch()`, and its state updates will not be run.\n\n  Usually, this does not necessarily mean that the layer is run in inference\n  mode (which is normally controlled by the `training` argument that can\n  be passed when calling a layer). \"Frozen state\" and \"inference mode\"\n  are two separate concepts.\n\n  However, in the case of the `BatchNormalization` layer, **setting\n  `trainable = False` on the layer means that the layer will be\n  subsequently run in inference mode** (meaning that it will use\n  the moving mean and the moving variance to normalize the current batch,\n  rather than using the mean and variance of the current batch).\n\n  This behavior has been introduced in TensorFlow 2.0, in order\n  to enable `layer.trainable = False` to produce the most commonly\n  expected behavior in the convnet fine-tuning use case.\n\n  Note that:\n    - Setting `trainable` on an model containing other layers will\n      recursively set the `trainable` value of all inner layers.\n    - If the value of the `trainable`\n      attribute is changed after calling `compile()` on a model,\n      the new value doesn't take effect for this model\n      until `compile()` is called again.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "axis",
        "default": -1
      },
      {
        "name": "momentum",
        "default": 0.99
      },
      {
        "name": "epsilon",
        "default": 0.001
      },
      {
        "name": "center",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "scale",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "beta_initializer",
        "default": "zeros"
      },
      {
        "name": "gamma_initializer",
        "default": "ones"
      },
      {
        "name": "moving_mean_initializer",
        "default": "zeros"
      },
      {
        "name": "moving_variance_initializer",
        "default": "ones"
      },
      {
        "name": "beta_regularizer",
        "default": "None"
      },
      {
        "name": "gamma_regularizer",
        "default": "None"
      },
      {
        "name": "beta_constraint",
        "default": "None"
      },
      {
        "name": "gamma_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/normalization/batch_normalization.py",
    "aliases": []
  },
  {
    "name": "Bidirectional",
    "base": "Wrapper",
    "docstring": "Bidirectional wrapper for RNNs.\n\n  Args:\n    layer: `keras.layers.RNN` instance, such as `keras.layers.LSTM` or\n      `keras.layers.GRU`. It could also be a `keras.layers.Layer` instance\n      that meets the following criteria:\n      1. Be a sequence-processing layer (accepts 3D+ inputs).\n      2. Have a `go_backwards`, `return_sequences` and `return_state`\n        attribute (with the same semantics as for the `RNN` class).\n      3. Have an `input_spec` attribute.\n      4. Implement serialization via `get_config()` and `from_config()`.\n      Note that the recommended way to create new RNN layers is to write a\n      custom RNN cell and use it with `keras.layers.RNN`, instead of\n      subclassing `keras.layers.Layer` directly.\n      - When the `returns_sequences` is true, the output of the masked timestep\n      will be zero regardless of the layer's original `zero_output_for_mask`\n      value.\n    merge_mode: Mode by which outputs of the forward and backward RNNs will be\n      combined. One of {'sum', 'mul', 'concat', 'ave', None}. If None, the\n      outputs will not be combined, they will be returned as a list. Default\n      value is 'concat'.\n    backward_layer: Optional `keras.layers.RNN`, or `keras.layers.Layer`\n      instance to be used to handle backwards input processing.\n      If `backward_layer` is not provided, the layer instance passed as the\n      `layer` argument will be used to generate the backward layer\n      automatically.\n      Note that the provided `backward_layer` layer should have properties\n      matching those of the `layer` argument, in particular it should have the\n      same values for `stateful`, `return_states`, `return_sequences`, etc.\n      In addition, `backward_layer` and `layer` should have different\n      `go_backwards` argument values.\n      A `ValueError` will be raised if these requirements are not met.\n\n  Call arguments:\n    The call arguments for this layer are the same as those of the wrapped RNN\n      layer.\n    Beware that when passing the `initial_state` argument during the call of\n    this layer, the first half in the list of elements in the `initial_state`\n    list will be passed to the forward RNN call and the last half in the list\n    of elements will be passed to the backward RNN call.\n\n  Raises:\n    ValueError:\n      1. If `layer` or `backward_layer` is not a `Layer` instance.\n      2. In case of invalid `merge_mode` argument.\n      3. If `backward_layer` has mismatched properties compared to `layer`.\n\n  Examples:\n\n  ```python\n  model = Sequential()\n  model.add(Bidirectional(LSTM(10, return_sequences=True), input_shape=(5, 10)))\n  model.add(Bidirectional(LSTM(10)))\n  model.add(Dense(5))\n  model.add(Activation('softmax'))\n  model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n   # With custom backward layer\n   model = Sequential()\n   forward_layer = LSTM(10, return_sequences=True)\n   backward_layer = LSTM(10, activation='relu', return_sequences=True,\n                         go_backwards=True)\n   model.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n                           input_shape=(5, 10)))\n   model.add(Dense(5))\n   model.add(Activation('softmax'))\n   model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "layer",
        "default": null
      },
      {
        "name": "merge_mode",
        "default": "concat"
      },
      {
        "name": "weights",
        "default": "None"
      },
      {
        "name": "backward_layer",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "initial_state",
        "default": "None"
      },
      {
        "name": "constants",
        "default": "None"
      }
    ],
    "file": "keras/layers/wrappers.py",
    "aliases": []
  },
  {
    "name": "CategoryEncoding",
    "base": "Layer",
    "docstring": "Category encoding layer.\n\n  This layer provides options for condensing data into a categorical encoding\n  when the total number of tokens are known in advance. It accepts integer\n  values as inputs, and it outputs a dense representation of those\n  inputs. For integer inputs where the total number of tokens is not known,\n  use instead `tf.keras.layers.IntegerLookup`.\n\n  Examples:\n\n  **One-hot encoding data**\n\n  >>> layer = tf.keras.layers.CategoryEncoding(\n  ...           num_tokens=4, output_mode=\"one_hot\")\n  >>> layer([3, 2, 0, 1])\n  <tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n    array([[0., 0., 0., 1.],\n           [0., 0., 1., 0.],\n           [1., 0., 0., 0.],\n           [0., 1., 0., 0.]], dtype=float32)>\n\n  **Multi-hot encoding data**\n\n  >>> layer = tf.keras.layers.CategoryEncoding(\n  ...           num_tokens=4, output_mode=\"multi_hot\")\n  >>> layer([[0, 1], [0, 0], [1, 2], [3, 1]])\n  <tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n    array([[1., 1., 0., 0.],\n           [1., 0., 0., 0.],\n           [0., 1., 1., 0.],\n           [0., 1., 0., 1.]], dtype=float32)>\n\n  **Using weighted inputs in `\"count\"` mode**\n\n  >>> layer = tf.keras.layers.CategoryEncoding(\n  ...           num_tokens=4, output_mode=\"count\")\n  >>> count_weights = np.array([[.1, .2], [.1, .1], [.2, .3], [.4, .2]])\n  >>> layer([[0, 1], [0, 0], [1, 2], [3, 1]], count_weights=count_weights)\n  <tf.Tensor: shape=(4, 4), dtype=float64, numpy=\n    array([[0.1, 0.2, 0. , 0. ],\n           [0.2, 0. , 0. , 0. ],\n           [0. , 0.2, 0.3, 0. ],\n           [0. , 0.2, 0. , 0.4]])>\n\n  Args:\n    num_tokens: The total number of tokens the layer should support. All inputs\n      to the layer must integers in the range `0 <= value < num_tokens`, or an\n      error will be thrown.\n    output_mode: Specification for the output of the layer.\n      Defaults to `\"multi_hot\"`. Values can be `\"one_hot\"`, `\"multi_hot\"` or\n      `\"count\"`, configuring the layer as follows:\n        - `\"one_hot\"`: Encodes each individual element in the input into an\n          array of `num_tokens` size, containing a 1 at the element index. If\n          the last dimension is size 1, will encode on that dimension. If the\n          last dimension is not size 1, will append a new dimension for the\n          encoded output.\n        - `\"multi_hot\"`: Encodes each sample in the input into a single array\n          of `num_tokens` size, containing a 1 for each vocabulary term present\n          in the sample. Treats the last dimension as the sample dimension, if\n          input shape is `(..., sample_length)`, output shape will be\n          `(..., num_tokens)`.\n        - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of\n          the number of times the token at that index appeared in the sample.\n      For all output modes, currently only output up to rank 2 is supported.\n    sparse: Boolean. If true, returns a `SparseTensor` instead of a dense\n      `Tensor`. Defaults to `False`.\n\n  Call arguments:\n    inputs: A 1D or 2D tensor of integer inputs.\n    count_weights: A tensor in the same shape as `inputs` indicating the\n      weight for each sample value when summing up in `count` mode. Not used in\n      `\"multi_hot\"` or `\"one_hot\"` modes.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "num_tokens",
        "default": "None"
      },
      {
        "name": "output_mode",
        "default": "multi_hot"
      },
      {
        "name": "sparse",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "count_weights",
        "default": "None"
      }
    ],
    "file": "keras/layers/preprocessing/category_encoding.py",
    "aliases": []
  },
  {
    "name": "CenterCrop",
    "base": "Layer",
    "docstring": "Crop the central portion of the images to target height and width.\n\n  Input shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\n  Output shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., target_height, target_width, channels)`.\n\n  If the input height/width is even and the target height/width is odd (or\n  inversely), the input image is left-padded by 1 pixel.\n\n  Args:\n    height: Integer, the height of the output shape.\n    width: Integer, the width of the output shape.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "height",
        "default": null
      },
      {
        "name": "width",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/preprocessing/image_preprocessing.py",
    "aliases": []
  },
  {
    "name": "Concatenate",
    "base": "_Merge",
    "docstring": "Layer that concatenates a list of inputs.\n\n  It takes as input a list of tensors, all of the same shape except\n  for the concatenation axis, and returns a single tensor that is the\n  concatenation of all inputs.\n\n  >>> x = np.arange(20).reshape(2, 2, 5)\n  >>> print(x)\n  [[[ 0  1  2  3  4]\n    [ 5  6  7  8  9]]\n   [[10 11 12 13 14]\n    [15 16 17 18 19]]]\n  >>> y = np.arange(20, 30).reshape(2, 1, 5)\n  >>> print(y)\n  [[[20 21 22 23 24]]\n   [[25 26 27 28 29]]]\n  >>> tf.keras.layers.Concatenate(axis=1)([x, y])\n  <tf.Tensor: shape=(2, 3, 5), dtype=int64, numpy=\n  array([[[ 0,  1,  2,  3,  4],\n          [ 5,  6,  7,  8,  9],\n          [20, 21, 22, 23, 24]],\n         [[10, 11, 12, 13, 14],\n          [15, 16, 17, 18, 19],\n          [25, 26, 27, 28, 29]]])>\n\n  >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n  >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n  >>> concatted = tf.keras.layers.Concatenate()([x1, x2])\n  >>> concatted.shape\n  TensorShape([5, 16])\n\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "axis",
        "default": -1
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "Conv1D",
    "base": "Conv",
    "docstring": "1D convolution layer (e.g. temporal convolution).\n\n  This layer creates a convolution kernel that is convolved\n  with the layer input over a single spatial (or temporal) dimension\n  to produce a tensor of outputs.\n  If `use_bias` is True, a bias vector is created and added to the outputs.\n  Finally, if `activation` is not `None`,\n  it is applied to the outputs as well.\n\n  When using this layer as the first layer in a model,\n  provide an `input_shape` argument\n  (tuple of integers or `None`, e.g.\n  `(10, 128)` for sequences of 10 vectors of 128-dimensional vectors,\n  or `(None, 128)` for variable-length sequences of 128-dimensional vectors.\n\n  Examples:\n\n  >>> # The inputs are 128-length vectors with 10 timesteps, and the batch size\n  >>> # is 4.\n  >>> input_shape = (4, 10, 128)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv1D(\n  ... 32, 3, activation='relu',input_shape=input_shape[1:])(x)\n  >>> print(y.shape)\n  (4, 8, 32)\n\n  >>> # With extended batch shape [4, 7] (e.g. weather data where batch\n  >>> # dimensions correspond to spatial location and the third dimension\n  >>> # corresponds to time.)\n  >>> input_shape = (4, 7, 10, 128)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv1D(\n  ... 32, 3, activation='relu', input_shape=input_shape[2:])(x)\n  >>> print(y.shape)\n  (4, 7, 8, 32)\n\n  Args:\n    filters: Integer, the dimensionality of the output space\n      (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of a single integer,\n      specifying the length of the 1D convolution window.\n    strides: An integer or tuple/list of a single integer,\n      specifying the stride length of the convolution.\n      Specifying any stride value != 1 is incompatible with specifying\n      any `dilation_rate` value != 1.\n    padding: One of `\"valid\"`, `\"same\"` or `\"causal\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n      to the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n      `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]`\n      does not depend on `input[t+1:]`. Useful when modeling temporal data\n      where the model should not violate the temporal order.\n      See [WaveNet: A Generative Model for Raw Audio, section\n        2.1](https://arxiv.org/abs/1609.03499).\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n    dilation_rate: an integer or tuple/list of a single integer, specifying\n      the dilation rate to use for dilated convolution.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any `strides` value != 1.\n    groups: A positive integer specifying the number of groups in which the\n      input is split along the channel axis. Each group is convolved\n      separately with `filters / groups` filters. The output is the\n      concatenation of all the `groups` results along the channel axis.\n      Input channels and `filters` must both be divisible by `groups`.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix (\n      see `keras.initializers`). Defaults to 'glorot_uniform'.\n    bias_initializer: Initializer for the bias vector (\n      see `keras.initializers`). Defaults to 'zeros'.\n    kernel_regularizer: Regularizer function applied to\n      the `kernel` weights matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its \"activation\") (\n      see `keras.regularizers`).\n    kernel_constraint: Constraint function applied to the kernel matrix (\n      see `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (\n      see `keras.constraints`).\n\n  Input shape:\n    3+D tensor with shape: `batch_shape + (steps, input_dim)`\n\n  Output shape:\n    3+D tensor with shape: `batch_shape + (new_steps, filters)`\n      `steps` value might have changed due to padding or strides.\n\n  Returns:\n    A tensor of rank 3 representing\n    `activation(conv1d(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": 1
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "channels_last"
      },
      {
        "name": "dilation_rate",
        "default": 1
      },
      {
        "name": "groups",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": [
      "Convolution1D"
    ]
  },
  {
    "name": "Conv1DTranspose",
    "base": "Conv1D",
    "docstring": "Transposed convolution layer (sometimes called Deconvolution).\n\n  The need for transposed convolutions generally arises\n  from the desire to use a transformation going in the opposite direction\n  of a normal convolution, i.e., from something that has the shape of the\n  output of some convolution to something that has the shape of its input\n  while maintaining a connectivity pattern that is compatible with\n  said convolution.\n\n  When using this layer as the first layer in a model,\n  provide the keyword argument `input_shape`\n  (tuple of integers or `None`, does not include the sample axis),\n  e.g. `input_shape=(128, 3)` for data with 128 time steps and 3 channels.\n\n  Args:\n    filters: Integer, the dimensionality of the output space\n      (i.e. the number of output filters in the convolution).\n    kernel_size: An integer length of the 1D convolution window.\n    strides: An integer specifying the stride of the convolution along the\n      time dimension. Specifying a stride value != 1 is incompatible with\n      specifying a `dilation_rate` value != 1. Defaults to 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n      to the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    output_padding: An integer specifying the amount of padding along\n      the time dimension of the output tensor.\n      The amount of output padding must be lower than the stride.\n      If set to `None` (default), the output shape is inferred.\n    data_format: A string, one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, length, channels)` while `channels_first` corresponds to\n      inputs with shape `(batch_size, channels, length)`.\n    dilation_rate: an integer, specifying\n      the dilation rate to use for dilated convolution.\n      Currently, specifying a `dilation_rate` value != 1 is\n      incompatible with specifying a stride value != 1.\n      Also dilation rate larger than 1 is not currently supported.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix (\n      see `keras.initializers`). Defaults to 'glorot_uniform'.\n    bias_initializer: Initializer for the bias vector (\n      see `keras.initializers`). Defaults to 'zeros'.\n    kernel_regularizer: Regularizer function applied to\n      the `kernel` weights matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its \"activation\") (see `keras.regularizers`).\n    kernel_constraint: Constraint function applied to the kernel matrix (\n      see `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (\n      see `keras.constraints`).\n\n  Input shape:\n    3D tensor with shape:\n    `(batch_size, steps, channels)`\n\n  Output shape:\n    3D tensor with shape:\n    `(batch_size, new_steps, filters)`\n    If `output_padding` is specified:\n    ```\n    new_timesteps = ((timesteps - 1) * strides + kernel_size -\n    2 * padding + output_padding)\n    ```\n\n  Returns:\n    A tensor of rank 3 representing\n    `activation(conv1dtranspose(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is \"causal\".\n    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n\n  References:\n    - [A guide to convolution arithmetic for deep learning](\n      https://arxiv.org/abs/1603.07285v1)\n    - [Deconvolutional Networks](\n      https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": 1
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "output_padding",
        "default": "None"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": [
      "Convolution1DTranspose"
    ]
  },
  {
    "name": "Conv2D",
    "base": "Conv",
    "docstring": "2D convolution layer (e.g. spatial convolution over images).\n\n  This layer creates a convolution kernel that is convolved\n  with the layer input to produce a tensor of\n  outputs. If `use_bias` is True,\n  a bias vector is created and added to the outputs. Finally, if\n  `activation` is not `None`, it is applied to the outputs as well.\n\n  When using this layer as the first layer in a model,\n  provide the keyword argument `input_shape`\n  (tuple of integers or `None`, does not include the sample axis),\n  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n  in `data_format=\"channels_last\"`. You can use `None` when\n  a dimension has variable size.\n\n  Examples:\n\n  >>> # The inputs are 28x28 RGB images with `channels_last` and the batch\n  >>> # size is 4.\n  >>> input_shape = (4, 28, 28, 3)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv2D(\n  ... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n  >>> print(y.shape)\n  (4, 26, 26, 2)\n\n  >>> # With `dilation_rate` as 2.\n  >>> input_shape = (4, 28, 28, 3)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv2D(\n  ... 2, 3, activation='relu', dilation_rate=2, input_shape=input_shape[1:])(x)\n  >>> print(y.shape)\n  (4, 24, 24, 2)\n\n  >>> # With `padding` as \"same\".\n  >>> input_shape = (4, 28, 28, 3)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv2D(\n  ... 2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n  >>> print(y.shape)\n  (4, 28, 28, 2)\n\n  >>> # With extended batch shape [4, 7]:\n  >>> input_shape = (4, 7, 28, 28, 3)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv2D(\n  ... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n  >>> print(y.shape)\n  (4, 7, 26, 26, 2)\n\n\n  Args:\n    filters: Integer, the dimensionality of the output space (i.e. the number of\n      output filters in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers, specifying the height\n      and width of the 2D convolution window. Can be a single integer to specify\n      the same value for all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers, specifying the strides of\n      the convolution along the height and width. Can be a single integer to\n      specify the same value for all spatial dimensions. Specifying any stride\n      value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n      to the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    data_format: A string, one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs. `channels_last` corresponds\n      to inputs with shape `(batch_size, height, width, channels)` while\n      `channels_first` corresponds to inputs with shape `(batch_size, channels,\n      height, width)`. It defaults to the `image_data_format` value found in\n      your Keras config file at `~/.keras/keras.json`. If you never set it, then\n      it will be `channels_last`.\n    dilation_rate: an integer or tuple/list of 2 integers, specifying the\n      dilation rate to use for dilated convolution. Can be a single integer to\n      specify the same value for all spatial dimensions. Currently, specifying\n      any `dilation_rate` value != 1 is incompatible with specifying any stride\n      value != 1.\n    groups: A positive integer specifying the number of groups in which the\n      input is split along the channel axis. Each group is convolved separately\n      with `filters / groups` filters. The output is the concatenation of all\n      the `groups` results along the channel axis. Input channels and `filters`\n      must both be divisible by `groups`.\n    activation: Activation function to use. If you don't specify anything, no\n      activation is applied (see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix (see\n      `keras.initializers`). Defaults to 'glorot_uniform'.\n    bias_initializer: Initializer for the bias vector (see\n      `keras.initializers`). Defaults to 'zeros'.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix (see `keras.regularizers`). \n    bias_regularizer: Regularizer function applied to the bias vector (see\n      `keras.regularizers`). \n    activity_regularizer: Regularizer function applied to the output of the\n      layer (its \"activation\") (see `keras.regularizers`).\n    kernel_constraint: Constraint function applied to the kernel matrix (see\n      `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (see\n      `keras.constraints`).\n  Input shape:\n    4+D tensor with shape: `batch_shape + (channels, rows, cols)` if\n      `data_format='channels_first'`\n    or 4+D tensor with shape: `batch_shape + (rows, cols, channels)` if\n      `data_format='channels_last'`.\n  Output shape:\n    4+D tensor with shape: `batch_shape + (filters, new_rows, new_cols)` if\n    `data_format='channels_first'` or 4+D tensor with shape: `batch_shape +\n      (new_rows, new_cols, filters)` if `data_format='channels_last'`.  `rows`\n      and `cols` values might have changed due to padding.\n\n  Returns:\n    A tensor of rank 4+ representing\n    `activation(conv2d(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is `\"causal\"`.\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "groups",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": [
      "Convolution2D"
    ]
  },
  {
    "name": "Conv2DTranspose",
    "base": "Conv2D",
    "docstring": "Transposed convolution layer (sometimes called Deconvolution).\n\n  The need for transposed convolutions generally arises\n  from the desire to use a transformation going in the opposite direction\n  of a normal convolution, i.e., from something that has the shape of the\n  output of some convolution to something that has the shape of its input\n  while maintaining a connectivity pattern that is compatible with\n  said convolution.\n\n  When using this layer as the first layer in a model,\n  provide the keyword argument `input_shape`\n  (tuple of integers or `None`, does not include the sample axis),\n  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n  in `data_format=\"channels_last\"`.\n\n  Args:\n    filters: Integer, the dimensionality of the output space\n      (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers, specifying the\n      height and width of the 2D convolution window.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers,\n      specifying the strides of the convolution along the height and width.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n      Specifying any stride value != 1 is incompatible with specifying\n      any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n      to the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    output_padding: An integer or tuple/list of 2 integers,\n      specifying the amount of padding along the height and width\n      of the output tensor.\n      Can be a single integer to specify the same value for all\n      spatial dimensions.\n      The amount of output padding along a given dimension must be\n      lower than the stride along that same dimension.\n      If set to `None` (default), the output shape is inferred.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 2 integers, specifying\n      the dilation rate to use for dilated convolution.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any stride value != 1.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix (\n      see `keras.initializers`). Defaults to 'glorot_uniform'.\n    bias_initializer: Initializer for the bias vector (\n      see `keras.initializers`). Defaults to 'zeros'.\n    kernel_regularizer: Regularizer function applied to\n      the `kernel` weights matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its \"activation\") (see `keras.regularizers`).\n    kernel_constraint: Constraint function applied to the kernel matrix (\n      see `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (\n      see `keras.constraints`).\n\n  Input shape:\n    4D tensor with shape:\n    `(batch_size, channels, rows, cols)` if data_format='channels_first'\n    or 4D tensor with shape:\n    `(batch_size, rows, cols, channels)` if data_format='channels_last'.\n\n  Output shape:\n    4D tensor with shape:\n    `(batch_size, filters, new_rows, new_cols)` if data_format='channels_first'\n    or 4D tensor with shape:\n    `(batch_size, new_rows, new_cols, filters)` if data_format='channels_last'.\n    `rows` and `cols` values might have changed due to padding.\n    If `output_padding` is specified:\n    ```\n    new_rows = ((rows - 1) * strides[0] + kernel_size[0] - 2 * padding[0] +\n    output_padding[0])\n    new_cols = ((cols - 1) * strides[1] + kernel_size[1] - 2 * padding[1] +\n    output_padding[1])\n    ```\n\n  Returns:\n    A tensor of rank 4 representing\n    `activation(conv2dtranspose(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is \"causal\".\n    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n\n  References:\n    - [A guide to convolution arithmetic for deep\n      learning](https://arxiv.org/abs/1603.07285v1)\n    - [Deconvolutional\n      Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "output_padding",
        "default": "None"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": [
      "Convolution2DTranspose"
    ]
  },
  {
    "name": "Conv3D",
    "base": "Conv",
    "docstring": "3D convolution layer (e.g. spatial convolution over volumes).\n\n  This layer creates a convolution kernel that is convolved\n  with the layer input to produce a tensor of\n  outputs. If `use_bias` is True,\n  a bias vector is created and added to the outputs. Finally, if\n  `activation` is not `None`, it is applied to the outputs as well.\n\n  When using this layer as the first layer in a model,\n  provide the keyword argument `input_shape`\n  (tuple of integers or `None`, does not include the sample axis),\n  e.g. `input_shape=(128, 128, 128, 1)` for 128x128x128 volumes\n  with a single channel,\n  in `data_format=\"channels_last\"`.\n\n  Examples:\n\n  >>> # The inputs are 28x28x28 volumes with a single channel, and the\n  >>> # batch size is 4\n  >>> input_shape =(4, 28, 28, 28, 1)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv3D(\n  ... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n  >>> print(y.shape)\n  (4, 26, 26, 26, 2)\n\n  >>> # With extended batch shape [4, 7], e.g. a batch of 4 videos of 3D frames,\n  >>> # with 7 frames per video.\n  >>> input_shape = (4, 7, 28, 28, 28, 1)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv3D(\n  ... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n  >>> print(y.shape)\n  (4, 7, 26, 26, 26, 2)\n\n  Args:\n    filters: Integer, the dimensionality of the output space (i.e. the number of\n      output filters in the convolution).\n    kernel_size: An integer or tuple/list of 3 integers, specifying the depth,\n      height and width of the 3D convolution window. Can be a single integer to\n      specify the same value for all spatial dimensions.\n    strides: An integer or tuple/list of 3 integers, specifying the strides of\n      the convolution along each spatial dimension. Can be a single integer to\n      specify the same value for all spatial dimensions. Specifying any stride\n      value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n      to the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    data_format: A string, one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs. `channels_last` corresponds\n      to inputs with shape `batch_shape + (spatial_dim1, spatial_dim2,\n      spatial_dim3, channels)` while `channels_first` corresponds to inputs with\n      shape `batch_shape + (channels, spatial_dim1, spatial_dim2,\n      spatial_dim3)`. It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`. If you never set it, then it\n      will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 3 integers, specifying the\n      dilation rate to use for dilated convolution. Can be a single integer to\n      specify the same value for all spatial dimensions. Currently, specifying\n      any `dilation_rate` value != 1 is incompatible with specifying any stride\n      value != 1.\n    groups: A positive integer specifying the number of groups in which the\n      input is split along the channel axis. Each group is convolved separately\n      with `filters / groups` filters. The output is the concatenation of all\n      the `groups` results along the channel axis. Input channels and `filters`\n      must both be divisible by `groups`.\n    activation: Activation function to use. If you don't specify anything, no\n      activation is applied (see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix (see\n      `keras.initializers`). Defaults to 'glorot_uniform'.\n    bias_initializer: Initializer for the bias vector (see\n      `keras.initializers`). Defaults to 'zeros'.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (see\n      `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to the output of the\n      layer (its \"activation\") (see `keras.regularizers`).\n    kernel_constraint: Constraint function applied to the kernel matrix (see\n      `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (see\n      `keras.constraints`).\n  Input shape:\n    5+D tensor with shape: `batch_shape + (channels, conv_dim1, conv_dim2,\n      conv_dim3)` if data_format='channels_first'\n    or 5+D tensor with shape: `batch_shape + (conv_dim1, conv_dim2, conv_dim3,\n      channels)` if data_format='channels_last'.\n  Output shape:\n    5+D tensor with shape: `batch_shape + (filters, new_conv_dim1,\n      new_conv_dim2, new_conv_dim3)` if data_format='channels_first'\n    or 5+D tensor with shape: `batch_shape + (new_conv_dim1, new_conv_dim2,\n      new_conv_dim3, filters)` if data_format='channels_last'. `new_conv_dim1`,\n      `new_conv_dim2` and `new_conv_dim3` values might have changed due to\n      padding.\n\n  Returns:\n    A tensor of rank 5+ representing\n    `activation(conv3d(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is \"causal\".\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1,
          1
        ]
      },
      {
        "name": "groups",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": [
      "Convolution3D"
    ]
  },
  {
    "name": "Conv3DTranspose",
    "base": "Conv3D",
    "docstring": "Transposed convolution layer (sometimes called Deconvolution).\n\n  The need for transposed convolutions generally arises\n  from the desire to use a transformation going in the opposite direction\n  of a normal convolution, i.e., from something that has the shape of the\n  output of some convolution to something that has the shape of its input\n  while maintaining a connectivity pattern that is compatible with\n  said convolution.\n\n  When using this layer as the first layer in a model,\n  provide the keyword argument `input_shape`\n  (tuple of integers or `None`, does not include the sample axis),\n  e.g. `input_shape=(128, 128, 128, 3)` for a 128x128x128 volume with 3 channels\n  if `data_format=\"channels_last\"`.\n\n  Args:\n    filters: Integer, the dimensionality of the output space\n      (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of 3 integers, specifying the\n      depth, height and width of the 3D convolution window.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n    strides: An integer or tuple/list of 3 integers,\n      specifying the strides of the convolution along the depth, height\n        and width.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n      Specifying any stride value != 1 is incompatible with specifying\n      any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n      to the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    output_padding: An integer or tuple/list of 3 integers,\n      specifying the amount of padding along the depth, height, and\n      width.\n      Can be a single integer to specify the same value for all\n      spatial dimensions.\n      The amount of output padding along a given dimension must be\n      lower than the stride along that same dimension.\n      If set to `None` (default), the output shape is inferred.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, depth, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, depth, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 3 integers, specifying\n      the dilation rate to use for dilated convolution.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any stride value != 1.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix (\n      see `keras.initializers`). Defaults to 'glorot_uniform'.\n    bias_initializer: Initializer for the bias vector (\n      see `keras.initializers`). Defaults to 'zeros'.\n    kernel_regularizer: Regularizer function applied to\n      the `kernel` weights matrix (\n      see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its \"activation\") (\n      see `keras.regularizers`).\n    kernel_constraint: Constraint function applied to the kernel matrix (\n      see `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (\n      see `keras.constraints`).\n\n  Input shape:\n    5D tensor with shape:\n    `(batch_size, channels, depth, rows, cols)` if data_format='channels_first'\n    or 5D tensor with shape:\n    `(batch_size, depth, rows, cols, channels)` if data_format='channels_last'.\n\n  Output shape:\n    5D tensor with shape:\n    `(batch_size, filters, new_depth, new_rows, new_cols)` if\n      data_format='channels_first'\n    or 5D tensor with shape:\n    `(batch_size, new_depth, new_rows, new_cols, filters)` if\n      data_format='channels_last'.\n    `depth` and `rows` and `cols` values might have changed due to padding.\n    If `output_padding` is specified::\n    ```\n    new_depth = ((depth - 1) * strides[0] + kernel_size[0] - 2 * padding[0] +\n    output_padding[0])\n    new_rows = ((rows - 1) * strides[1] + kernel_size[1] - 2 * padding[1] +\n    output_padding[1])\n    new_cols = ((cols - 1) * strides[2] + kernel_size[2] - 2 * padding[2] +\n    output_padding[2])\n    ```\n\n  Returns:\n    A tensor of rank 5 representing\n    `activation(conv3dtranspose(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is \"causal\".\n    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n\n  References:\n    - [A guide to convolution arithmetic for deep\n      learning](https://arxiv.org/abs/1603.07285v1)\n    - [Deconvolutional\n      Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "output_padding",
        "default": "None"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1,
          1
        ]
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": [
      "Convolution3DTranspose"
    ]
  },
  {
    "name": "ConvLSTM1D",
    "base": "ConvLSTM",
    "docstring": "1D Convolutional LSTM.\n\n  Similar to an LSTM layer, but the input transformations\n  and recurrent transformations are both convolutional.\n\n  Args:\n    filters: Integer, the dimensionality of the output space (i.e. the number of\n      output filters in the convolution).\n    kernel_size: An integer or tuple/list of n integers, specifying the\n      dimensions of the convolution window.\n    strides: An integer or tuple/list of n integers, specifying the strides of\n      the convolution. Specifying any stride value != 1 is incompatible with\n      specifying any `dilation_rate` value != 1.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive). `\"valid\"` means no\n      padding. `\"same\"` results in padding evenly to the left/right or up/down\n      of the input such that output has the same height/width dimension as the\n      input.\n    data_format: A string, one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs. `channels_last` corresponds\n      to inputs with shape `(batch, time, ..., channels)` while `channels_first`\n      corresponds to inputs with shape `(batch, time, channels, ...)`. It\n      defaults to the `image_data_format` value found in your Keras config file\n      at `~/.keras/keras.json`. If you never set it, then it will be\n      \"channels_last\".\n    dilation_rate: An integer or tuple/list of n integers, specifying the\n      dilation rate to use for dilated convolution. Currently, specifying any\n      `dilation_rate` value != 1 is incompatible with specifying any `strides`\n      value != 1.\n    activation: Activation function to use. By default hyperbolic tangent\n      activation function is applied (`tanh(x)`).\n    recurrent_activation: Activation function to use for the recurrent step.\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix, used for\n      the linear transformation of the inputs.\n    recurrent_initializer: Initializer for the `recurrent_kernel` weights\n      matrix, used for the linear transformation of the recurrent state.\n    bias_initializer: Initializer for the bias vector.\n    unit_forget_bias: Boolean. If True, add 1 to the bias of the forget gate at\n      initialization. Use in combination with `bias_initializer=\"zeros\"`. This\n      is recommended in [Jozefowicz et al., 2015](\n        http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix.\n    bias_regularizer: Regularizer function applied to the bias vector.\n    activity_regularizer: Regularizer function applied to.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix.\n    bias_constraint: Constraint function applied to the bias vector.\n    return_sequences: Boolean. Whether to return the last output in the output\n      sequence, or the full sequence. (default False)\n    return_state: Boolean Whether to return the last state in addition to the\n      output. (default False)\n    go_backwards: Boolean (default False). If True, process the input sequence\n      backwards.\n    stateful: Boolean (default False). If True, the last state for each sample\n      at index i in a batch will be used as initial state for the sample of\n      index i in the following batch.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the linear\n      transformation of the inputs.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state.\n  Call arguments:\n    inputs: A 4D tensor.\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether a\n      given timestep should be masked.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the cell\n      when calling it. This is only relevant if `dropout` or `recurrent_dropout`\n      are set.\n    initial_state: List of initial state tensors to be passed to the first call\n      of the cell.\n  Input shape: - If data_format='channels_first'\n        4D tensor with shape: `(samples, time, channels, rows)` - If\n          data_format='channels_last'\n        4D tensor with shape: `(samples, time, rows, channels)`\n  Output shape:\n    - If `return_state`: a list of tensors. The first tensor is the output. The\n      remaining tensors are the last states,\n      each 3D tensor with shape: `(samples, filters, new_rows)` if\n        data_format='channels_first'\n      or shape: `(samples, new_rows, filters)` if data_format='channels_last'.\n        `rows` values might have changed due to padding.\n    - If `return_sequences`: 4D tensor with shape: `(samples, timesteps,\n      filters, new_rows)` if data_format='channels_first'\n      or shape: `(samples, timesteps, new_rows, filters)` if\n        data_format='channels_last'.\n    - Else, 3D tensor with shape: `(samples, filters, new_rows)` if\n      data_format='channels_first'\n      or shape: `(samples, new_rows, filters)` if data_format='channels_last'.\n\n  Raises:\n    ValueError: in case of invalid constructor arguments.\n\n  References:\n    - [Shi et al., 2015](http://arxiv.org/abs/1506.04214v1)\n    (the current implementation does not include the feedback loop on the\n    cells output).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": 1
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": 1
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "recurrent_activation",
        "default": "hard_sigmoid"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "unit_forget_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "return_sequences",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "return_state",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "go_backwards",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "stateful",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "initial_state",
        "default": "None"
      }
    ],
    "file": "keras/layers/convolutional_recurrent.py",
    "aliases": []
  },
  {
    "name": "ConvLSTM2D",
    "base": "ConvLSTM",
    "docstring": "2D Convolutional LSTM.\n\n  Similar to an LSTM layer, but the input transformations\n  and recurrent transformations are both convolutional.\n\n  Args:\n    filters: Integer, the dimensionality of the output space (i.e. the number of\n      output filters in the convolution).\n    kernel_size: An integer or tuple/list of n integers, specifying the\n      dimensions of the convolution window.\n    strides: An integer or tuple/list of n integers, specifying the strides of\n      the convolution. Specifying any stride value != 1 is incompatible with\n      specifying any `dilation_rate` value != 1.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive). `\"valid\"` means no\n      padding. `\"same\"` results in padding evenly to the left/right or up/down\n      of the input such that output has the same height/width dimension as the\n      input.\n    data_format: A string, one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs. `channels_last` corresponds\n      to inputs with shape `(batch, time, ..., channels)` while `channels_first`\n      corresponds to inputs with shape `(batch, time, channels, ...)`. It\n      defaults to the `image_data_format` value found in your Keras config file\n      at `~/.keras/keras.json`. If you never set it, then it will be\n      \"channels_last\".\n    dilation_rate: An integer or tuple/list of n integers, specifying the\n      dilation rate to use for dilated convolution. Currently, specifying any\n      `dilation_rate` value != 1 is incompatible with specifying any `strides`\n      value != 1.\n    activation: Activation function to use. By default hyperbolic tangent\n      activation function is applied (`tanh(x)`).\n    recurrent_activation: Activation function to use for the recurrent step.\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix, used for\n      the linear transformation of the inputs.\n    recurrent_initializer: Initializer for the `recurrent_kernel` weights\n      matrix, used for the linear transformation of the recurrent state.\n    bias_initializer: Initializer for the bias vector.\n    unit_forget_bias: Boolean. If True, add 1 to the bias of the forget gate at\n      initialization. Use in combination with `bias_initializer=\"zeros\"`. This\n      is recommended in [Jozefowicz et al., 2015](\n        http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix.\n    bias_regularizer: Regularizer function applied to the bias vector.\n    activity_regularizer: Regularizer function applied to.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix.\n    bias_constraint: Constraint function applied to the bias vector.\n    return_sequences: Boolean. Whether to return the last output in the output\n      sequence, or the full sequence. (default False)\n    return_state: Boolean Whether to return the last state in addition to the\n      output. (default False)\n    go_backwards: Boolean (default False). If True, process the input sequence\n      backwards.\n    stateful: Boolean (default False). If True, the last state for each sample\n      at index i in a batch will be used as initial state for the sample of\n      index i in the following batch.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the linear\n      transformation of the inputs.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state.\n  Call arguments:\n    inputs: A 5D tensor.\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether a\n      given timestep should be masked.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the cell\n      when calling it. This is only relevant if `dropout` or `recurrent_dropout`\n      are set.\n    initial_state: List of initial state tensors to be passed to the first call\n      of the cell.\n  Input shape: - If data_format='channels_first'\n        5D tensor with shape: `(samples, time, channels, rows, cols)` - If\n          data_format='channels_last'\n        5D tensor with shape: `(samples, time, rows, cols, channels)`\n  Output shape:\n    - If `return_state`: a list of tensors. The first tensor is the output. The\n      remaining tensors are the last states,\n      each 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n        data_format='channels_first'\n      or shape: `(samples, new_rows, new_cols, filters)` if\n        data_format='channels_last'. `rows` and `cols` values might have changed\n        due to padding.\n    - If `return_sequences`: 5D tensor with shape: `(samples, timesteps,\n      filters, new_rows, new_cols)` if data_format='channels_first'\n      or shape: `(samples, timesteps, new_rows, new_cols, filters)` if\n        data_format='channels_last'.\n    - Else, 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n      data_format='channels_first'\n      or shape: `(samples, new_rows, new_cols, filters)` if\n        data_format='channels_last'.\n\n  Raises:\n    ValueError: in case of invalid constructor arguments.\n\n  References:\n    - [Shi et al., 2015](http://arxiv.org/abs/1506.04214v1)\n    (the current implementation does not include the feedback loop on the\n    cells output).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "recurrent_activation",
        "default": "hard_sigmoid"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "unit_forget_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "return_sequences",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "return_state",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "go_backwards",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "stateful",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "initial_state",
        "default": "None"
      }
    ],
    "file": "keras/layers/convolutional_recurrent.py",
    "aliases": []
  },
  {
    "name": "ConvLSTM3D",
    "base": "ConvLSTM",
    "docstring": "3D Convolutional LSTM.\n\n  Similar to an LSTM layer, but the input transformations\n  and recurrent transformations are both convolutional.\n\n  Args:\n    filters: Integer, the dimensionality of the output space (i.e. the number of\n      output filters in the convolution).\n    kernel_size: An integer or tuple/list of n integers, specifying the\n      dimensions of the convolution window.\n    strides: An integer or tuple/list of n integers, specifying the strides of\n      the convolution. Specifying any stride value != 1 is incompatible with\n      specifying any `dilation_rate` value != 1.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive). `\"valid\"` means no\n      padding. `\"same\"` results in padding evenly to the left/right or up/down\n      of the input such that output has the same height/width dimension as the\n      input.\n    data_format: A string, one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs. `channels_last` corresponds\n      to inputs with shape `(batch, time, ..., channels)` while `channels_first`\n      corresponds to inputs with shape `(batch, time, channels, ...)`. It\n      defaults to the `image_data_format` value found in your Keras config file\n      at `~/.keras/keras.json`. If you never set it, then it will be\n      \"channels_last\".\n    dilation_rate: An integer or tuple/list of n integers, specifying the\n      dilation rate to use for dilated convolution. Currently, specifying any\n      `dilation_rate` value != 1 is incompatible with specifying any `strides`\n      value != 1.\n    activation: Activation function to use. By default hyperbolic tangent\n      activation function is applied (`tanh(x)`).\n    recurrent_activation: Activation function to use for the recurrent step.\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix, used for\n      the linear transformation of the inputs.\n    recurrent_initializer: Initializer for the `recurrent_kernel` weights\n      matrix, used for the linear transformation of the recurrent state.\n    bias_initializer: Initializer for the bias vector.\n    unit_forget_bias: Boolean. If True, add 1 to the bias of the forget gate at\n      initialization. Use in combination with `bias_initializer=\"zeros\"`. This\n      is recommended in [Jozefowicz et al., 2015](\n        http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix.\n    bias_regularizer: Regularizer function applied to the bias vector.\n    activity_regularizer: Regularizer function applied to.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix.\n    bias_constraint: Constraint function applied to the bias vector.\n    return_sequences: Boolean. Whether to return the last output in the output\n      sequence, or the full sequence. (default False)\n    return_state: Boolean Whether to return the last state in addition to the\n      output. (default False)\n    go_backwards: Boolean (default False). If True, process the input sequence\n      backwards.\n    stateful: Boolean (default False). If True, the last state for each sample\n      at index i in a batch will be used as initial state for the sample of\n      index i in the following batch.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the linear\n      transformation of the inputs.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state.\n  Call arguments:\n    inputs: A 6D tensor.\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether a\n      given timestep should be masked.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the cell\n      when calling it. This is only relevant if `dropout` or `recurrent_dropout`\n      are set.\n    initial_state: List of initial state tensors to be passed to the first call\n      of the cell.\n  Input shape: - If data_format='channels_first'\n        6D tensor with shape: `(samples, time, channels, rows, cols, depth)` -\n          If data_format='channels_last'\n        5D tensor with shape: `(samples, time, rows, cols, depth, channels)`\n  Output shape:\n    - If `return_state`: a list of tensors. The first tensor is the output. The\n      remaining tensors are the last states,\n      each 5D tensor with shape: `(samples, filters, new_rows, new_cols,\n        new_depth)` if data_format='channels_first'\n      or shape: `(samples, new_rows, new_cols, new_depth, filters)` if\n        data_format='channels_last'. `rows`, `cols`, and `depth` values might\n        have changed due to padding.\n    - If `return_sequences`: 6D tensor with shape: `(samples, timesteps,\n      filters, new_rows, new_cols, new_depth)` if data_format='channels_first'\n      or shape: `(samples, timesteps, new_rows, new_cols, new_depth, filters)`\n        if data_format='channels_last'.\n    - Else, 5D tensor with shape: `(samples, filters, new_rows, new_cols,\n      new_depth)` if data_format='channels_first'\n      or shape: `(samples, new_rows, new_cols, new_depth, filters)` if\n        data_format='channels_last'.\n\n  Raises:\n    ValueError: in case of invalid constructor arguments.\n\n  References:\n    - [Shi et al., 2015](http://arxiv.org/abs/1506.04214v1)\n    (the current implementation does not include the feedback loop on the\n    cells output).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1,
          1
        ]
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "recurrent_activation",
        "default": "hard_sigmoid"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "unit_forget_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "return_sequences",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "return_state",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "go_backwards",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "stateful",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "initial_state",
        "default": "None"
      }
    ],
    "file": "keras/layers/convolutional_recurrent.py",
    "aliases": []
  },
  {
    "name": "Cropping1D",
    "base": "Layer",
    "docstring": "Cropping layer for 1D input (e.g. temporal sequence).\n\n  It crops along the time dimension (axis 1).\n\n  Examples:\n\n  >>> input_shape = (2, 3, 2)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> print(x)\n  [[[ 0  1]\n    [ 2  3]\n    [ 4  5]]\n   [[ 6  7]\n    [ 8  9]\n    [10 11]]]\n  >>> y = tf.keras.layers.Cropping1D(cropping=1)(x)\n  >>> print(y)\n  tf.Tensor(\n    [[[2 3]]\n     [[8 9]]], shape=(2, 1, 2), dtype=int64)\n\n  Args:\n    cropping: Int or tuple of int (length 2)\n      How many units should be trimmed off at the beginning and end of\n      the cropping dimension (axis 1).\n      If a single int is provided, the same value will be used for both.\n\n  Input shape:\n    3D tensor with shape `(batch_size, axis_to_crop, features)`\n\n  Output shape:\n    3D tensor with shape `(batch_size, cropped_axis, features)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "cropping",
        "default": [
          1,
          1
        ]
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "Cropping2D",
    "base": "Layer",
    "docstring": "Cropping layer for 2D input (e.g. picture).\n\n  It crops along spatial dimensions, i.e. height and width.\n\n  Examples:\n\n  >>> input_shape = (2, 28, 28, 3)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> y = tf.keras.layers.Cropping2D(cropping=((2, 2), (4, 4)))(x)\n  >>> print(y.shape)\n  (2, 24, 20, 3)\n\n  Args:\n    cropping: Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n      - If int: the same symmetric cropping\n        is applied to height and width.\n      - If tuple of 2 ints:\n        interpreted as two different\n        symmetric cropping values for height and width:\n        `(symmetric_height_crop, symmetric_width_crop)`.\n      - If tuple of 2 tuples of 2 ints:\n        interpreted as\n        `((top_crop, bottom_crop), (left_crop, right_crop))`\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, rows, cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, channels, rows, cols)`\n\n  Output shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, cropped_rows, cropped_cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, channels, cropped_rows, cropped_cols)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "cropping",
        "default": [
          [
            0,
            0
          ],
          [
            0,
            0
          ]
        ]
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "Cropping3D",
    "base": "Layer",
    "docstring": "Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n\n    Examples:\n\n  >>> input_shape = (2, 28, 28, 10, 3)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> y = tf.keras.layers.Cropping3D(cropping=(2, 4, 2))(x)\n  >>> print(y.shape)\n  (2, 24, 20, 6, 3)\n\n  Args:\n    cropping: Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n      - If int: the same symmetric cropping\n        is applied to depth, height, and width.\n      - If tuple of 3 ints: interpreted as two different\n        symmetric cropping values for depth, height, and width:\n        `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n      - If tuple of 3 tuples of 2 ints: interpreted as\n        `((left_dim1_crop, right_dim1_crop), (left_dim2_crop,\n          right_dim2_crop), (left_dim3_crop, right_dim3_crop))`\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop,\n        depth)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, depth, first_axis_to_crop, second_axis_to_crop,\n        third_axis_to_crop)`\n\n  Output shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, first_cropped_axis, second_cropped_axis, third_cropped_axis,\n        depth)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, depth, first_cropped_axis, second_cropped_axis,\n        third_cropped_axis)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "cropping",
        "default": [
          [
            1,
            1
          ],
          [
            1,
            1
          ],
          [
            1,
            1
          ]
        ]
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "Dense",
    "base": "Layer",
    "docstring": "Just your regular densely-connected NN layer.\n\n  `Dense` implements the operation:\n  `output = activation(dot(input, kernel) + bias)`\n  where `activation` is the element-wise activation function\n  passed as the `activation` argument, `kernel` is a weights matrix\n  created by the layer, and `bias` is a bias vector created by the layer\n  (only applicable if `use_bias` is `True`). These are all attributes of\n  `Dense`.\n\n  Note: If the input to the layer has a rank greater than 2, then `Dense`\n  computes the dot product between the `inputs` and the `kernel` along the\n  last axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\n  For example, if input has dimensions `(batch_size, d0, d1)`,\n  then we create a `kernel` with shape `(d1, units)`, and the `kernel` operates\n  along axis 2 of the `input`, on every sub-tensor of shape `(1, 1, d1)`\n  (there are `batch_size * d0` such sub-tensors).\n  The output in this case will have shape `(batch_size, d0, units)`.\n\n  Besides, layer attributes cannot be modified after the layer has been called\n  once (except the `trainable` attribute).\n  When a popular kwarg `input_shape` is passed, then keras will create\n  an input layer to insert before the current layer. This can be treated\n  equivalent to explicitly defining an `InputLayer`.\n\n  Example:\n\n  >>> # Create a `Sequential` model and add a Dense layer as the first layer.\n  >>> model = tf.keras.models.Sequential()\n  >>> model.add(tf.keras.Input(shape=(16,)))\n  >>> model.add(tf.keras.layers.Dense(32, activation='relu'))\n  >>> # Now the model will take as input arrays of shape (None, 16)\n  >>> # and output arrays of shape (None, 32).\n  >>> # Note that after the first layer, you don't need to specify\n  >>> # the size of the input anymore:\n  >>> model.add(tf.keras.layers.Dense(32))\n  >>> model.output_shape\n  (None, 32)\n\n  Args:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix.\n    bias_initializer: Initializer for the bias vector.\n    kernel_regularizer: Regularizer function applied to\n      the `kernel` weights matrix.\n    bias_regularizer: Regularizer function applied to the bias vector.\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its \"activation\").\n    kernel_constraint: Constraint function applied to\n      the `kernel` weights matrix.\n    bias_constraint: Constraint function applied to the bias vector.\n\n  Input shape:\n    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n    The most common situation would be\n    a 2D input with shape `(batch_size, input_dim)`.\n\n  Output shape:\n    N-D tensor with shape: `(batch_size, ..., units)`.\n    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n    the output would have shape `(batch_size, units)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "DenseFeatures",
    "base": "DenseFeatures",
    "docstring": "A layer that produces a dense `Tensor` based on given `feature_columns`.\n\n  Generally a single example in training data is described with FeatureColumns.\n  At the first layer of the model, this column oriented data should be converted\n  to a single `Tensor`.\n\n  This layer can be called multiple times with different features.\n\n  This is the V2 version of this layer that uses name_scopes to create\n  variables instead of variable_scopes. But this approach currently lacks\n  support for partitioned variables. In that case, use the V1 version instead.\n\n  Example:\n\n  ```python\n  price = tf.feature_column.numeric_column('price')\n  keywords_embedded = tf.feature_column.embedding_column(\n      tf.feature_column.categorical_column_with_hash_bucket(\"keywords\", 10K),\n      dimensions=16)\n  columns = [price, keywords_embedded, ...]\n  feature_layer = tf.keras.layers.DenseFeatures(columns)\n\n  features = tf.io.parse_example(\n      ..., features=tf.feature_column.make_parse_example_spec(columns))\n  dense_tensor = feature_layer(features)\n  for units in [128, 64, 32]:\n    dense_tensor = tf.keras.layers.Dense(units, activation='relu')(dense_tensor)\n  prediction = tf.keras.layers.Dense(1)(dense_tensor)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "feature_columns",
        "default": null
      },
      {
        "name": "trainable",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "name",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "features",
        "default": null
      },
      {
        "name": "cols_to_output_tensors",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/feature_column/dense_features_v2.py",
    "aliases": []
  },
  {
    "name": "DepthwiseConv2D",
    "base": "Conv2D",
    "docstring": "Depthwise 2D convolution.\n\n  Depthwise convolution is a type of convolution in which a single convolutional\n  filter is apply to each input channel (i.e. in a depthwise way).\n  You can understand depthwise convolution as being\n  the first step in a depthwise separable convolution.\n\n  It is implemented via the following steps:\n\n  - Split the input into individual channels.\n  - Convolve each input with the layer's kernel (called a depthwise kernel).\n  - Stack the convolved outputs together (along the channels axis).\n\n  Unlike a regular 2D convolution, depthwise convolution does not mix\n  information across different input channels.\n\n  The `depth_multiplier` argument controls how many\n  output channels are generated per input channel in the depthwise step.\n\n  Args:\n    kernel_size: An integer or tuple/list of 2 integers, specifying the\n      height and width of the 2D convolution window.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers,\n      specifying the strides of the convolution along the height and width.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n      Specifying any stride value != 1 is incompatible with specifying\n      any `dilation_rate` value != 1.\n    padding: one of `'valid'` or `'same'` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n      to the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    depth_multiplier: The number of depthwise convolution output channels\n      for each input channel.\n      The total number of depthwise convolution output\n      channels will be equal to `filters_in * depth_multiplier`.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be 'channels_last'.\n    dilation_rate: An integer or tuple/list of 2 integers, specifying\n      the dilation rate to use for dilated convolution.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any `strides` value != 1.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    depthwise_initializer: Initializer for the depthwise kernel matrix (\n      see `keras.initializers`). If None, the default initializer (\n      'glorot_uniform') will be used.\n    bias_initializer: Initializer for the bias vector (\n      see `keras.initializers`). If None, the default initializer (\n      'zeros') will bs used.\n    depthwise_regularizer: Regularizer function applied to\n      the depthwise kernel matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its 'activation') (\n      see `keras.regularizers`).\n    depthwise_constraint: Constraint function applied to\n      the depthwise kernel matrix (\n      see `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (\n      see `keras.constraints`).\n\n  Input shape:\n    4D tensor with shape:\n    `[batch_size, channels, rows, cols]` if data_format='channels_first'\n    or 4D tensor with shape:\n    `[batch_size, rows, cols, channels]` if data_format='channels_last'.\n\n  Output shape:\n    4D tensor with shape:\n    `[batch_size, channels * depth_multiplier, new_rows, new_cols]` if\n    data_format='channels_first' or 4D tensor with shape:\n    `[batch_size, new_rows, new_cols, channels * depth_multiplier]` if\n    data_format='channels_last'. `rows` and `cols` values might have\n    changed due to padding.\n\n  Returns:\n    A tensor of rank 4 representing\n    `activation(depthwiseconv2d(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is \"causal\".\n    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "depth_multiplier",
        "default": 1
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "depthwise_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "depthwise_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "depthwise_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "Discretization",
    "base": "PreprocessingLayer",
    "docstring": "Buckets data into discrete ranges.\n\n  This layer will place each element of its input data into one of several\n  contiguous ranges and output an integer index indicating which range each\n  element was placed in.\n\n  Input shape:\n    Any `tf.Tensor` or `tf.RaggedTensor` of dimension 2 or higher.\n\n  Output shape:\n    Same as input shape.\n\n  Attributes:\n    bin_boundaries: A list of bin boundaries. The leftmost and rightmost bins\n      will always extend to `-inf` and `inf`, so `bin_boundaries=[0., 1., 2.]`\n      generates bins `(-inf, 0.)`, `[0., 1.)`, `[1., 2.)`, and `[2., +inf)`. If\n      this option is set, `adapt` should not be called.\n    num_bins: The integer number of bins to compute. If this option is set,\n      `adapt` should be called to learn the bin boundaries.\n    epsilon: Error tolerance, typically a small fraction close to zero (e.g.\n      0.01). Higher values of epsilon increase the quantile approximation, and\n      hence result in more unequal buckets, but could improve performance\n      and resource consumption.\n\n  Examples:\n\n  Bucketize float values based on provided buckets.\n  >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n  >>> layer = tf.keras.layers.Discretization(bin_boundaries=[0., 1., 2.])\n  >>> layer(input)\n  <tf.Tensor: shape=(2, 4), dtype=int64, numpy=\n  array([[0, 2, 3, 1],\n         [1, 3, 2, 1]], dtype=int64)>\n\n  Bucketize float values based on a number of buckets to compute.\n  >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])\n  >>> layer = tf.keras.layers.Discretization(num_bins=4, epsilon=0.01)\n  >>> layer.adapt(input)\n  >>> layer(input)\n  <tf.Tensor: shape=(2, 4), dtype=int64, numpy=\n  array([[0, 2, 3, 2],\n         [1, 3, 3, 1]], dtype=int64)>\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "bin_boundaries",
        "default": "None"
      },
      {
        "name": "num_bins",
        "default": "None"
      },
      {
        "name": "epsilon",
        "default": 0.01
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/preprocessing/discretization.py",
    "aliases": []
  },
  {
    "name": "Dot",
    "base": "_Merge",
    "docstring": "Layer that computes a dot product between samples in two tensors.\n\n  E.g. if applied to a list of two tensors `a` and `b` of shape\n  `(batch_size, n)`, the output will be a tensor of shape `(batch_size, 1)`\n  where each entry `i` will be the dot product between\n  `a[i]` and `b[i]`.\n\n  >>> x = np.arange(10).reshape(1, 5, 2)\n  >>> print(x)\n  [[[0 1]\n    [2 3]\n    [4 5]\n    [6 7]\n    [8 9]]]\n  >>> y = np.arange(10, 20).reshape(1, 2, 5)\n  >>> print(y)\n  [[[10 11 12 13 14]\n    [15 16 17 18 19]]]\n  >>> tf.keras.layers.Dot(axes=(1, 2))([x, y])\n  <tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\n  array([[[260, 360],\n          [320, 445]]])>\n\n  >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n  >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n  >>> dotted = tf.keras.layers.Dot(axes=1)([x1, x2])\n  >>> dotted.shape\n  TensorShape([5, 1])\n\n\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "axes",
        "default": null
      },
      {
        "name": "normalize",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "Dropout",
    "base": "Layer",
    "docstring": "Applies Dropout to the input.\n\n  The Dropout layer randomly sets input units to 0 with a frequency of `rate`\n  at each step during training time, which helps prevent overfitting.\n  Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over\n  all inputs is unchanged.\n\n  Note that the Dropout layer only applies when `training` is set to True\n  such that no values are dropped during inference. When using `model.fit`,\n  `training` will be appropriately set to True automatically, and in other\n  contexts, you can set the kwarg explicitly to True when calling the layer.\n\n  (This is in contrast to setting `trainable=False` for a Dropout layer.\n  `trainable` does not affect the layer's behavior, as Dropout does\n  not have any variables/weights that can be frozen during training.)\n\n  >>> tf.random.set_seed(0)\n  >>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n  >>> data = np.arange(10).reshape(5, 2).astype(np.float32)\n  >>> print(data)\n  [[0. 1.]\n   [2. 3.]\n   [4. 5.]\n   [6. 7.]\n   [8. 9.]]\n  >>> outputs = layer(data, training=True)\n  >>> print(outputs)\n  tf.Tensor(\n  [[ 0.    1.25]\n   [ 2.5   3.75]\n   [ 5.    6.25]\n   [ 7.5   8.75]\n   [10.    0.  ]], shape=(5, 2), dtype=float32)\n\n  Args:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n    noise_shape: 1D integer tensor representing the shape of the\n      binary dropout mask that will be multiplied with the input.\n      For instance, if your inputs have shape\n      `(batch_size, timesteps, features)` and\n      you want the dropout mask to be the same for all timesteps,\n      you can use `noise_shape=(batch_size, 1, features)`.\n    seed: A Python integer to use as random seed.\n\n  Call arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      },
      {
        "name": "noise_shape",
        "default": "None"
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "ELU",
    "base": "Layer",
    "docstring": "Exponential Linear Unit.\n\n  It follows:\n\n  ```\n    f(x) =  alpha * (exp(x) - 1.) for x < 0\n    f(x) = x for x >= 0\n  ```\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as the input.\n\n  Args:\n    alpha: Scale for the negative factor.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "alpha",
        "default": 1.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/advanced_activations.py",
    "aliases": []
  },
  {
    "name": "Embedding",
    "base": "Layer",
    "docstring": "Turns positive integers (indexes) into dense vectors of fixed size.\n\n  e.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`\n\n  This layer can only be used as the first layer in a model.\n\n  Example:\n\n  >>> model = tf.keras.Sequential()\n  >>> model.add(tf.keras.layers.Embedding(1000, 64, input_length=10))\n  >>> # The model will take as input an integer matrix of size (batch,\n  >>> # input_length), and the largest integer (i.e. word index) in the input\n  >>> # should be no larger than 999 (vocabulary size).\n  >>> # Now model.output_shape is (None, 10, 64), where `None` is the batch\n  >>> # dimension.\n  >>> input_array = np.random.randint(1000, size=(32, 10))\n  >>> model.compile('rmsprop', 'mse')\n  >>> output_array = model.predict(input_array)\n  >>> print(output_array.shape)\n  (32, 10, 64)\n\n  Args:\n    input_dim: Integer. Size of the vocabulary,\n      i.e. maximum integer index + 1.\n    output_dim: Integer. Dimension of the dense embedding.\n    embeddings_initializer: Initializer for the `embeddings`\n      matrix (see `keras.initializers`).\n    embeddings_regularizer: Regularizer function applied to\n      the `embeddings` matrix (see `keras.regularizers`).\n    embeddings_constraint: Constraint function applied to\n      the `embeddings` matrix (see `keras.constraints`).\n    mask_zero: Boolean, whether or not the input value 0 is a special \"padding\"\n      value that should be masked out.\n      This is useful when using recurrent layers\n      which may take variable length input.\n      If this is `True`, then all subsequent layers\n      in the model need to support masking or an exception will be raised.\n      If mask_zero is set to True, as a consequence, index 0 cannot be\n      used in the vocabulary (input_dim should equal size of\n      vocabulary + 1).\n    input_length: Length of input sequences, when it is constant.\n      This argument is required if you are going to connect\n      `Flatten` then `Dense` layers upstream\n      (without it, the shape of the dense outputs cannot be computed).\n\n  Input shape:\n    2D tensor with shape: `(batch_size, input_length)`.\n\n  Output shape:\n    3D tensor with shape: `(batch_size, input_length, output_dim)`.\n\n  **Note on variable placement:**\n  By default, if a GPU is available, the embedding matrix will be placed on\n  the GPU. This achieves the best performance, but it might cause issues:\n\n  - You may be using an optimizer that does not support sparse GPU kernels.\n  In this case you will see an error upon training your model.\n  - Your embedding matrix may be too large to fit on your GPU. In this case\n  you will see an Out Of Memory (OOM) error.\n\n  In such cases, you should place the embedding matrix on the CPU memory.\n  You can do so with a device scope, as such:\n\n  ```python\n  with tf.device('cpu:0'):\n    embedding_layer = Embedding(...)\n    embedding_layer.build()\n  ```\n\n  The pre-built `embedding_layer` instance can then be added to a `Sequential`\n  model (e.g. `model.add(embedding_layer)`), called in a Functional model\n  (e.g. `x = embedding_layer(x)`), or used in a subclassed model.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "input_dim",
        "default": null
      },
      {
        "name": "output_dim",
        "default": null
      },
      {
        "name": "embeddings_initializer",
        "default": "uniform"
      },
      {
        "name": "embeddings_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "embeddings_constraint",
        "default": "None"
      },
      {
        "name": "mask_zero",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "input_length",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/embeddings.py",
    "aliases": []
  },
  {
    "name": "Flatten",
    "base": "Layer",
    "docstring": "Flattens the input. Does not affect the batch size.\n\n  Note: If inputs are shaped `(batch,)` without a feature axis, then\n  flattening adds an extra channel dimension and output shape is `(batch, 1)`.\n\n  Args:\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, ..., channels)` while `channels_first` corresponds to\n      inputs with shape `(batch, channels, ...)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Example:\n\n  >>> model = tf.keras.Sequential()\n  >>> model.add(tf.keras.layers.Conv2D(64, 3, 3, input_shape=(3, 32, 32)))\n  >>> model.output_shape\n  (None, 1, 10, 64)\n\n  >>> model.add(Flatten())\n  >>> model.output_shape\n  (None, 640)\n\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "GRU",
    "base": "DropoutRNNCellMixin",
    "docstring": "Gated Recurrent Unit - Cho et al. 2014.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  Based on available runtime hardware and constraints, this layer\n  will choose different implementations (cuDNN-based or pure-TensorFlow)\n  to maximize the performance. If a GPU is available and all\n  the arguments to the layer meet the requirement of the CuDNN kernel\n  (see below for details), the layer will use a fast cuDNN implementation.\n\n  The requirements to use the cuDNN implementation are:\n\n  1. `activation` == `tanh`\n  2. `recurrent_activation` == `sigmoid`\n  3. `recurrent_dropout` == 0\n  4. `unroll` is `False`\n  5. `use_bias` is `True`\n  6. `reset_after` is `True`\n  7. Inputs, if use masking, are strictly right-padded.\n  8. Eager execution is enabled in the outermost context.\n\n  There are two variants of the GRU implementation. The default one is based on\n  [v3](https://arxiv.org/abs/1406.1078v3) and has reset gate applied to hidden\n  state before matrix multiplication. The other one is based on\n  [original](https://arxiv.org/abs/1406.1078v1) and has the order reversed.\n\n  The second variant is compatible with CuDNNGRU (GPU-only) and allows\n  inference on CPU. Thus it has separate biases for `kernel` and\n  `recurrent_kernel`. To use this variant, set `'reset_after'=True` and\n  `recurrent_activation='sigmoid'`.\n\n  For example:\n\n  >>> inputs = tf.random.normal([32, 10, 8])\n  >>> gru = tf.keras.layers.GRU(4)\n  >>> output = gru(inputs)\n  >>> print(output.shape)\n  (32, 4)\n  >>> gru = tf.keras.layers.GRU(4, return_sequences=True, return_state=True)\n  >>> whole_sequence_output, final_state = gru(inputs)\n  >>> print(whole_sequence_output.shape)\n  (32, 10, 4)\n  >>> print(final_state.shape)\n  (32, 4)\n\n  Args:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n      Default: hyperbolic tangent (`tanh`).\n      If you pass `None`, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation function to use\n      for the recurrent step.\n      Default: sigmoid (`sigmoid`).\n      If you pass `None`, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n      used for the linear transformation of the inputs. Default:\n      `glorot_uniform`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n       weights matrix, used for the linear transformation of the recurrent\n       state. Default: `orthogonal`.\n    bias_initializer: Initializer for the bias vector. Default: `zeros`.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector. Default:\n      `None`.\n    activity_regularizer: Regularizer function applied to the output of the\n      layer (its \"activation\"). Default: `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector. Default:\n      `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the linear\n      transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state. Default: 0.\n    return_sequences: Boolean. Whether to return the last output\n      in the output sequence, or the full sequence. Default: `False`.\n    return_state: Boolean. Whether to return the last state in addition to the\n      output. Default: `False`.\n    go_backwards: Boolean (default `False`).\n      If True, process the input sequence backwards and return the\n      reversed sequence.\n    stateful: Boolean (default False). If True, the last state\n      for each sample at index i in a batch will be used as initial\n      state for the sample of index i in the following batch.\n    unroll: Boolean (default False).\n      If True, the network will be unrolled,\n      else a symbolic loop will be used.\n      Unrolling can speed-up a RNN,\n      although it tends to be more memory-intensive.\n      Unrolling is only suitable for short sequences.\n    time_major: The shape format of the `inputs` and `outputs` tensors.\n      If True, the inputs and outputs will be in shape\n      `[timesteps, batch, feature]`, whereas in the False case, it will be\n      `[batch, timesteps, feature]`. Using `time_major = True` is a bit more\n      efficient because it avoids transposes at the beginning and end of the\n      RNN calculation. However, most TensorFlow data is batch-major, so by\n      default this function accepts input and emits output in batch-major\n      form.\n    reset_after: GRU convention (whether to apply reset gate after or\n      before matrix multiplication). False = \"before\",\n      True = \"after\" (default and CuDNN compatible).\n\n  Call arguments:\n    inputs: A 3D tensor, with shape `[batch, timesteps, feature]`.\n    mask: Binary tensor of shape `[samples, timesteps]` indicating whether\n      a given timestep should be masked  (optional, defaults to `None`).\n      An individual `True` entry indicates that the corresponding timestep\n      should be utilized, while a `False` entry indicates that the\n      corresponding timestep should be ignored.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the cell\n      when calling it. This is only relevant if `dropout` or\n      `recurrent_dropout` is used  (optional, defaults to `None`).\n    initial_state: List of initial state tensors to be passed to the first\n      call of the cell  (optional, defaults to `None` which causes creation\n      of zero-filled initial state tensors).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "recurrent_activation",
        "default": "sigmoid"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      },
      {
        "name": "return_sequences",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "return_state",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "go_backwards",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "stateful",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "unroll",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "time_major",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "reset_after",
        "default": "True",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "initial_state",
        "default": "None"
      }
    ],
    "file": "keras/layers/recurrent_v2.py",
    "aliases": []
  },
  {
    "name": "GRUCell",
    "base": "GRUCell",
    "docstring": "Cell class for the GRU layer.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  This class processes one step within the whole time sequence input, whereas\n  `tf.keras.layer.GRU` processes the whole sequence.\n\n  For example:\n\n  >>> inputs = tf.random.normal([32, 10, 8])\n  >>> rnn = tf.keras.layers.RNN(tf.keras.layers.GRUCell(4))\n  >>> output = rnn(inputs)\n  >>> print(output.shape)\n  (32, 4)\n  >>> rnn = tf.keras.layers.RNN(\n  ...    tf.keras.layers.GRUCell(4),\n  ...    return_sequences=True,\n  ...    return_state=True)\n  >>> whole_sequence_output, final_state = rnn(inputs)\n  >>> print(whole_sequence_output.shape)\n  (32, 10, 4)\n  >>> print(final_state.shape)\n  (32, 4)\n\n  Args:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use. Default: hyperbolic tangent\n      (`tanh`). If you pass None, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation function to use for the recurrent step.\n      Default: sigmoid (`sigmoid`). If you pass `None`, no activation is\n      applied (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n      used for the linear transformation of the inputs. Default:\n      `glorot_uniform`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n      weights matrix, used for the linear transformation of the recurrent state.\n      Default: `orthogonal`.\n    bias_initializer: Initializer for the bias vector. Default: `zeros`.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector. Default:\n      `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector. Default:\n      `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n      linear transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state. Default: 0.\n    reset_after: GRU convention (whether to apply reset gate after or\n      before matrix multiplication). False = \"before\",\n      True = \"after\" (default and CuDNN compatible).\n\n  Call arguments:\n    inputs: A 2D tensor, with shape of `[batch, feature]`.\n    states: A 2D tensor with shape of `[batch, units]`, which is the state from\n      the previous time step. For timestep 0, the initial state provided by user\n      will be feed to cell.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. Only relevant when `dropout` or\n      `recurrent_dropout` is used.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "recurrent_activation",
        "default": "sigmoid"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      },
      {
        "name": "reset_after",
        "default": "True",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "states",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/recurrent_v2.py",
    "aliases": []
  },
  {
    "name": "GaussianDropout",
    "base": "Layer",
    "docstring": "Apply multiplicative 1-centered Gaussian noise.\n\n  As it is a regularization layer, it is only active at training time.\n\n  Args:\n    rate: Float, drop probability (as with `Dropout`).\n      The multiplicative noise will have\n      standard deviation `sqrt(rate / (1 - rate))`.\n\n  Call arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as input.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/noise.py",
    "aliases": []
  },
  {
    "name": "GaussianNoise",
    "base": "Layer",
    "docstring": "Apply additive zero-centered Gaussian noise.\n\n  This is useful to mitigate overfitting\n  (you could see it as a form of random data augmentation).\n  Gaussian Noise (GS) is a natural choice as corruption process\n  for real valued inputs.\n\n  As it is a regularization layer, it is only active at training time.\n\n  Args:\n    stddev: Float, standard deviation of the noise distribution.\n\n  Call arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding noise) or in inference mode (doing nothing).\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as input.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "stddev",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/noise.py",
    "aliases": []
  },
  {
    "name": "GlobalAveragePooling1D",
    "base": "GlobalPooling1D",
    "docstring": "Global average pooling operation for temporal data.\n\n  Examples:\n\n  >>> input_shape = (2, 3, 4)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.GlobalAveragePooling1D()(x)\n  >>> print(y.shape)\n  (2, 4)\n\n  Args:\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, steps, features)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, features, steps)`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n      If `keepdims` is `False` (default), the rank of the tensor is reduced\n      for spatial dimensions.\n      If `keepdims` is `True`, the temporal dimension are retained with\n      length 1.\n      The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\n  Call arguments:\n    inputs: A 3D tensor.\n    mask: Binary tensor of shape `(batch_size, steps)` indicating whether\n      a given step should be masked (excluded from the average).\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      3D tensor with shape:\n      `(batch_size, steps, features)`\n    - If `data_format='channels_first'`:\n      3D tensor with shape:\n      `(batch_size, features, steps)`\n\n  Output shape:\n    - If `keepdims`=False:\n      2D tensor with shape `(batch_size, features)`.\n    - If `keepdims`=True:\n      - If `data_format='channels_last'`:\n        3D tensor with shape `(batch_size, 1, features)`\n      - If `data_format='channels_first'`:\n        3D tensor with shape `(batch_size, features, 1)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "channels_last"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "keras/layers/pooling.py",
    "aliases": [
      "GlobalAvgPool1D"
    ]
  },
  {
    "name": "GlobalAveragePooling2D",
    "base": "GlobalPooling2D",
    "docstring": "Global average pooling operation for spatial data.\n\n  Examples:\n\n  >>> input_shape = (2, 4, 5, 3)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.GlobalAveragePooling2D()(x)\n  >>> print(y.shape)\n  (2, 3)\n\n  Args:\n      data_format: A string,\n        one of `channels_last` (default) or `channels_first`.\n        The ordering of the dimensions in the inputs.\n        `channels_last` corresponds to inputs with shape\n        `(batch, height, width, channels)` while `channels_first`\n        corresponds to inputs with shape\n        `(batch, channels, height, width)`.\n        It defaults to the `image_data_format` value found in your\n        Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\".\n      keepdims: A boolean, whether to keep the spatial dimensions or not.\n        If `keepdims` is `False` (default), the rank of the tensor is reduced\n        for spatial dimensions.\n        If `keepdims` is `True`, the spatial dimensions are retained with\n        length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      4D tensor with shape `(batch_size, rows, cols, channels)`.\n    - If `data_format='channels_first'`:\n      4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n  Output shape:\n    - If `keepdims`=False:\n      2D tensor with shape `(batch_size, channels)`.\n    - If `keepdims`=True:\n      - If `data_format='channels_last'`:\n        4D tensor with shape `(batch_size, 1, 1, channels)`\n      - If `data_format='channels_first'`:\n        4D tensor with shape `(batch_size, channels, 1, 1)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "keepdims",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/pooling.py",
    "aliases": [
      "GlobalAvgPool2D"
    ]
  },
  {
    "name": "GlobalAveragePooling3D",
    "base": "GlobalPooling3D",
    "docstring": "Global Average pooling operation for 3D data.\n\n  Args:\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n    keepdims: A boolean, whether to keep the spatial dimensions or not.\n      If `keepdims` is `False` (default), the rank of the tensor is reduced\n      for spatial dimensions.\n      If `keepdims` is `True`, the spatial dimensions are retained with\n      length 1.\n      The behavior is the same as for `tf.reduce_mean` or `np.mean`.\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      5D tensor with shape:\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n      5D tensor with shape:\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\n  Output shape:\n    - If `keepdims`=False:\n      2D tensor with shape `(batch_size, channels)`.\n    - If `keepdims`=True:\n      - If `data_format='channels_last'`:\n        5D tensor with shape `(batch_size, 1, 1, 1, channels)`\n      - If `data_format='channels_first'`:\n        5D tensor with shape `(batch_size, channels, 1, 1, 1)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "keepdims",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/pooling.py",
    "aliases": [
      "GlobalAvgPool3D"
    ]
  },
  {
    "name": "GlobalMaxPooling1D",
    "base": "GlobalPooling1D",
    "docstring": "Global max pooling operation for 1D temporal data.\n\n  Downsamples the input representation by taking the maximum value over\n  the time dimension.\n\n  For example:\n\n  >>> x = tf.constant([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])\n  >>> x = tf.reshape(x, [3, 3, 1])\n  >>> x\n  <tf.Tensor: shape=(3, 3, 1), dtype=float32, numpy=\n  array([[[1.], [2.], [3.]],\n         [[4.], [5.], [6.]],\n         [[7.], [8.], [9.]]], dtype=float32)>\n  >>> max_pool_1d = tf.keras.layers.GlobalMaxPooling1D()\n  >>> max_pool_1d(x)\n  <tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n  array([[3.],\n         [6.],\n         [9.], dtype=float32)>\n\n  Args:\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, steps, features)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, features, steps)`.\n    keepdims: A boolean, whether to keep the temporal dimension or not.\n      If `keepdims` is `False` (default), the rank of the tensor is reduced\n      for spatial dimensions.\n      If `keepdims` is `True`, the temporal dimension are retained with\n      length 1.\n      The behavior is the same as for `tf.reduce_max` or `np.max`.\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      3D tensor with shape:\n      `(batch_size, steps, features)`\n    - If `data_format='channels_first'`:\n      3D tensor with shape:\n      `(batch_size, features, steps)`\n\n  Output shape:\n    - If `keepdims`=False:\n      2D tensor with shape `(batch_size, features)`.\n    - If `keepdims`=True:\n      - If `data_format='channels_last'`:\n        3D tensor with shape `(batch_size, 1, features)`\n      - If `data_format='channels_first'`:\n        3D tensor with shape `(batch_size, features, 1)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "channels_last"
      },
      {
        "name": "keepdims",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/pooling.py",
    "aliases": [
      "GlobalMaxPool1D"
    ]
  },
  {
    "name": "GlobalMaxPooling2D",
    "base": "GlobalPooling2D",
    "docstring": "Global max pooling operation for spatial data.\n\n  Examples:\n\n  >>> input_shape = (2, 4, 5, 3)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.GlobalMaxPool2D()(x)\n  >>> print(y.shape)\n  (2, 3)\n\n  Args:\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n    keepdims: A boolean, whether to keep the spatial dimensions or not.\n      If `keepdims` is `False` (default), the rank of the tensor is reduced\n      for spatial dimensions.\n      If `keepdims` is `True`, the spatial dimensions are retained with\n      length 1.\n      The behavior is the same as for `tf.reduce_max` or `np.max`.\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      4D tensor with shape `(batch_size, rows, cols, channels)`.\n    - If `data_format='channels_first'`:\n      4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n  Output shape:\n    - If `keepdims`=False:\n      2D tensor with shape `(batch_size, channels)`.\n    - If `keepdims`=True:\n      - If `data_format='channels_last'`:\n        4D tensor with shape `(batch_size, 1, 1, channels)`\n      - If `data_format='channels_first'`:\n        4D tensor with shape `(batch_size, channels, 1, 1)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "keepdims",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/pooling.py",
    "aliases": [
      "GlobalMaxPool2D"
    ]
  },
  {
    "name": "GlobalMaxPooling3D",
    "base": "GlobalPooling3D",
    "docstring": "Global Max pooling operation for 3D data.\n\n  Args:\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n    keepdims: A boolean, whether to keep the spatial dimensions or not.\n      If `keepdims` is `False` (default), the rank of the tensor is reduced\n      for spatial dimensions.\n      If `keepdims` is `True`, the spatial dimensions are retained with\n      length 1.\n      The behavior is the same as for `tf.reduce_max` or `np.max`.\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      5D tensor with shape:\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n      5D tensor with shape:\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\n  Output shape:\n    - If `keepdims`=False:\n      2D tensor with shape `(batch_size, channels)`.\n    - If `keepdims`=True:\n      - If `data_format='channels_last'`:\n        5D tensor with shape `(batch_size, 1, 1, 1, channels)`\n      - If `data_format='channels_first'`:\n        5D tensor with shape `(batch_size, channels, 1, 1, 1)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "keepdims",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/pooling.py",
    "aliases": [
      "GlobalMaxPool3D"
    ]
  },
  {
    "name": "Hashing",
    "base": "Layer",
    "docstring": "Implements categorical feature hashing, also known as \"hashing trick\".\n\n  This layer transforms single or multiple categorical inputs to hashed output.\n  It converts a sequence of int or string to a sequence of int. The stable hash\n  function uses `tensorflow::ops::Fingerprint` to produce the same output\n  consistently across all platforms.\n\n  This layer uses [FarmHash64](https://github.com/google/farmhash) by default,\n  which provides a consistent hashed output across different platforms and is\n  stable across invocations, regardless of device and context, by mixing the\n  input bits thoroughly.\n\n  If you want to obfuscate the hashed output, you can also pass a random `salt`\n  argument in the constructor. In that case, the layer will use the\n  [SipHash64](https://github.com/google/highwayhash) hash function, with\n  the `salt` value serving as additional input to the hash function.\n\n  **Example (FarmHash64)**\n\n  >>> layer = tf.keras.layers.Hashing(num_bins=3)\n  >>> inp = [['A'], ['B'], ['C'], ['D'], ['E']]\n  >>> layer(inp)\n  <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n    array([[1],\n           [0],\n           [1],\n           [1],\n           [2]])>\n\n  **Example (FarmHash64) with a mask value**\n\n  >>> layer = tf.keras.layers.Hashing(num_bins=3, mask_value='')\n  >>> inp = [['A'], ['B'], [''], ['C'], ['D']]\n  >>> layer(inp)\n  <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n    array([[1],\n           [1],\n           [0],\n           [2],\n           [2]])>\n\n  **Example (SipHash64)**\n\n  >>> layer = tf.keras.layers.Hashing(num_bins=3, salt=[133, 137])\n  >>> inp = [['A'], ['B'], ['C'], ['D'], ['E']]\n  >>> layer(inp)\n  <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n    array([[1],\n           [2],\n           [1],\n           [0],\n           [2]])>\n\n  **Example (Siphash64 with a single integer, same as `salt=[133, 133]`)**\n\n  >>> layer = tf.keras.layers.Hashing(num_bins=3, salt=133)\n  >>> inp = [['A'], ['B'], ['C'], ['D'], ['E']]\n  >>> layer(inp)\n  <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n    array([[0],\n           [0],\n           [2],\n           [1],\n           [0]])>\n\n  Args:\n    num_bins: Number of hash bins. Note that this includes the `mask_value` bin,\n      so the effective number of bins is `(num_bins - 1)` if `mask_value` is\n      set.\n    mask_value: A value that represents masked inputs, which are mapped to\n      index 0. Defaults to None, meaning no mask term will be added and the\n      hashing will start at index 0.\n    salt: A single unsigned integer or None.\n      If passed, the hash function used will be SipHash64, with these values\n      used as an additional input (known as a \"salt\" in cryptography).\n      These should be non-zero. Defaults to `None` (in that\n      case, the FarmHash64 hash function is used). It also supports\n      tuple/list of 2 unsigned integer numbers, see reference paper for details.\n    **kwargs: Keyword arguments to construct a layer.\n\n  Input shape:\n    A single or list of string, int32 or int64 `Tensor`,\n    `SparseTensor` or `RaggedTensor` of shape `(batch_size, ...,)`\n\n  Output shape:\n    An int64 `Tensor`, `SparseTensor` or `RaggedTensor` of shape\n    `(batch_size, ...)`. If any input is `RaggedTensor` then output is\n    `RaggedTensor`, otherwise if any input is `SparseTensor` then output is\n    `SparseTensor`, otherwise the output is `Tensor`.\n\n  Reference:\n    - [SipHash with salt](https://www.131002.net/siphash/siphash.pdf)\n\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "num_bins",
        "default": null
      },
      {
        "name": "mask_value",
        "default": "None"
      },
      {
        "name": "salt",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/preprocessing/hashing.py",
    "aliases": []
  },
  {
    "name": "IntegerLookup",
    "base": "IndexLookup",
    "docstring": "Reindex integer inputs to be in a contiguous range, via a dict lookup.\n\n  This layer maps a set of arbitrary integer input tokens into indexed\n  integer output via a table-based vocabulary lookup. The layer's output indices\n  will be contiguously arranged up to the maximum vocab size, even if the input\n  tokens are non-continguous or unbounded. The layer supports multiple options\n  for encoding the output via `output_mode`, and has optional support for\n  out-of-vocabulary (OOV) tokens and masking.\n\n  The vocabulary for the layer can be supplied on construction or learned via\n  `adapt()`. During `adapt()`, the layer will analyze a data set, determine the\n  frequency of individual integer tokens, and create a vocabulary from them. If\n  the vocabulary is capped in size, the most frequent tokens will be used to\n  create the vocabulary and all others will be treated as OOV.\n\n  There are two possible output modes for the layer.\n  When `output_mode` is `\"int\"`,\n  input integers are converted to their index in the vocabulary (an integer).\n  When `output_mode` is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`, input integers\n  are encoded into an array where each dimension corresponds to an element in\n  the vocabulary.\n\n  The vocabulary can optionally contain a mask token as well as an OOV token\n  (which can optionally occupy multiple indices in the vocabulary, as set\n  by `num_oov_indices`).\n  The position of these tokens in the vocabulary is fixed. When `output_mode` is\n  `\"int\"`, the vocabulary will begin with the mask token at index 0, followed by\n  OOV indices, followed by the rest of the vocabulary. When `output_mode` is\n  `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"` the vocabulary will begin with OOV\n  indices and instances of the mask token will be dropped.\n\n  Args:\n    max_tokens: The maximum size of the vocabulary for this layer. If None,\n      there is no cap on the size of the vocabulary. Note that this size\n      includes the OOV and mask tokens. Default to None.\n    num_oov_indices: The number of out-of-vocabulary tokens to use. If this\n      value is more than 1, OOV inputs are modulated to determine their OOV\n      value. If this value is 0, OOV inputs will cause an error when calling the\n      layer. Defaults to 1.\n    mask_token: An integer token that represents masked inputs. When\n      `output_mode` is `\"int\"`, the token is included in vocabulary and mapped\n      to index 0. In other output modes, the token will not appear in the\n      vocabulary and instances of the mask token in the input will be dropped.\n      If set to None, no mask term will be added. Defaults to None.\n    oov_token: Only used when `invert` is True. The token to return for OOV\n      indices. Defaults to -1.\n    vocabulary: Optional. Either an array of integers or a string path to a text\n      file. If passing an array, can pass a tuple, list, 1D numpy array, or 1D\n      tensor containing the integer vocbulary terms. If passing a file path, the\n      file should contain one line per term in the vocabulary. If this argument\n      is set, there is no need to `adapt` the layer.\n    invert: Only valid when `output_mode` is `\"int\"`. If True, this layer will\n      map indices to vocabulary items instead of mapping vocabulary items to\n      indices. Default to False.\n    output_mode: Specification for the output of the layer. Defaults to `\"int\"`.\n      Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, `\"count\"`, or\n      `\"tf_idf\"` configuring the layer as follows:\n        - `\"int\"`: Return the vocabulary indices of the input tokens.\n        - `\"one_hot\"`: Encodes each individual element in the input into an\n          array the same size as the vocabulary, containing a 1 at the element\n          index. If the last dimension is size 1, will encode on that dimension.\n          If the last dimension is not size 1, will append a new dimension for\n          the encoded output.\n        - `\"multi_hot\"`: Encodes each sample in the input into a single array\n          the same size as the vocabulary, containing a 1 for each vocabulary\n          term present in the sample. Treats the last dimension as the sample\n          dimension, if input shape is (..., sample_length), output shape will\n          be (..., num_tokens).\n        - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of the\n          number of times the token at that index appeared in the sample.\n        - `\"tf_idf\"`: As `\"multi_hot\"`, but the TF-IDF algorithm is applied to\n          find the value in each token slot.\n      For `\"int\"` output, any shape of input and output is supported. For all\n      other output modes, currently only output up to rank 2 is supported.\n    pad_to_max_tokens: Only applicable when `output_mode` is `\"multi_hot\"`,\n      `\"count\"`, or `\"tf_idf\"`. If True, the output will have its feature axis\n      padded to `max_tokens` even if the number of unique tokens in the\n      vocabulary is less than max_tokens, resulting in a tensor of shape\n      [batch_size, max_tokens] regardless of vocabulary size. Defaults to False.\n    sparse: Boolean. Only applicable when `output_mode` is `\"multi_hot\"`,\n      `\"count\"`, or `\"tf_idf\"`. If True, returns a `SparseTensor` instead of a\n      dense `Tensor`. Defaults to False.\n\n  Examples:\n\n  **Creating a lookup layer with a known vocabulary**\n\n  This example creates a lookup layer with a pre-existing vocabulary.\n\n  >>> vocab = [12, 36, 1138, 42]\n  >>> data = tf.constant([[12, 1138, 42], [42, 1000, 36]])  # Note OOV tokens\n  >>> layer = tf.keras.layers.IntegerLookup(vocabulary=vocab)\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n  array([[1, 3, 4],\n         [4, 0, 2]])>\n\n  **Creating a lookup layer with an adapted vocabulary**\n\n  This example creates a lookup layer and generates the vocabulary by analyzing\n  the dataset.\n\n  >>> data = tf.constant([[12, 1138, 42], [42, 1000, 36]])\n  >>> layer = tf.keras.layers.IntegerLookup()\n  >>> layer.adapt(data)\n  >>> layer.get_vocabulary()\n  [-1, 42, 1138, 1000, 36, 12]\n\n  Note that the OOV token -1 have been added to the vocabulary. The remaining\n  tokens are sorted by frequency (42, which has 2 occurrences, is first) then\n  by inverse sort order.\n\n  >>> data = tf.constant([[12, 1138, 42], [42, 1000, 36]])\n  >>> layer = tf.keras.layers.IntegerLookup()\n  >>> layer.adapt(data)\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n  array([[5, 2, 1],\n         [1, 3, 4]])>\n\n\n  **Lookups with multiple OOV indices**\n\n  This example demonstrates how to use a lookup layer with multiple OOV indices.\n  When a layer is created with more than one OOV index, any OOV tokens are\n  hashed into the number of OOV buckets, distributing OOV tokens in a\n  deterministic fashion across the set.\n\n  >>> vocab = [12, 36, 1138, 42]\n  >>> data = tf.constant([[12, 1138, 42], [37, 1000, 36]])\n  >>> layer = tf.keras.layers.IntegerLookup(vocabulary=vocab, num_oov_indices=2)\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n  array([[2, 4, 5],\n         [1, 0, 3]])>\n\n  Note that the output for OOV token 37 is 1, while the output for OOV token\n  1000 is 0. The in-vocab terms have their output index increased by 1 from\n  earlier examples (12 maps to 2, etc) in order to make space for the extra OOV\n  token.\n\n  **One-hot output**\n\n  Configure the layer with `output_mode='one_hot'`. Note that the first\n  `num_oov_indices` dimensions in the ont_hot encoding represent OOV values.\n\n  >>> vocab = [12, 36, 1138, 42]\n  >>> data = tf.constant([12, 36, 1138, 42, 7]) # Note OOV tokens\n  >>> layer = tf.keras.layers.IntegerLookup(\n  ...     vocabulary=vocab, output_mode='one_hot')\n  >>> layer(data)\n  <tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n    array([[0., 1., 0., 0., 0.],\n           [0., 0., 1., 0., 0.],\n           [0., 0., 0., 1., 0.],\n           [0., 0., 0., 0., 1.],\n           [1., 0., 0., 0., 0.]], dtype=float32)>\n\n  **Multi-hot output**\n\n  Configure the layer with `output_mode='multi_hot'`. Note that the first\n  `num_oov_indices` dimensions in the multi_hot encoding represent OOV tokens\n\n  >>> vocab = [12, 36, 1138, 42]\n  >>> data = tf.constant([[12, 1138, 42, 42], [42, 7, 36, 7]]) # Note OOV tokens\n  >>> layer = tf.keras.layers.IntegerLookup(\n  ...     vocabulary=vocab, output_mode='multi_hot')\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n    array([[0., 1., 0., 1., 1.],\n           [1., 0., 1., 0., 1.]], dtype=float32)>\n\n  **Token count output**\n\n  Configure the layer with `output_mode='count'`. As with multi_hot output, the\n  first `num_oov_indices` dimensions in the output represent OOV tokens.\n\n  >>> vocab = [12, 36, 1138, 42]\n  >>> data = tf.constant([[12, 1138, 42, 42], [42, 7, 36, 7]]) # Note OOV tokens\n  >>> layer = tf.keras.layers.IntegerLookup(\n  ...     vocabulary=vocab, output_mode='count')\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n    array([[0., 1., 0., 1., 2.],\n           [2., 0., 1., 0., 1.]], dtype=float32)>\n\n  **TF-IDF output**\n\n  Configure the layer with `output_mode='tf_idf'`. As with multi_hot output, the\n  first `num_oov_indices` dimensions in the output represent OOV tokens.\n\n  Each token bin will output `token_count * idf_weight`, where the idf weights\n  are the inverse document frequency weights per token. These should be provided\n  along with the vocabulary. Note that the `idf_weight` for OOV tokens will\n  default to the average of all idf weights passed in.\n\n  >>> vocab = [12, 36, 1138, 42]\n  >>> idf_weights = [0.25, 0.75, 0.6, 0.4]\n  >>> data = tf.constant([[12, 1138, 42, 42], [42, 7, 36, 7]]) # Note OOV tokens\n  >>> layer = tf.keras.layers.IntegerLookup(output_mode='tf_idf')\n  >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n           [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)>\n\n  To specify the idf weights for oov tokens, you will need to pass the entire\n  vocabularly including the leading oov token.\n\n  >>> vocab = [-1, 12, 36, 1138, 42]\n  >>> idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]\n  >>> data = tf.constant([[12, 1138, 42, 42], [42, 7, 36, 7]]) # Note OOV tokens\n  >>> layer = tf.keras.layers.IntegerLookup(output_mode='tf_idf')\n  >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n           [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)>\n\n  When adapting the layer in tf_idf mode, each input sample will be considered a\n  document, and idf weight per token will be calculated as\n  `log(1 + num_documents / (1 + token_document_count))`.\n\n  **Inverse lookup**\n\n  This example demonstrates how to map indices to tokens using this layer. (You\n  can also use `adapt()` with `inverse=True`, but for simplicity we'll pass the\n  vocab in this example.)\n\n  >>> vocab = [12, 36, 1138, 42]\n  >>> data = tf.constant([[1, 3, 4], [4, 0, 2]])\n  >>> layer = tf.keras.layers.IntegerLookup(vocabulary=vocab, invert=True)\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n  array([[  12, 1138,   42],\n         [  42,   -1,   36]])>\n\n  Note that the first index correspond to the oov token by default.\n\n\n  **Forward and inverse lookup pairs**\n\n  This example demonstrates how to use the vocabulary of a standard lookup\n  layer to create an inverse lookup layer.\n\n  >>> vocab = [12, 36, 1138, 42]\n  >>> data = tf.constant([[12, 1138, 42], [42, 1000, 36]])\n  >>> layer = tf.keras.layers.IntegerLookup(vocabulary=vocab)\n  >>> i_layer = tf.keras.layers.IntegerLookup(\n  ...     vocabulary=layer.get_vocabulary(), invert=True)\n  >>> int_data = layer(data)\n  >>> i_layer(int_data)\n  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n  array([[  12, 1138,   42],\n         [  42,   -1,   36]])>\n\n  In this example, the input token 1000 resulted in an output of -1, since\n  1000 was not in the vocabulary - it got represented as an OOV, and all OOV\n  tokens are returned as -1 in the inverse layer. Also, note that for the\n  inverse to work, you must have already set the forward layer vocabulary\n  either directly or via `adapt()` before calling `get_vocabulary()`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "max_tokens",
        "default": "None"
      },
      {
        "name": "num_oov_indices",
        "default": 1
      },
      {
        "name": "mask_token",
        "default": "None"
      },
      {
        "name": "oov_token",
        "default": -1
      },
      {
        "name": "vocabulary",
        "default": "None"
      },
      {
        "name": "invert",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "output_mode",
        "default": "int"
      },
      {
        "name": "sparse",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "pad_to_max_tokens",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/preprocessing/integer_lookup.py",
    "aliases": []
  },
  {
    "name": "LSTM",
    "base": "DropoutRNNCellMixin",
    "docstring": "Long Short-Term Memory layer - Hochreiter 1997.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  Based on available runtime hardware and constraints, this layer\n  will choose different implementations (cuDNN-based or pure-TensorFlow)\n  to maximize the performance. If a GPU is available and all\n  the arguments to the layer meet the requirement of the CuDNN kernel\n  (see below for details), the layer will use a fast cuDNN implementation.\n\n  The requirements to use the cuDNN implementation are:\n\n  1. `activation` == `tanh`\n  2. `recurrent_activation` == `sigmoid`\n  3. `recurrent_dropout` == 0\n  4. `unroll` is `False`\n  5. `use_bias` is `True`\n  6. Inputs, if use masking, are strictly right-padded.\n  7. Eager execution is enabled in the outermost context.\n\n  For example:\n\n  >>> inputs = tf.random.normal([32, 10, 8])\n  >>> lstm = tf.keras.layers.LSTM(4)\n  >>> output = lstm(inputs)\n  >>> print(output.shape)\n  (32, 4)\n  >>> lstm = tf.keras.layers.LSTM(4, return_sequences=True, return_state=True)\n  >>> whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n  >>> print(whole_seq_output.shape)\n  (32, 10, 4)\n  >>> print(final_memory_state.shape)\n  (32, 4)\n  >>> print(final_carry_state.shape)\n  (32, 4)\n\n  Args:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n      Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation\n      is applied (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation function to use for the recurrent step.\n      Default: sigmoid (`sigmoid`). If you pass `None`, no activation is\n      applied (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean (default `True`), whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix, used for\n      the linear transformation of the inputs. Default: `glorot_uniform`.\n    recurrent_initializer: Initializer for the `recurrent_kernel` weights\n      matrix, used for the linear transformation of the recurrent state.\n      Default: `orthogonal`.\n    bias_initializer: Initializer for the bias vector. Default: `zeros`.\n    unit_forget_bias: Boolean (default `True`). If True, add 1 to the bias of\n      the forget gate at initialization. Setting it to true will also force\n      `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et\n          al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector. Default:\n      `None`.\n    activity_regularizer: Regularizer function applied to the output of the\n      layer (its \"activation\"). Default: `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector. Default:\n      `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the linear\n      transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state. Default: 0.\n    return_sequences: Boolean. Whether to return the last output. in the output\n      sequence, or the full sequence. Default: `False`.\n    return_state: Boolean. Whether to return the last state in addition to the\n      output. Default: `False`.\n    go_backwards: Boolean (default `False`). If True, process the input sequence\n      backwards and return the reversed sequence.\n    stateful: Boolean (default `False`). If True, the last state for each sample\n      at index i in a batch will be used as initial state for the sample of\n      index i in the following batch.\n    time_major: The shape format of the `inputs` and `outputs` tensors.\n      If True, the inputs and outputs will be in shape\n      `[timesteps, batch, feature]`, whereas in the False case, it will be\n      `[batch, timesteps, feature]`. Using `time_major = True` is a bit more\n      efficient because it avoids transposes at the beginning and end of the\n      RNN calculation. However, most TensorFlow data is batch-major, so by\n      default this function accepts input and emits output in batch-major\n      form.\n    unroll: Boolean (default `False`). If True, the network will be unrolled,\n      else a symbolic loop will be used. Unrolling can speed-up a RNN, although\n      it tends to be more memory-intensive. Unrolling is only suitable for short\n      sequences.\n\n  Call arguments:\n    inputs: A 3D tensor with shape `[batch, timesteps, feature]`.\n    mask: Binary tensor of shape `[batch, timesteps]` indicating whether\n      a given timestep should be masked (optional, defaults to `None`).\n      An individual `True` entry indicates that the corresponding timestep\n      should be utilized, while a `False` entry indicates that the corresponding\n      timestep should be ignored.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the cell\n      when calling it. This is only relevant if `dropout` or\n      `recurrent_dropout` is used (optional, defaults to `None`).\n    initial_state: List of initial state tensors to be passed to the first\n      call of the cell (optional, defaults to `None` which causes creation\n      of zero-filled initial state tensors).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "recurrent_activation",
        "default": "sigmoid"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "unit_forget_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      },
      {
        "name": "return_sequences",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "return_state",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "go_backwards",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "stateful",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "time_major",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "unroll",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "initial_state",
        "default": "None"
      }
    ],
    "file": "keras/layers/recurrent_v2.py",
    "aliases": []
  },
  {
    "name": "LSTMCell",
    "base": "LSTMCell",
    "docstring": "Cell class for the LSTM layer.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  This class processes one step within the whole time sequence input, whereas\n  `tf.keras.layer.LSTM` processes the whole sequence.\n\n  For example:\n\n  >>> inputs = tf.random.normal([32, 10, 8])\n  >>> rnn = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(4))\n  >>> output = rnn(inputs)\n  >>> print(output.shape)\n  (32, 4)\n  >>> rnn = tf.keras.layers.RNN(\n  ...    tf.keras.layers.LSTMCell(4),\n  ...    return_sequences=True,\n  ...    return_state=True)\n  >>> whole_seq_output, final_memory_state, final_carry_state = rnn(inputs)\n  >>> print(whole_seq_output.shape)\n  (32, 10, 4)\n  >>> print(final_memory_state.shape)\n  (32, 4)\n  >>> print(final_carry_state.shape)\n  (32, 4)\n\n  Args:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use. Default: hyperbolic tangent\n      (`tanh`). If you pass `None`, no activation is applied (ie. \"linear\"\n      activation: `a(x) = x`).\n    recurrent_activation: Activation function to use for the recurrent step.\n      Default: sigmoid (`sigmoid`). If you pass `None`, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix, used for\n      the linear transformation of the inputs. Default: `glorot_uniform`.\n    recurrent_initializer: Initializer for the `recurrent_kernel` weights\n      matrix, used for the linear transformation of the recurrent state.\n      Default: `orthogonal`.\n    bias_initializer: Initializer for the bias vector. Default: `zeros`.\n    unit_forget_bias: Boolean (default `True`). If True, add 1 to the bias of\n      the forget gate at initialization. Setting it to true will also force\n      `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et\n        al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to\n      the `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector. Default:\n      `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector. Default:\n      `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the linear\n      transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state. Default: 0.\n\n  Call arguments:\n    inputs: A 2D tensor, with shape of `[batch, feature]`.\n    states: List of 2 tensors that corresponding to the cell's units. Both of\n      them have shape `[batch, units]`, the first tensor is the memory state\n      from previous time step, the second tensor is the carry state from\n      previous time step. For timestep 0, the initial state provided by user\n      will be feed to cell.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. Only relevant when `dropout` or\n      `recurrent_dropout` is used.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "recurrent_activation",
        "default": "sigmoid"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "unit_forget_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "states",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/recurrent_v2.py",
    "aliases": []
  },
  {
    "name": "Lambda",
    "base": "Layer",
    "docstring": "Wraps arbitrary expressions as a `Layer` object.\n\n  The `Lambda` layer exists so that arbitrary expressions can be used\n  as a `Layer` when constructing `Sequential`\n  and Functional API models. `Lambda` layers are best suited for simple\n  operations or quick experimentation. For more advanced use cases, follow\n  [this guide](https://www.tensorflow.org/guide/keras/custom_layers_and_models)\n  for subclassing `tf.keras.layers.Layer`.\n\n  WARNING: `tf.keras.layers.Lambda` layers have (de)serialization limitations!\n\n  The main reason to subclass `tf.keras.layers.Layer` instead of using a\n  `Lambda` layer is saving and inspecting a Model. `Lambda` layers\n  are saved by serializing the Python bytecode, which is fundamentally\n  non-portable. They should only be loaded in the same environment where\n  they were saved. Subclassed layers can be saved in a more portable way\n  by overriding their `get_config` method. Models that rely on\n  subclassed Layers are also often easier to visualize and reason about.\n\n  Examples:\n\n  ```python\n  # add a x -> x^2 layer\n  model.add(Lambda(lambda x: x ** 2))\n  ```\n  ```python\n  # add a layer that returns the concatenation\n  # of the positive part of the input and\n  # the opposite of the negative part\n\n  def antirectifier(x):\n      x -= K.mean(x, axis=1, keepdims=True)\n      x = K.l2_normalize(x, axis=1)\n      pos = K.relu(x)\n      neg = K.relu(-x)\n      return K.concatenate([pos, neg], axis=1)\n\n  model.add(Lambda(antirectifier))\n  ```\n\n  Variables:\n    While it is possible to use Variables with Lambda layers, this practice is\n    discouraged as it can easily lead to bugs. For instance, consider the\n    following layer:\n\n    ```python\n      scale = tf.Variable(1.)\n      scale_layer = tf.keras.layers.Lambda(lambda x: x * scale)\n    ```\n\n    Because scale_layer does not directly track the `scale` variable, it will\n    not appear in `scale_layer.trainable_weights` and will therefore not be\n    trained if `scale_layer` is used in a Model.\n\n    A better pattern is to write a subclassed Layer:\n\n    ```python\n      class ScaleLayer(tf.keras.layers.Layer):\n        def __init__(self):\n          super(ScaleLayer, self).__init__()\n          self.scale = tf.Variable(1.)\n\n        def call(self, inputs):\n          return inputs * self.scale\n    ```\n\n    In general, Lambda layers can be convenient for simple stateless\n    computation, but anything more complex should use a subclass Layer instead.\n\n  Args:\n    function: The function to be evaluated. Takes input tensor as first\n      argument.\n    output_shape: Expected output shape from function. This argument can be\n      inferred if not explicitly provided. Can be a tuple or function. If a\n      tuple, it only specifies the first dimension onward;\n      sample dimension is assumed either the same as the input: `output_shape =\n        (input_shape[0], ) + output_shape` or, the input is `None` and\n      the sample dimension is also `None`: `output_shape = (None, ) +\n        output_shape` If a function, it specifies the entire shape as a function\n        of the\n      input shape: `output_shape = f(input_shape)`\n    mask: Either None (indicating no masking) or a callable with the same\n      signature as the `compute_mask` layer method, or a tensor that will be\n      returned as output mask regardless of what the input is.\n    arguments: Optional dictionary of keyword arguments to be passed to the\n      function.\n\n  Input shape:\n    Arbitrary. Use the keyword argument input_shape (tuple of\n    integers, does not include the samples axis) when using this layer as the\n    first layer in a model.\n\n  Output shape:\n    Specified by `output_shape` argument\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "function",
        "default": null
      },
      {
        "name": "output_shape",
        "default": "None"
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "arguments",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "LayerNormalization",
    "base": "Layer",
    "docstring": "Layer normalization layer (Ba et al., 2016).\n\n  Normalize the activations of the previous layer for each given example in a\n  batch independently, rather than across a batch like Batch Normalization.\n  i.e. applies a transformation that maintains the mean activation within each\n  example close to 0 and the activation standard deviation close to 1.\n\n  Given a tensor `inputs`, moments are calculated and normalization\n  is performed across the axes specified in `axis`.\n\n  Example:\n\n  >>> data = tf.constant(np.arange(10).reshape(5, 2) * 10, dtype=tf.float32)\n  >>> print(data)\n  tf.Tensor(\n  [[ 0. 10.]\n   [20. 30.]\n   [40. 50.]\n   [60. 70.]\n   [80. 90.]], shape=(5, 2), dtype=float32)\n\n  >>> layer = tf.keras.layers.LayerNormalization(axis=1)\n  >>> output = layer(data)\n  >>> print(output)\n  tf.Tensor(\n  [[-1. 1.]\n   [-1. 1.]\n   [-1. 1.]\n   [-1. 1.]\n   [-1. 1.]], shape=(5, 2), dtype=float32)\n\n  Notice that with Layer Normalization the normalization happens across the\n  axes *within* each example, rather than across different examples in the\n  batch.\n\n  If `scale` or `center` are enabled, the layer will scale the normalized\n  outputs by broadcasting them with a trainable variable `gamma`, and center\n  the outputs by broadcasting with a trainable variable `beta`. `gamma` will\n  default to a ones tensor and `beta` will default to a zeros tensor, so that\n  centering and scaling are no-ops before training has begun.\n\n  So, with scaling and centering enabled the normalization equations\n  are as follows:\n\n  Let the intermediate activations for a mini-batch to be the `inputs`.\n\n  For each sample `x_i` in `inputs` with `k` features, we compute the mean and\n  variance of the sample:\n\n  ```python\n  mean_i = sum(x_i[j] for j in range(k)) / k\n  var_i = sum((x_i[j] - mean_i) ** 2 for j in range(k)) / k\n  ```\n\n  and then compute a normalized `x_i_normalized`, including a small factor\n  `epsilon` for numerical stability.\n\n  ```python\n  x_i_normalized = (x_i - mean_i) / sqrt(var_i + epsilon)\n  ```\n\n  And finally `x_i_normalized ` is linearly transformed by `gamma` and `beta`,\n  which are learned parameters:\n\n  ```python\n  output_i = x_i_normalized * gamma + beta\n  ```\n\n  `gamma` and `beta` will span the axes of `inputs` specified in `axis`, and\n  this part of the inputs' shape must be fully defined.\n\n  For example:\n\n  >>> layer = tf.keras.layers.LayerNormalization(axis=[1, 2, 3])\n  >>> layer.build([5, 20, 30, 40])\n  >>> print(layer.beta.shape)\n  (20, 30, 40)\n  >>> print(layer.gamma.shape)\n  (20, 30, 40)\n\n  Note that other implementations of layer normalization may choose to define\n  `gamma` and `beta` over a separate set of axes from the axes being\n  normalized across. For example, Group Normalization\n  ([Wu et al. 2018](https://arxiv.org/abs/1803.08494)) with group size of 1\n  corresponds to a Layer Normalization that normalizes across height, width,\n  and channel and has `gamma` and `beta` span only the channel dimension.\n  So, this Layer Normalization implementation will not match a Group\n  Normalization layer with group size set to 1.\n\n  Args:\n    axis: Integer or List/Tuple. The axis or axes to normalize across. Typically\n      this is the features axis/axes. The left-out axes are typically the batch\n      axis/axes. This argument defaults to `-1`, the last dimension in the\n      input.\n    epsilon: Small float added to variance to avoid dividing by zero. Defaults\n      to 1e-3\n    center: If True, add offset of `beta` to normalized tensor. If False, `beta`\n      is ignored. Defaults to True.\n    scale: If True, multiply by `gamma`. If False, `gamma` is not used. Defaults\n      to True. When the next layer is linear (also e.g. `nn.relu`), this can be\n      disabled since the scaling will be done by the next layer.\n    beta_initializer: Initializer for the beta weight. Defaults to zeros.\n    gamma_initializer: Initializer for the gamma weight. Defaults to ones.\n    beta_regularizer: Optional regularizer for the beta weight. None by default.\n    gamma_regularizer: Optional regularizer for the gamma weight. None by\n      default.\n    beta_constraint: Optional constraint for the beta weight. None by default.\n    gamma_constraint: Optional constraint for the gamma weight. None by default.\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape` (tuple of\n    integers, does not include the samples axis) when using this layer as the\n    first layer in a model.\n\n  Output shape:\n    Same shape as input.\n\n  Reference:\n    - [Lei Ba et al., 2016](https://arxiv.org/abs/1607.06450).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "axis",
        "default": -1
      },
      {
        "name": "epsilon",
        "default": 0.001
      },
      {
        "name": "center",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "scale",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "beta_initializer",
        "default": "zeros"
      },
      {
        "name": "gamma_initializer",
        "default": "ones"
      },
      {
        "name": "beta_regularizer",
        "default": "None"
      },
      {
        "name": "gamma_regularizer",
        "default": "None"
      },
      {
        "name": "beta_constraint",
        "default": "None"
      },
      {
        "name": "gamma_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/normalization/layer_normalization.py",
    "aliases": []
  },
  {
    "name": "LeakyReLU",
    "base": "Layer",
    "docstring": "Leaky version of a Rectified Linear Unit.\n\n  It allows a small gradient when the unit is not active:\n\n  ```\n    f(x) = alpha * x if x < 0\n    f(x) = x if x >= 0\n  ```\n\n  Usage:\n\n  >>> layer = tf.keras.layers.LeakyReLU()\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [-0.9, -0.3, 0.0, 2.0]\n  >>> layer = tf.keras.layers.LeakyReLU(alpha=0.1)\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [-0.3, -0.1, 0.0, 2.0]\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the batch axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as the input.\n\n  Args:\n    alpha: Float >= 0. Negative slope coefficient. Default to 0.3.\n\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "alpha",
        "default": 0.3
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/advanced_activations.py",
    "aliases": []
  },
  {
    "name": "LocallyConnected1D",
    "base": "Layer",
    "docstring": "Locally-connected layer for 1D inputs.\n\n  The `LocallyConnected1D` layer works similarly to\n  the `Conv1D` layer, except that weights are unshared,\n  that is, a different set of filters is applied at each different patch\n  of the input.\n\n  Note: layer attributes cannot be modified after the layer has been called\n  once (except the `trainable` attribute).\n\n  Example:\n  ```python\n      # apply a unshared weight convolution 1d of length 3 to a sequence with\n      # 10 timesteps, with 64 output filters\n      model = Sequential()\n      model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n      # now model.output_shape == (None, 8, 64)\n      # add a new conv1d on top\n      model.add(LocallyConnected1D(32, 3))\n      # now model.output_shape == (None, 6, 32)\n  ```\n\n  Args:\n      filters: Integer, the dimensionality of the output space (i.e. the number\n        of output filters in the convolution).\n      kernel_size: An integer or tuple/list of a single integer, specifying the\n        length of the 1D convolution window.\n      strides: An integer or tuple/list of a single integer, specifying the\n        stride length of the convolution.\n      padding: Currently only supports `\"valid\"` (case-insensitive). `\"same\"`\n        may be supported in the future. `\"valid\"` means no padding.\n      data_format: A string, one of `channels_last` (default) or\n        `channels_first`. The ordering of the dimensions in the inputs.\n        `channels_last` corresponds to inputs with shape `(batch, length,\n        channels)` while `channels_first` corresponds to inputs with shape\n        `(batch, channels, length)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`. If you\n        never set it, then it will be \"channels_last\".\n      activation: Activation function to use. If you don't specify anything, no\n        activation is applied\n          (ie. \"linear\" activation: `a(x) = x`).\n      use_bias: Boolean, whether the layer uses a bias vector.\n      kernel_initializer: Initializer for the `kernel` weights matrix.\n      bias_initializer: Initializer for the bias vector.\n      kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix.\n      bias_regularizer: Regularizer function applied to the bias vector.\n      activity_regularizer: Regularizer function applied to the output of the\n        layer (its \"activation\")..\n      kernel_constraint: Constraint function applied to the kernel matrix.\n      bias_constraint: Constraint function applied to the bias vector.\n      implementation: implementation mode, either `1`, `2`, or `3`. `1` loops\n        over input spatial locations to perform the forward pass. It is\n        memory-efficient but performs a lot of (small) ops.  `2` stores layer\n        weights in a dense but sparsely-populated 2D matrix and implements the\n        forward pass as a single matrix-multiply. It uses a lot of RAM but\n        performs few (large) ops.  `3` stores layer weights in a sparse tensor\n        and implements the forward pass as a single sparse matrix-multiply.\n          How to choose:\n          `1`: large, dense models,\n          `2`: small models,\n          `3`: large, sparse models,  where \"large\" stands for large\n            input/output activations (i.e. many `filters`, `input_filters`,\n            large `input_size`, `output_size`), and \"sparse\" stands for few\n            connections between inputs and outputs, i.e. small ratio `filters *\n            input_filters * kernel_size / (input_size * strides)`, where inputs\n            to and outputs of the layer are assumed to have shapes `(input_size,\n            input_filters)`, `(output_size, filters)` respectively.  It is\n            recommended to benchmark each in the setting of interest to pick the\n            most efficient one (in terms of speed and memory usage). Correct\n            choice of implementation can lead to dramatic speed improvements\n            (e.g. 50X), potentially at the expense of RAM.  Also, only\n            `padding=\"valid\"` is supported by `implementation=1`.\n  Input shape:\n      3D tensor with shape: `(batch_size, steps, input_dim)`\n  Output shape:\n      3D tensor with shape: `(batch_size, new_steps, filters)` `steps` value\n        might have changed due to padding or strides.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": 1
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "implementation",
        "default": 1
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/local.py",
    "aliases": []
  },
  {
    "name": "LocallyConnected2D",
    "base": "Layer",
    "docstring": "Locally-connected layer for 2D inputs.\n\n  The `LocallyConnected2D` layer works similarly\n  to the `Conv2D` layer, except that weights are unshared,\n  that is, a different set of filters is applied at each\n  different patch of the input.\n\n  Note: layer attributes cannot be modified after the layer has been called\n  once (except the `trainable` attribute).\n\n  Examples:\n  ```python\n      # apply a 3x3 unshared weights convolution with 64 output filters on a\n      32x32 image\n      # with `data_format=\"channels_last\"`:\n      model = Sequential()\n      model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3)))\n      # now model.output_shape == (None, 30, 30, 64)\n      # notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64\n      parameters\n\n      # add a 3x3 unshared weights convolution on top, with 32 output filters:\n      model.add(LocallyConnected2D(32, (3, 3)))\n      # now model.output_shape == (None, 28, 28, 32)\n  ```\n\n  Args:\n      filters: Integer, the dimensionality of the output space (i.e. the number\n        of output filters in the convolution).\n      kernel_size: An integer or tuple/list of 2 integers, specifying the width\n        and height of the 2D convolution window. Can be a single integer to\n        specify the same value for all spatial dimensions.\n      strides: An integer or tuple/list of 2 integers, specifying the strides of\n        the convolution along the width and height. Can be a single integer to\n        specify the same value for all spatial dimensions.\n      padding: Currently only support `\"valid\"` (case-insensitive). `\"same\"`\n        will be supported in future. `\"valid\"` means no padding.\n      data_format: A string, one of `channels_last` (default) or\n        `channels_first`. The ordering of the dimensions in the inputs.\n        `channels_last` corresponds to inputs with shape `(batch, height, width,\n        channels)` while `channels_first` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        \"channels_last\".\n      activation: Activation function to use. If you don't specify anything, no\n        activation is applied\n          (ie. \"linear\" activation: `a(x) = x`).\n      use_bias: Boolean, whether the layer uses a bias vector.\n      kernel_initializer: Initializer for the `kernel` weights matrix.\n      bias_initializer: Initializer for the bias vector.\n      kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix.\n      bias_regularizer: Regularizer function applied to the bias vector.\n      activity_regularizer: Regularizer function applied to the output of the\n        layer (its \"activation\").\n      kernel_constraint: Constraint function applied to the kernel matrix.\n      bias_constraint: Constraint function applied to the bias vector.\n      implementation: implementation mode, either `1`, `2`, or `3`. `1` loops\n        over input spatial locations to perform the forward pass. It is\n        memory-efficient but performs a lot of (small) ops.  `2` stores layer\n        weights in a dense but sparsely-populated 2D matrix and implements the\n        forward pass as a single matrix-multiply. It uses a lot of RAM but\n        performs few (large) ops.  `3` stores layer weights in a sparse tensor\n        and implements the forward pass as a single sparse matrix-multiply.\n          How to choose:\n          `1`: large, dense models,\n          `2`: small models,\n          `3`: large, sparse models,  where \"large\" stands for large\n            input/output activations (i.e. many `filters`, `input_filters`,\n            large `np.prod(input_size)`, `np.prod(output_size)`), and \"sparse\"\n            stands for few connections between inputs and outputs, i.e. small\n            ratio `filters * input_filters * np.prod(kernel_size) /\n            (np.prod(input_size) * np.prod(strides))`, where inputs to and\n            outputs of the layer are assumed to have shapes `input_size +\n            (input_filters,)`, `output_size + (filters,)` respectively.  It is\n            recommended to benchmark each in the setting of interest to pick the\n            most efficient one (in terms of speed and memory usage). Correct\n            choice of implementation can lead to dramatic speed improvements\n            (e.g. 50X), potentially at the expense of RAM.  Also, only\n            `padding=\"valid\"` is supported by `implementation=1`.\n  Input shape:\n      4D tensor with shape: `(samples, channels, rows, cols)` if\n        data_format='channels_first'\n      or 4D tensor with shape: `(samples, rows, cols, channels)` if\n        data_format='channels_last'.\n  Output shape:\n      4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n        data_format='channels_first'\n      or 4D tensor with shape: `(samples, new_rows, new_cols, filters)` if\n        data_format='channels_last'. `rows` and `cols` values might have changed\n        due to padding.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "implementation",
        "default": 1
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/local.py",
    "aliases": []
  },
  {
    "name": "Masking",
    "base": "Layer",
    "docstring": "Masks a sequence by using a mask value to skip timesteps.\n\n  For each timestep in the input tensor (dimension #1 in the tensor),\n  if all values in the input tensor at that timestep\n  are equal to `mask_value`, then the timestep will be masked (skipped)\n  in all downstream layers (as long as they support masking).\n\n  If any downstream layer does not support masking yet receives such\n  an input mask, an exception will be raised.\n\n  Example:\n\n  Consider a Numpy data array `x` of shape `(samples, timesteps, features)`,\n  to be fed to an LSTM layer. You want to mask timestep #3 and #5 because you\n  lack data for these timesteps. You can:\n\n  - Set `x[:, 3, :] = 0.` and `x[:, 5, :] = 0.`\n  - Insert a `Masking` layer with `mask_value=0.` before the LSTM layer:\n\n  ```python\n  samples, timesteps, features = 32, 10, 8\n  inputs = np.random.random([samples, timesteps, features]).astype(np.float32)\n  inputs[:, 3, :] = 0.\n  inputs[:, 5, :] = 0.\n\n  model = tf.keras.models.Sequential()\n  model.add(tf.keras.layers.Masking(mask_value=0.,\n                                    input_shape=(timesteps, features)))\n  model.add(tf.keras.layers.LSTM(32))\n\n  output = model(inputs)\n  # The time step 3 and 5 will be skipped from LSTM calculation.\n  ```\n\n  See [the masking and padding guide](\n    https://www.tensorflow.org/guide/keras/masking_and_padding)\n  for more details.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "mask_value",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "MaxPooling1D",
    "base": "Pooling1D",
    "docstring": "Max pooling operation for 1D temporal data.\n\n  Downsamples the input representation by taking the maximum value over a\n  spatial window of size `pool_size`. The window is shifted by `strides`.  The\n  resulting output, when using the `\"valid\"` padding option, has a shape of:\n  `output_shape = (input_shape - pool_size + 1) / strides)`\n\n  The resulting output shape when using the `\"same\"` padding option is:\n  `output_shape = input_shape / strides`\n\n  For example, for `strides=1` and `padding=\"valid\"`:\n\n  >>> x = tf.constant([1., 2., 3., 4., 5.])\n  >>> x = tf.reshape(x, [1, 5, 1])\n  >>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,\n  ...    strides=1, padding='valid')\n  >>> max_pool_1d(x)\n  <tf.Tensor: shape=(1, 4, 1), dtype=float32, numpy=\n  array([[[2.],\n          [3.],\n          [4.],\n          [5.]]], dtype=float32)>\n\n  For example, for `strides=2` and `padding=\"valid\"`:\n\n  >>> x = tf.constant([1., 2., 3., 4., 5.])\n  >>> x = tf.reshape(x, [1, 5, 1])\n  >>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,\n  ...    strides=2, padding='valid')\n  >>> max_pool_1d(x)\n  <tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=\n  array([[[2.],\n          [4.]]], dtype=float32)>\n\n  For example, for `strides=1` and `padding=\"same\"`:\n\n  >>> x = tf.constant([1., 2., 3., 4., 5.])\n  >>> x = tf.reshape(x, [1, 5, 1])\n  >>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,\n  ...    strides=1, padding='same')\n  >>> max_pool_1d(x)\n  <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\n  array([[[2.],\n          [3.],\n          [4.],\n          [5.],\n          [5.]]], dtype=float32)>\n\n  Args:\n    pool_size: Integer, size of the max pooling window.\n    strides: Integer, or None. Specifies how much the pooling window moves\n      for each pooling step.\n      If None, it will default to `pool_size`.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n      the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, steps, features)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, features, steps)`.\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      3D tensor with shape `(batch_size, steps, features)`.\n    - If `data_format='channels_first'`:\n      3D tensor with shape `(batch_size, features, steps)`.\n\n  Output shape:\n    - If `data_format='channels_last'`:\n      3D tensor with shape `(batch_size, downsampled_steps, features)`.\n    - If `data_format='channels_first'`:\n      3D tensor with shape `(batch_size, features, downsampled_steps)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "pool_size",
        "default": 2
      },
      {
        "name": "strides",
        "default": "None"
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "channels_last"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/pooling.py",
    "aliases": [
      "MaxPool1D"
    ]
  },
  {
    "name": "MaxPooling2D",
    "base": "Pooling2D",
    "docstring": "Max pooling operation for 2D spatial data.\n\n  Downsamples the input along its spatial dimensions (height and width)\n  by taking the maximum value over an input window\n  (of size defined by `pool_size`) for each channel of the input.\n  The window is shifted by `strides` along each dimension.\n\n  The resulting output,\n  when using the `\"valid\"` padding option, has a spatial shape\n  (number of rows or columns) of:\n  `output_shape = math.floor((input_shape - pool_size) / strides) + 1`\n  (when `input_shape >= pool_size`)\n\n  The resulting output shape when using the `\"same\"` padding option is:\n  `output_shape = math.floor((input_shape - 1) / strides) + 1`\n\n  For example, for `strides=(1, 1)` and `padding=\"valid\"`:\n\n  >>> x = tf.constant([[1., 2., 3.],\n  ...                  [4., 5., 6.],\n  ...                  [7., 8., 9.]])\n  >>> x = tf.reshape(x, [1, 3, 3, 1])\n  >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n  ...    strides=(1, 1), padding='valid')\n  >>> max_pool_2d(x)\n  <tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n    array([[[[5.],\n             [6.]],\n            [[8.],\n             [9.]]]], dtype=float32)>\n\n  For example, for `strides=(2, 2)` and `padding=\"valid\"`:\n\n  >>> x = tf.constant([[1., 2., 3., 4.],\n  ...                  [5., 6., 7., 8.],\n  ...                  [9., 10., 11., 12.]])\n  >>> x = tf.reshape(x, [1, 3, 4, 1])\n  >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n  ...    strides=(2, 2), padding='valid')\n  >>> max_pool_2d(x)\n  <tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=\n    array([[[[6.],\n             [8.]]]], dtype=float32)>\n\n  Usage Example:\n\n  >>> input_image = tf.constant([[[[1.], [1.], [2.], [4.]],\n  ...                            [[2.], [2.], [3.], [2.]],\n  ...                            [[4.], [1.], [1.], [1.]],\n  ...                            [[2.], [2.], [1.], [4.]]]])\n  >>> output = tf.constant([[[[1], [0]],\n  ...                       [[0], [1]]]])\n  >>> model = tf.keras.models.Sequential()\n  >>> model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n  ...    input_shape=(4, 4, 1)))\n  >>> model.compile('adam', 'mean_squared_error')\n  >>> model.predict(input_image, steps=1)\n  array([[[[2.],\n           [4.]],\n          [[4.],\n           [4.]]]], dtype=float32)\n\n  For example, for stride=(1, 1) and padding=\"same\":\n\n  >>> x = tf.constant([[1., 2., 3.],\n  ...                  [4., 5., 6.],\n  ...                  [7., 8., 9.]])\n  >>> x = tf.reshape(x, [1, 3, 3, 1])\n  >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n  ...    strides=(1, 1), padding='same')\n  >>> max_pool_2d(x)\n  <tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n    array([[[[5.],\n             [6.],\n             [6.]],\n            [[8.],\n             [9.],\n             [9.]],\n            [[8.],\n             [9.],\n             [9.]]]], dtype=float32)>\n\n  Args:\n    pool_size: integer or tuple of 2 integers,\n      window size over which to take the maximum.\n      `(2, 2)` will take the max value over a 2x2 pooling window.\n      If only one integer is specified, the same window length\n      will be used for both dimensions.\n    strides: Integer, tuple of 2 integers, or None.\n      Strides values.  Specifies how far the pooling window moves\n      for each pooling step. If None, it will default to `pool_size`.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n      the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      4D tensor with shape `(batch_size, rows, cols, channels)`.\n    - If `data_format='channels_first'`:\n      4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n  Output shape:\n    - If `data_format='channels_last'`:\n      4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n    - If `data_format='channels_first'`:\n      4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.\n\n  Returns:\n    A tensor of rank 4 representing the maximum pooled values.  See above for\n    output shape.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "pool_size",
        "default": [
          2,
          2
        ]
      },
      {
        "name": "strides",
        "default": "None"
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/pooling.py",
    "aliases": [
      "MaxPool2D"
    ]
  },
  {
    "name": "MaxPooling3D",
    "base": "Pooling3D",
    "docstring": "Max pooling operation for 3D data (spatial or spatio-temporal).\n\n  Downsamples the input along its spatial dimensions (depth, height, and width)\n  by taking the maximum value over an input window\n  (of size defined by `pool_size`) for each channel of the input.\n  The window is shifted by `strides` along each dimension.\n\n  Args:\n    pool_size: Tuple of 3 integers,\n      factors by which to downscale (dim1, dim2, dim3).\n      `(2, 2, 2)` will halve the size of the 3D input in each dimension.\n    strides: tuple of 3 integers, or None. Strides values.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n      the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      5D tensor with shape:\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n      5D tensor with shape:\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\n  Output shape:\n    - If `data_format='channels_last'`:\n      5D tensor with shape:\n      `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n    - If `data_format='channels_first'`:\n      5D tensor with shape:\n      `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n\n  Example:\n\n  ```python\n  depth = 30\n  height = 30\n  width = 30\n  input_channels = 3\n\n  inputs = tf.keras.Input(shape=(depth, height, width, input_channels))\n  layer = tf.keras.layers.MaxPooling3D(pool_size=3)\n  outputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "pool_size",
        "default": [
          2,
          2,
          2
        ]
      },
      {
        "name": "strides",
        "default": "None"
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/pooling.py",
    "aliases": [
      "MaxPool3D"
    ]
  },
  {
    "name": "Maximum",
    "base": "_Merge",
    "docstring": "Layer that computes the maximum (element-wise) a list of inputs.\n\n  It takes as input a list of tensors, all of the same shape, and returns\n  a single tensor (also of the same shape).\n\n  >>> tf.keras.layers.Maximum()([np.arange(5).reshape(5, 1),\n  ...                            np.arange(5, 10).reshape(5, 1)])\n  <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n  array([[5],\n       [6],\n       [7],\n       [8],\n       [9]])>\n\n  >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n  >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n  >>> maxed = tf.keras.layers.Maximum()([x1, x2])\n  >>> maxed.shape\n  TensorShape([5, 8])\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "Minimum",
    "base": "_Merge",
    "docstring": "Layer that computes the minimum (element-wise) a list of inputs.\n\n  It takes as input a list of tensors, all of the same shape, and returns\n  a single tensor (also of the same shape).\n\n  >>> tf.keras.layers.Minimum()([np.arange(5).reshape(5, 1),\n  ...                            np.arange(5, 10).reshape(5, 1)])\n  <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n  array([[0],\n       [1],\n       [2],\n       [3],\n       [4]])>\n\n  >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n  >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n  >>> minned = tf.keras.layers.Minimum()([x1, x2])\n  >>> minned.shape\n  TensorShape([5, 8])\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "MultiHeadAttention",
    "base": "Layer",
    "docstring": "MultiHeadAttention layer.\n\n  This is an implementation of multi-headed attention as described in the paper\n  \"Attention is all you Need\" (Vaswani et al., 2017).\n  If `query`, `key,` `value` are the same, then\n  this is self-attention. Each timestep in `query` attends to the\n  corresponding sequence in `key`, and returns a fixed-width vector.\n\n  This layer first projects `query`, `key` and `value`. These are\n  (effectively) a list of tensors of length `num_attention_heads`, where the\n  corresponding shapes are `(batch_size, <query dimensions>, key_dim)`,\n  `(batch_size, <key/value dimensions>, key_dim)`,\n  `(batch_size, <key/value dimensions>, value_dim)`.\n\n  Then, the query and key tensors are dot-producted and scaled. These are\n  softmaxed to obtain attention probabilities. The value tensors are then\n  interpolated by these probabilities, then concatenated back to a single\n  tensor.\n\n  Finally, the result tensor with the last dimension as value_dim can take an\n  linear projection and return.\n\n  Examples:\n\n  Performs 1D cross-attention over two sequence inputs with an attention mask.\n  Returns the additional attention weights over heads.\n\n  >>> layer = MultiHeadAttention(num_heads=2, key_dim=2)\n  >>> target = tf.keras.Input(shape=[8, 16])\n  >>> source = tf.keras.Input(shape=[4, 16])\n  >>> output_tensor, weights = layer(target, source,\n  ...                                return_attention_scores=True)\n  >>> print(output_tensor.shape)\n  (None, 8, 16)\n  >>> print(weights.shape)\n  (None, 2, 8, 4)\n\n  Performs 2D self-attention over a 5D input tensor on axes 2 and 3.\n\n  >>> layer = MultiHeadAttention(num_heads=2, key_dim=2, attention_axes=(2, 3))\n  >>> input_tensor = tf.keras.Input(shape=[5, 3, 4, 16])\n  >>> output_tensor = layer(input_tensor, input_tensor)\n  >>> print(output_tensor.shape)\n  (None, 5, 3, 4, 16)\n\n  Args:\n    num_heads: Number of attention heads.\n    key_dim: Size of each attention head for query and key.\n    value_dim: Size of each attention head for value.\n    dropout: Dropout probability.\n    use_bias: Boolean, whether the dense layers use bias vectors/matrices.\n    output_shape: The expected shape of an output tensor, besides the batch and\n      sequence dims. If not specified, projects back to the key feature dim.\n    attention_axes: axes over which the attention is applied. `None` means\n      attention over all axes, but batch, heads, and features.\n    kernel_initializer: Initializer for dense layer kernels.\n    bias_initializer: Initializer for dense layer biases.\n    kernel_regularizer: Regularizer for dense layer kernels.\n    bias_regularizer: Regularizer for dense layer biases.\n    activity_regularizer: Regularizer for dense layer activity.\n    kernel_constraint: Constraint for dense layer kernels.\n    bias_constraint: Constraint for dense layer kernels.\n\n  Call arguments:\n    query: Query `Tensor` of shape `(B, T, dim)`.\n    value: Value `Tensor` of shape `(B, S, dim)`.\n    key: Optional key `Tensor` of shape `(B, S, dim)`. If not given, will use\n      `value` for both `key` and `value`, which is the most common case.\n    attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n      attention to certain positions. The boolean mask specifies which query\n      elements can attend to which key elements, 1 indicates attention and 0\n      indicates no attention. Broadcasting can happen for the missing batch\n      dimensions and the head dimension.\n    return_attention_scores: A boolean to indicate whether the output should\n      be attention output if True, or (attention_output, attention_scores) if\n      False. Defaults to False.\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (no dropout).\n      Defaults to either using the training mode of the parent layer/model,\n      or False (inference) if there is no parent layer.\n\n  Returns:\n    attention_output: The result of the computation, of shape `(B, T, E)`,\n      where `T` is for target sequence shapes and `E` is the query input last\n      dimension if `output_shape` is `None`. Otherwise, the multi-head outputs\n      are project to the shape specified by `output_shape`.\n    attention_scores: [Optional] multi-head attention coeffients over\n      attention axes.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "num_heads",
        "default": null
      },
      {
        "name": "key_dim",
        "default": null
      },
      {
        "name": "value_dim",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "output_shape",
        "default": "None"
      },
      {
        "name": "attention_axes",
        "default": "None"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "query",
        "default": null
      },
      {
        "name": "value",
        "default": null
      },
      {
        "name": "key",
        "default": "None"
      },
      {
        "name": "attention_mask",
        "default": "None"
      },
      {
        "name": "return_attention_scores",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/multi_head_attention.py",
    "aliases": []
  },
  {
    "name": "Multiply",
    "base": "_Merge",
    "docstring": "Layer that multiplies (element-wise) a list of inputs.\n\n  It takes as input a list of tensors, all of the same shape, and returns\n  a single tensor (also of the same shape).\n\n  >>> tf.keras.layers.Multiply()([np.arange(5).reshape(5, 1),\n  ...                             np.arange(5, 10).reshape(5, 1)])\n  <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n  array([[ 0],\n       [ 6],\n       [14],\n       [24],\n       [36]])>\n\n  >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n  >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n  >>> multiplied = tf.keras.layers.Multiply()([x1, x2])\n  >>> multiplied.shape\n  TensorShape([5, 8])\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "Normalization",
    "base": "PreprocessingLayer",
    "docstring": "Feature-wise normalization of the data.\n\n  This layer will coerce its inputs into a distribution centered around\n  0 with standard deviation 1. It accomplishes this by precomputing the mean and\n  variance of the data, and calling `(input - mean) / sqrt(var)` at runtime.\n\n  What happens in `adapt()`: Compute mean and variance of the data and store\n  them as the layer's weights. `adapt()` should be called before `fit()`,\n  `evaluate()`, or `predict()`.\n\n  Args:\n      axis: Integer, tuple of integers, or None. The axis or axes that should\n        have a separate mean and variance for each index in the shape. For\n        example, if shape is `(None, 5)` and `axis=1`, the layer will track 5\n        separate mean and variance values for the last axis. If `axis` is set to\n        `None`, the layer will normalize all elements in the input by a scalar\n        mean and variance. Defaults to -1, where the last axis of the input is\n        assumed to be a feature dimension and is normalized per index. Note that\n        in the specific case of batched scalar inputs where the only axis is the\n        batch axis, the default will normalize each index in the batch\n        separately. In this case, consider passing `axis=None`.\n      mean: The mean value(s) to use during normalization. The passed value(s)\n        will be broadcast to the shape of the kept axes above; if the value(s)\n        cannot be broadcast, an error will be raised when this layer's `build()`\n        method is called.\n      variance: The variance value(s) to use during normalization. The passed\n        value(s) will be broadcast to the shape of the kept axes above; if the\n        value(s) cannot be broadcast, an error will be raised when this layer's\n        `build()` method is called.\n\n  Examples:\n\n  Calculate a global mean and variance by analyzing the dataset in `adapt()`.\n\n  >>> adapt_data = np.array([1., 2., 3., 4., 5.], dtype='float32')\n  >>> input_data = np.array([1., 2., 3.], dtype='float32')\n  >>> layer = tf.keras.layers.Normalization(axis=None)\n  >>> layer.adapt(adapt_data)\n  >>> layer(input_data)\n  <tf.Tensor: shape=(3,), dtype=float32, numpy=\n  array([-1.4142135, -0.70710677, 0.], dtype=float32)>\n\n  Calculate a mean and variance for each index on the last axis.\n\n  >>> adapt_data = np.array([[0., 7., 4.],\n  ...                        [2., 9., 6.],\n  ...                        [0., 7., 4.],\n  ...                        [2., 9., 6.]], dtype='float32')\n  >>> input_data = np.array([[0., 7., 4.]], dtype='float32')\n  >>> layer = tf.keras.layers.Normalization(axis=-1)\n  >>> layer.adapt(adapt_data)\n  >>> layer(input_data)\n  <tf.Tensor: shape=(1, 3), dtype=float32, numpy=\n  array([0., 0., 0.], dtype=float32)>\n\n  Pass the mean and variance directly.\n\n  >>> input_data = np.array([[1.], [2.], [3.]], dtype='float32')\n  >>> layer = tf.keras.layers.Normalization(mean=3., variance=2.)\n  >>> layer(input_data)\n  <tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n  array([[-1.4142135 ],\n         [-0.70710677],\n         [ 0.        ]], dtype=float32)>\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "axis",
        "default": -1
      },
      {
        "name": "mean",
        "default": "None"
      },
      {
        "name": "variance",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/preprocessing/normalization.py",
    "aliases": []
  },
  {
    "name": "PReLU",
    "base": "Layer",
    "docstring": "Parametric Rectified Linear Unit.\n\n  It follows:\n\n  ```\n    f(x) = alpha * x for x < 0\n    f(x) = x for x >= 0\n  ```\n\n  where `alpha` is a learned array with the same shape as x.\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as the input.\n\n  Args:\n    alpha_initializer: Initializer function for the weights.\n    alpha_regularizer: Regularizer for the weights.\n    alpha_constraint: Constraint for the weights.\n    shared_axes: The axes along which to share learnable\n      parameters for the activation function.\n      For example, if the incoming feature maps\n      are from a 2D convolution\n      with output shape `(batch, height, width, channels)`,\n      and you wish to share parameters across space\n      so that each filter only has one set of parameters,\n      set `shared_axes=[1, 2]`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "alpha_initializer",
        "default": "zeros"
      },
      {
        "name": "alpha_regularizer",
        "default": "None"
      },
      {
        "name": "alpha_constraint",
        "default": "None"
      },
      {
        "name": "shared_axes",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/advanced_activations.py",
    "aliases": []
  },
  {
    "name": "Permute",
    "base": "Layer",
    "docstring": "Permutes the dimensions of the input according to a given pattern.\n\n  Useful e.g. connecting RNNs and convnets.\n\n  Example:\n\n  ```python\n  model = Sequential()\n  model.add(Permute((2, 1), input_shape=(10, 64)))\n  # now: model.output_shape == (None, 64, 10)\n  # note: `None` is the batch dimension\n  ```\n\n  Args:\n    dims: Tuple of integers. Permutation pattern does not include the\n      samples dimension. Indexing starts at 1.\n      For instance, `(2, 1)` permutes the first and second dimensions\n      of the input.\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same as the input shape, but with the dimensions re-ordered according\n    to the specified pattern.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "dims",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "RNN",
    "base": "Layer",
    "docstring": "Base class for recurrent layers.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  Args:\n    cell: A RNN cell instance or a list of RNN cell instances.\n      A RNN cell is a class that has:\n      - A `call(input_at_t, states_at_t)` method, returning\n        `(output_at_t, states_at_t_plus_1)`. The call method of the\n        cell can also take the optional argument `constants`, see\n        section \"Note on passing external constants\" below.\n      - A `state_size` attribute. This can be a single integer\n        (single state) in which case it is the size of the recurrent\n        state. This can also be a list/tuple of integers (one size per state).\n        The `state_size` can also be TensorShape or tuple/list of\n        TensorShape, to represent high dimension state.\n      - A `output_size` attribute. This can be a single integer or a\n        TensorShape, which represent the shape of the output. For backward\n        compatible reason, if this attribute is not available for the\n        cell, the value will be inferred by the first element of the\n        `state_size`.\n      - A `get_initial_state(inputs=None, batch_size=None, dtype=None)`\n        method that creates a tensor meant to be fed to `call()` as the\n        initial state, if the user didn't specify any initial state via other\n        means. The returned initial state should have a shape of\n        [batch_size, cell.state_size]. The cell might choose to create a\n        tensor full of zeros, or full of other values based on the cell's\n        implementation.\n        `inputs` is the input tensor to the RNN layer, which should\n        contain the batch size as its shape[0], and also dtype. Note that\n        the shape[0] might be `None` during the graph construction. Either\n        the `inputs` or the pair of `batch_size` and `dtype` are provided.\n        `batch_size` is a scalar tensor that represents the batch size\n        of the inputs. `dtype` is `tf.DType` that represents the dtype of\n        the inputs.\n        For backward compatibility, if this method is not implemented\n        by the cell, the RNN layer will create a zero filled tensor with the\n        size of [batch_size, cell.state_size].\n      In the case that `cell` is a list of RNN cell instances, the cells\n      will be stacked on top of each other in the RNN, resulting in an\n      efficient stacked RNN.\n    return_sequences: Boolean (default `False`). Whether to return the last\n      output in the output sequence, or the full sequence.\n    return_state: Boolean (default `False`). Whether to return the last state\n      in addition to the output.\n    go_backwards: Boolean (default `False`).\n      If True, process the input sequence backwards and return the\n      reversed sequence.\n    stateful: Boolean (default `False`). If True, the last state\n      for each sample at index i in a batch will be used as initial\n      state for the sample of index i in the following batch.\n    unroll: Boolean (default `False`).\n      If True, the network will be unrolled, else a symbolic loop will be used.\n      Unrolling can speed-up a RNN, although it tends to be more\n      memory-intensive. Unrolling is only suitable for short sequences.\n    time_major: The shape format of the `inputs` and `outputs` tensors.\n      If True, the inputs and outputs will be in shape\n      `(timesteps, batch, ...)`, whereas in the False case, it will be\n      `(batch, timesteps, ...)`. Using `time_major = True` is a bit more\n      efficient because it avoids transposes at the beginning and end of the\n      RNN calculation. However, most TensorFlow data is batch-major, so by\n      default this function accepts input and emits output in batch-major\n      form.\n    zero_output_for_mask: Boolean (default `False`).\n      Whether the output should use zeros for the masked timesteps. Note that\n      this field is only used when `return_sequences` is True and mask is\n      provided. It can useful if you want to reuse the raw output sequence of\n      the RNN without interference from the masked timesteps, eg, merging\n      bidirectional RNNs.\n\n  Call arguments:\n    inputs: Input tensor.\n    mask: Binary tensor of shape `[batch_size, timesteps]` indicating whether\n      a given timestep should be masked. An individual `True` entry indicates\n      that the corresponding timestep should be utilized, while a `False`\n      entry indicates that the corresponding timestep should be ignored.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the cell\n      when calling it. This is for use with cells that use dropout.\n    initial_state: List of initial state tensors to be passed to the first\n      call of the cell.\n    constants: List of constant tensors to be passed to the cell at each\n      timestep.\n\n  Input shape:\n    N-D tensor with shape `[batch_size, timesteps, ...]` or\n    `[timesteps, batch_size, ...]` when time_major is True.\n\n  Output shape:\n    - If `return_state`: a list of tensors. The first tensor is\n      the output. The remaining tensors are the last states,\n      each with shape `[batch_size, state_size]`, where `state_size` could\n      be a high dimension tensor shape.\n    - If `return_sequences`: N-D tensor with shape\n      `[batch_size, timesteps, output_size]`, where `output_size` could\n      be a high dimension tensor shape, or\n      `[timesteps, batch_size, output_size]` when `time_major` is True.\n    - Else, N-D tensor with shape `[batch_size, output_size]`, where\n      `output_size` could be a high dimension tensor shape.\n\n  Masking:\n    This layer supports masking for input data with a variable number\n    of timesteps. To introduce masks to your data,\n    use an [tf.keras.layers.Embedding] layer with the `mask_zero` parameter\n    set to `True`.\n\n  Note on using statefulness in RNNs:\n    You can set RNN layers to be 'stateful', which means that the states\n    computed for the samples in one batch will be reused as initial states\n    for the samples in the next batch. This assumes a one-to-one mapping\n    between samples in different successive batches.\n\n    To enable statefulness:\n      - Specify `stateful=True` in the layer constructor.\n      - Specify a fixed batch size for your model, by passing\n        If sequential model:\n          `batch_input_shape=(...)` to the first layer in your model.\n        Else for functional model with 1 or more Input layers:\n          `batch_shape=(...)` to all the first layers in your model.\n        This is the expected shape of your inputs\n        *including the batch size*.\n        It should be a tuple of integers, e.g. `(32, 10, 100)`.\n      - Specify `shuffle=False` when calling `fit()`.\n\n    To reset the states of your model, call `.reset_states()` on either\n    a specific layer, or on your entire model.\n\n  Note on specifying the initial state of RNNs:\n    You can specify the initial state of RNN layers symbolically by\n    calling them with the keyword argument `initial_state`. The value of\n    `initial_state` should be a tensor or list of tensors representing\n    the initial state of the RNN layer.\n\n    You can specify the initial state of RNN layers numerically by\n    calling `reset_states` with the keyword argument `states`. The value of\n    `states` should be a numpy array or list of numpy arrays representing\n    the initial state of the RNN layer.\n\n  Note on passing external constants to RNNs:\n    You can pass \"external\" constants to the cell using the `constants`\n    keyword argument of `RNN.__call__` (as well as `RNN.call`) method. This\n    requires that the `cell.call` method accepts the same keyword argument\n    `constants`. Such constants can be used to condition the cell\n    transformation on additional static inputs (not changing over time),\n    a.k.a. an attention mechanism.\n\n  Examples:\n\n  ```python\n  # First, let's define a RNN Cell, as a layer subclass.\n\n  class MinimalRNNCell(keras.layers.Layer):\n\n      def __init__(self, units, **kwargs):\n          self.units = units\n          self.state_size = units\n          super(MinimalRNNCell, self).__init__(**kwargs)\n\n      def build(self, input_shape):\n          self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                        initializer='uniform',\n                                        name='kernel')\n          self.recurrent_kernel = self.add_weight(\n              shape=(self.units, self.units),\n              initializer='uniform',\n              name='recurrent_kernel')\n          self.built = True\n\n      def call(self, inputs, states):\n          prev_output = states[0]\n          h = backend.dot(inputs, self.kernel)\n          output = h + backend.dot(prev_output, self.recurrent_kernel)\n          return output, [output]\n\n  # Let's use this cell in a RNN layer:\n\n  cell = MinimalRNNCell(32)\n  x = keras.Input((None, 5))\n  layer = RNN(cell)\n  y = layer(x)\n\n  # Here's how to use the cell to build a stacked RNN:\n\n  cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n  x = keras.Input((None, 5))\n  layer = RNN(cells)\n  y = layer(x)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "cell",
        "default": null
      },
      {
        "name": "return_sequences",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "return_state",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "go_backwards",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "stateful",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "unroll",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "time_major",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "initial_state",
        "default": "None"
      },
      {
        "name": "constants",
        "default": "None"
      }
    ],
    "file": "keras/layers/recurrent.py",
    "aliases": []
  },
  {
    "name": "RandomContrast",
    "base": "Layer",
    "docstring": "Adjust the contrast of an image or images by a random factor.\n\n  Contrast is adjusted independently for each channel of each image during\n  training.\n\n  For each channel, this layer computes the mean of the image pixels in the\n  channel and then adjusts each component `x` of each pixel to\n  `(x - mean) * contrast_factor + mean`.\n\n  Input shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\n  Output shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\n  Attributes:\n    factor: a positive float represented as fraction of value, or a tuple of\n      size 2 representing lower and upper bound. When represented as a single\n      float, lower = upper. The contrast factor will be randomly picked between\n      `[1.0 - lower, 1.0 + upper]`.\n    seed: Integer. Used to create a random seed.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "factor",
        "default": null
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "True",
        "type": "boolean"
      }
    ],
    "file": "keras/layers/preprocessing/image_preprocessing.py",
    "aliases": []
  },
  {
    "name": "RandomCrop",
    "base": "Layer",
    "docstring": "Randomly crop the images to target height and width.\n\n  This layer will crop all the images in the same batch to the same cropping\n  location.\n  By default, random cropping is only applied during training. At inference\n  time, the images will be first rescaled to preserve the shorter side, and\n  center cropped. If you need to apply random cropping at inference time,\n  set `training` to True when calling the layer.\n\n  Input shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\n  Output shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., target_height, target_width, channels)`.\n\n  Args:\n    height: Integer, the height of the output shape.\n    width: Integer, the width of the output shape.\n    seed: Integer. Used to create a random seed.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "height",
        "default": null
      },
      {
        "name": "width",
        "default": null
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "True",
        "type": "boolean"
      }
    ],
    "file": "keras/layers/preprocessing/image_preprocessing.py",
    "aliases": []
  },
  {
    "name": "RandomFlip",
    "base": "Layer",
    "docstring": "Randomly flip each image horizontally and vertically.\n\n  This layer will flip the images based on the `mode` attribute.\n  During inference time, the output will be identical to input. Call the layer\n  with `training=True` to flip the input.\n\n  Input shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\n  Output shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\n  Attributes:\n    mode: String indicating which flip mode to use. Can be `\"horizontal\"`,\n      `\"vertical\"`, or `\"horizontal_and_vertical\"`. Defaults to\n      `\"horizontal_and_vertical\"`. `\"horizontal\"` is a left-right flip and\n      `\"vertical\"` is a top-bottom flip.\n    seed: Integer. Used to create a random seed.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "mode",
        "default": "horizontal_and_vertical"
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "True",
        "type": "boolean"
      }
    ],
    "file": "keras/layers/preprocessing/image_preprocessing.py",
    "aliases": []
  },
  {
    "name": "RandomHeight",
    "base": "Layer",
    "docstring": "Randomly vary the height of a batch of images during training.\n\n  Adjusts the height of a batch of images by a random factor. The input\n  should be a 3D (unbatched) or 4D (batched) tensor in the `\"channels_last\"`\n  image data format.\n\n  By default, this layer is inactive during inference.\n\n  Args:\n    factor: A positive float (fraction of original height), or a tuple of size 2\n      representing lower and upper bound for resizing vertically. When\n      represented as a single float, this value is used for both the upper and\n      lower bound. For instance, `factor=(0.2, 0.3)` results in an output with\n      height changed by a random amount in the range `[20%, 30%]`.\n      `factor=(-0.2, 0.3)` results in an output with height changed by a random\n      amount in the range `[-20%, +30%]. `factor=0.2` results in an output with\n      height changed by a random amount in the range `[-20%, +20%]`.\n    interpolation: String, the interpolation method. Defaults to `\"bilinear\"`.\n      Supports `\"bilinear\"`, `\"nearest\"`, `\"bicubic\"`, `\"area\"`,\n      `\"lanczos3\"`, `\"lanczos5\"`, `\"gaussian\"`, `\"mitchellcubic\"`.\n    seed: Integer. Used to create a random seed.\n\n  Input shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\n  Output shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., random_height, width, channels)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "factor",
        "default": null
      },
      {
        "name": "interpolation",
        "default": "bilinear"
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "True",
        "type": "boolean"
      }
    ],
    "file": "keras/layers/preprocessing/image_preprocessing.py",
    "aliases": []
  },
  {
    "name": "RandomRotation",
    "base": "Layer",
    "docstring": "Randomly rotate each image.\n\n  By default, random rotations are only applied during training.\n  At inference time, the layer does nothing. If you need to apply random\n  rotations at inference time, set `training` to True when calling the layer.\n\n  Input shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format\n\n  Output shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format\n\n  Attributes:\n    factor: a float represented as fraction of 2 Pi, or a tuple of size 2\n      representing lower and upper bound for rotating clockwise and\n      counter-clockwise. A positive values means rotating counter clock-wise,\n      while a negative value means clock-wise. When represented as a single\n      float, this value is used for both the upper and lower bound. For\n      instance, `factor=(-0.2, 0.3)` results in an output rotation by a random\n      amount in the range `[-20% * 2pi, 30% * 2pi]`. `factor=0.2` results in an\n      output rotating by a random amount in the range `[-20% * 2pi, 20% * 2pi]`.\n    fill_mode: Points outside the boundaries of the input are filled according\n      to the given mode (one of `{\"constant\", \"reflect\", \"wrap\", \"nearest\"}`).\n      - *reflect*: `(d c b a | a b c d | d c b a)` The input is extended by\n        reflecting about the edge of the last pixel.\n      - *constant*: `(k k k k | a b c d | k k k k)` The input is extended by\n        filling all values beyond the edge with the same constant value k = 0.\n      - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by\n        wrapping around to the opposite edge.\n      - *nearest*: `(a a a a | a b c d | d d d d)` The input is extended by the\n        nearest pixel.\n    interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n      `\"bilinear\"`.\n    seed: Integer. Used to create a random seed.\n    fill_value: a float represents the value to be filled outside the boundaries\n      when `fill_mode=\"constant\"`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "factor",
        "default": null
      },
      {
        "name": "fill_mode",
        "default": "reflect"
      },
      {
        "name": "interpolation",
        "default": "bilinear"
      },
      {
        "name": "seed",
        "default": "None"
      },
      {
        "name": "fill_value",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "True",
        "type": "boolean"
      }
    ],
    "file": "keras/layers/preprocessing/image_preprocessing.py",
    "aliases": []
  },
  {
    "name": "RandomTranslation",
    "base": "Layer",
    "docstring": "Randomly translate each image during training.\n\n  Args:\n    height_factor: a float represented as fraction of value, or a tuple of size\n      2 representing lower and upper bound for shifting vertically. A negative\n      value means shifting image up, while a positive value means shifting image\n      down. When represented as a single positive float, this value is used for\n      both the upper and lower bound. For instance, `height_factor=(-0.2, 0.3)`\n      results in an output shifted by a random amount in the range\n      `[-20%, +30%]`.\n      `height_factor=0.2` results in an output height shifted by a random amount\n      in the range `[-20%, +20%]`.\n    width_factor: a float represented as fraction of value, or a tuple of size 2\n      representing lower and upper bound for shifting horizontally. A negative\n      value means shifting image left, while a positive value means shifting\n      image right. When represented as a single positive float, this value is\n      used for both the upper and lower bound. For instance,\n      `width_factor=(-0.2, 0.3)` results in an output shifted left by 20%, and\n      shifted right by 30%. `width_factor=0.2` results in an output height\n      shifted left or right by 20%.\n    fill_mode: Points outside the boundaries of the input are filled according\n      to the given mode (one of `{\"constant\", \"reflect\", \"wrap\", \"nearest\"}`).\n      - *reflect*: `(d c b a | a b c d | d c b a)` The input is extended by\n        reflecting about the edge of the last pixel.\n      - *constant*: `(k k k k | a b c d | k k k k)` The input is extended by\n        filling all values beyond the edge with the same constant value k = 0.\n      - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by\n        wrapping around to the opposite edge.\n      - *nearest*: `(a a a a | a b c d | d d d d)` The input is extended by the\n        nearest pixel.\n    interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n      `\"bilinear\"`.\n    seed: Integer. Used to create a random seed.\n    fill_value: a float represents the value to be filled outside the boundaries\n      when `fill_mode=\"constant\"`.\n\n  Input shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`,  in `\"channels_last\"` format.\n\n  Output shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`,  in `\"channels_last\"` format.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "height_factor",
        "default": null
      },
      {
        "name": "width_factor",
        "default": null
      },
      {
        "name": "fill_mode",
        "default": "reflect"
      },
      {
        "name": "interpolation",
        "default": "bilinear"
      },
      {
        "name": "seed",
        "default": "None"
      },
      {
        "name": "fill_value",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "True",
        "type": "boolean"
      }
    ],
    "file": "keras/layers/preprocessing/image_preprocessing.py",
    "aliases": []
  },
  {
    "name": "RandomWidth",
    "base": "Layer",
    "docstring": "Randomly vary the width of a batch of images during training.\n\n  Adjusts the width of a batch of images by a random factor. The input\n  should be a 3D (unbatched) or 4D (batched) tensor in the `\"channels_last\"`\n  image data format.\n\n  By default, this layer is inactive during inference.\n\n  Args:\n    factor: A positive float (fraction of original height), or a tuple of size 2\n      representing lower and upper bound for resizing vertically. When\n      represented as a single float, this value is used for both the upper and\n      lower bound. For instance, `factor=(0.2, 0.3)` results in an output with\n      width changed by a random amount in the range `[20%, 30%]`. `factor=(-0.2,\n      0.3)` results in an output with width changed by a random amount in the\n      range `[-20%, +30%]`. `factor=0.2` results in an output with width changed\n      by a random amount in the range `[-20%, +20%]`.\n    interpolation: String, the interpolation method. Defaults to `bilinear`.\n      Supports `\"bilinear\"`, `\"nearest\"`, `\"bicubic\"`, `\"area\"`, `\"lanczos3\"`,\n      `\"lanczos5\"`, `\"gaussian\"`, `\"mitchellcubic\"`.\n    seed: Integer. Used to create a random seed.\n\n  Input shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\n  Output shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., random_height, width, channels)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "factor",
        "default": null
      },
      {
        "name": "interpolation",
        "default": "bilinear"
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "True",
        "type": "boolean"
      }
    ],
    "file": "keras/layers/preprocessing/image_preprocessing.py",
    "aliases": []
  },
  {
    "name": "RandomZoom",
    "base": "Layer",
    "docstring": "Randomly zoom each image during training.\n\n  Args:\n    height_factor: a float represented as fraction of value, or a tuple of size\n      2 representing lower and upper bound for zooming vertically. When\n      represented as a single float, this value is used for both the upper and\n      lower bound. A positive value means zooming out, while a negative value\n      means zooming in. For instance, `height_factor=(0.2, 0.3)` result in an\n      output zoomed out by a random amount in the range `[+20%, +30%]`.\n      `height_factor=(-0.3, -0.2)` result in an output zoomed in by a random\n      amount in the range `[+20%, +30%]`.\n    width_factor: a float represented as fraction of value, or a tuple of size 2\n      representing lower and upper bound for zooming horizontally. When\n      represented as a single float, this value is used for both the upper and\n      lower bound. For instance, `width_factor=(0.2, 0.3)` result in an output\n      zooming out between 20% to 30%. `width_factor=(-0.3, -0.2)` result in an\n      output zooming in between 20% to 30%. Defaults to `None`, i.e., zooming\n      vertical and horizontal directions by preserving the aspect ratio.\n    fill_mode: Points outside the boundaries of the input are filled according\n      to the given mode (one of `{\"constant\", \"reflect\", \"wrap\", \"nearest\"}`).\n      - *reflect*: `(d c b a | a b c d | d c b a)` The input is extended by\n        reflecting about the edge of the last pixel.\n      - *constant*: `(k k k k | a b c d | k k k k)` The input is extended by\n        filling all values beyond the edge with the same constant value k = 0.\n      - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by\n        wrapping around to the opposite edge.\n      - *nearest*: `(a a a a | a b c d | d d d d)` The input is extended by the\n        nearest pixel.\n    interpolation: Interpolation mode. Supported values: `\"nearest\"`,\n      `\"bilinear\"`.\n    seed: Integer. Used to create a random seed.\n    fill_value: a float represents the value to be filled outside the boundaries\n      when `fill_mode=\"constant\"`.\n\n  Example:\n\n  >>> input_img = np.random.random((32, 224, 224, 3))\n  >>> layer = tf.keras.layers.RandomZoom(.5, .2)\n  >>> out_img = layer(input_img)\n  >>> out_img.shape\n  TensorShape([32, 224, 224, 3])\n\n  Input shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n\n  Output shape:\n    3D (unbatched) or 4D (batched) tensor with shape:\n    `(..., height, width, channels)`, in `\"channels_last\"` format.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "height_factor",
        "default": null
      },
      {
        "name": "width_factor",
        "default": "None"
      },
      {
        "name": "fill_mode",
        "default": "reflect"
      },
      {
        "name": "interpolation",
        "default": "bilinear"
      },
      {
        "name": "seed",
        "default": "None"
      },
      {
        "name": "fill_value",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "True",
        "type": "boolean"
      }
    ],
    "file": "keras/layers/preprocessing/image_preprocessing.py",
    "aliases": []
  },
  {
    "name": "ReLU",
    "base": "Layer",
    "docstring": "Rectified Linear Unit activation function.\n\n  With default values, it returns element-wise `max(x, 0)`.\n\n  Otherwise, it follows:\n\n  ```\n    f(x) = max_value if x >= max_value\n    f(x) = x if threshold <= x < max_value\n    f(x) = negative_slope * (x - threshold) otherwise\n  ```\n\n  Usage:\n\n  >>> layer = tf.keras.layers.ReLU()\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [0.0, 0.0, 0.0, 2.0]\n  >>> layer = tf.keras.layers.ReLU(max_value=1.0)\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [0.0, 0.0, 0.0, 1.0]\n  >>> layer = tf.keras.layers.ReLU(negative_slope=1.0)\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [-3.0, -1.0, 0.0, 2.0]\n  >>> layer = tf.keras.layers.ReLU(threshold=1.5)\n  >>> output = layer([-3.0, -1.0, 1.0, 2.0])\n  >>> list(output.numpy())\n  [0.0, 0.0, 0.0, 2.0]\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the batch axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as the input.\n\n  Args:\n    max_value: Float >= 0. Maximum activation value. Default to None, which\n      means unlimited.\n    negative_slope: Float >= 0. Negative slope coefficient. Default to 0.\n    threshold: Float >= 0. Threshold value for thresholded activation. Default\n      to 0.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "max_value",
        "default": "None"
      },
      {
        "name": "negative_slope",
        "default": 0
      },
      {
        "name": "threshold",
        "default": 0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/advanced_activations.py",
    "aliases": []
  },
  {
    "name": "RepeatVector",
    "base": "Layer",
    "docstring": "Repeats the input n times.\n\n  Example:\n\n  ```python\n  model = Sequential()\n  model.add(Dense(32, input_dim=32))\n  # now: model.output_shape == (None, 32)\n  # note: `None` is the batch dimension\n\n  model.add(RepeatVector(3))\n  # now: model.output_shape == (None, 3, 32)\n  ```\n\n  Args:\n    n: Integer, repetition factor.\n\n  Input shape:\n    2D tensor of shape `(num_samples, features)`.\n\n  Output shape:\n    3D tensor of shape `(num_samples, n, features)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "n",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "Rescaling",
    "base": "Layer",
    "docstring": "Multiply inputs by `scale` and adds `offset`.\n\n  For instance:\n\n  1. To rescale an input in the `[0, 255]` range\n  to be in the `[0, 1]` range, you would pass `scale=1./255`.\n\n  2. To rescale an input in the `[0, 255]` range to be in the `[-1, 1]` range,\n  you would pass `scale=1./127.5, offset=-1`.\n\n  The rescaling is applied both during training and inference.\n\n  Input shape:\n    Arbitrary.\n\n  Output shape:\n    Same as input.\n\n  Args:\n    scale: Float, the scale to apply to the inputs.\n    offset: Float, the offset to apply to the inputs.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "scale",
        "default": null
      },
      {
        "name": "offset",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/preprocessing/image_preprocessing.py",
    "aliases": []
  },
  {
    "name": "Reshape",
    "base": "Layer",
    "docstring": "Layer that reshapes inputs into the given shape.\n\n  Input shape:\n    Arbitrary, although all dimensions in the input shape must be known/fixed.\n    Use the keyword argument `input_shape` (tuple of integers, does not include\n    the samples/batch size axis) when using this layer as the first layer\n    in a model.\n\n  Output shape:\n    `(batch_size,) + target_shape`\n\n  Example:\n\n  >>> # as first layer in a Sequential model\n  >>> model = tf.keras.Sequential()\n  >>> model.add(tf.keras.layers.Reshape((3, 4), input_shape=(12,)))\n  >>> # model.output_shape == (None, 3, 4), `None` is the batch size.\n  >>> model.output_shape\n  (None, 3, 4)\n\n  >>> # as intermediate layer in a Sequential model\n  >>> model.add(tf.keras.layers.Reshape((6, 2)))\n  >>> model.output_shape\n  (None, 6, 2)\n\n  >>> # also supports shape inference using `-1` as dimension\n  >>> model.add(tf.keras.layers.Reshape((-1, 2, 2)))\n  >>> model.output_shape\n  (None, 3, 2, 2)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "target_shape",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "Resizing",
    "base": "Layer",
    "docstring": "Image resizing layer.\n\n  Resize the batched image input to target height and width. The input should\n  be a 4D (batched) or 3D (unbatched) tensor in `\"channels_last\"` format.\n\n  Args:\n    height: Integer, the height of the output shape.\n    width: Integer, the width of the output shape.\n    interpolation: String, the interpolation method. Defaults to `\"bilinear\"`.\n      Supports `\"bilinear\"`, `\"nearest\"`, `\"bicubic\"`, `\"area\"`, `\"lanczos3\"`,\n      `\"lanczos5\"`, `\"gaussian\"`, `\"mitchellcubic\"`.\n    crop_to_aspect_ratio: If True, resize the images without aspect\n      ratio distortion. When the original aspect ratio differs from the target\n      aspect ratio, the output image will be cropped so as to return the largest\n      possible window in the image (of size `(height, width)`) that matches\n      the target aspect ratio. By default (`crop_to_aspect_ratio=False`),\n      aspect ratio may not be preserved.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "height",
        "default": null
      },
      {
        "name": "width",
        "default": null
      },
      {
        "name": "interpolation",
        "default": "bilinear"
      },
      {
        "name": "crop_to_aspect_ratio",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/preprocessing/image_preprocessing.py",
    "aliases": []
  },
  {
    "name": "SeparableConv1D",
    "base": "SeparableConv",
    "docstring": "Depthwise separable 1D convolution.\n\n  This layer performs a depthwise convolution that acts separately on\n  channels, followed by a pointwise convolution that mixes channels.\n  If `use_bias` is True and a bias initializer is provided,\n  it adds a bias vector to the output.\n  It then optionally applies an activation function to produce the final output.\n\n  Args:\n    filters: Integer, the dimensionality of the output space (i.e. the number\n      of filters in the convolution).\n    kernel_size: A single integer specifying the spatial\n      dimensions of the filters.\n    strides: A single integer specifying the strides\n      of the convolution.\n      Specifying any `stride` value != 1 is incompatible with specifying\n      any `dilation_rate` value != 1.\n    padding: One of `\"valid\"`, `\"same\"`, or `\"causal\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n      to the left/right or up/down of the input such that output has the same\n      height/width dimension as the input. `\"causal\"` results in causal\n      (dilated) convolutions, e.g. `output[t]` does not depend on `input[t+1:]`.\n    data_format: A string, one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, length, channels)` while `channels_first` corresponds to\n      inputs with shape `(batch_size, channels, length)`.\n    dilation_rate: A single integer, specifying\n      the dilation rate to use for dilated convolution.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any stride value != 1.\n    depth_multiplier: The number of depthwise convolution output channels for\n      each input channel. The total number of depthwise convolution output\n      channels will be equal to `num_filters_in * depth_multiplier`.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias.\n    depthwise_initializer: An initializer for the depthwise convolution kernel (\n      see `keras.initializers`). If None, then the default initializer (\n      'glorot_uniform') will be used.\n    pointwise_initializer: An initializer for the pointwise convolution kernel (\n      see `keras.initializers`). If None, then the default initializer \n      ('glorot_uniform') will be used.\n    bias_initializer: An initializer for the bias vector. If None, the default\n      initializer ('zeros') will be used (see `keras.initializers`).\n    depthwise_regularizer: Optional regularizer for the depthwise\n      convolution kernel (see `keras.regularizers`).\n    pointwise_regularizer: Optional regularizer for the pointwise\n      convolution kernel (see `keras.regularizers`).\n    bias_regularizer: Optional regularizer for the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Optional regularizer function for the output (\n      see `keras.regularizers`).\n    depthwise_constraint: Optional projection function to be applied to the\n      depthwise kernel after being updated by an `Optimizer` (e.g. used for\n      norm constraints or value constraints for layer weights). The function\n      must take as input the unprojected variable and must return the\n      projected variable (which must have the same shape). Constraints are\n      not safe to use when doing asynchronous distributed training (\n      see `keras.constraints`).\n    pointwise_constraint: Optional projection function to be applied to the\n      pointwise kernel after being updated by an `Optimizer` (\n      see `keras.constraints`).\n    bias_constraint: Optional projection function to be applied to the\n      bias after being updated by an `Optimizer` (\n      see `keras.constraints`).\n    trainable: Boolean, if `True` the weights of this layer will be marked as\n      trainable (and listed in `layer.trainable_weights`).\n\n  Input shape:\n    3D tensor with shape:\n    `(batch_size, channels, steps)` if data_format='channels_first'\n    or 5D tensor with shape:\n    `(batch_size, steps, channels)` if data_format='channels_last'.\n\n  Output shape:\n    3D tensor with shape:\n    `(batch_size, filters, new_steps)` if data_format='channels_first'\n    or 3D tensor with shape:\n    `(batch_size,  new_steps, filters)` if data_format='channels_last'.\n    `new_steps` value might have changed due to padding or strides.\n\n  Returns:\n    A tensor of rank 3 representing\n    `activation(separableconv1d(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": 1
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": 1
      },
      {
        "name": "depth_multiplier",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "depthwise_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "pointwise_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "depthwise_regularizer",
        "default": "None"
      },
      {
        "name": "pointwise_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "depthwise_constraint",
        "default": "None"
      },
      {
        "name": "pointwise_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": [
      "SeparableConvolution1D"
    ]
  },
  {
    "name": "SeparableConv2D",
    "base": "SeparableConv",
    "docstring": "Depthwise separable 2D convolution.\n\n  Separable convolutions consist of first performing\n  a depthwise spatial convolution\n  (which acts on each input channel separately)\n  followed by a pointwise convolution which mixes the resulting\n  output channels. The `depth_multiplier` argument controls how many\n  output channels are generated per input channel in the depthwise step.\n\n  Intuitively, separable convolutions can be understood as\n  a way to factorize a convolution kernel into two smaller kernels,\n  or as an extreme version of an Inception block.\n\n  Args:\n    filters: Integer, the dimensionality of the output space\n      (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers, specifying the\n      height and width of the 2D convolution window.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers,\n      specifying the strides of the convolution along the height and width.\n      Can be a single integer to specify the same value for\n      all spatial dimensions. Current implementation only supports equal \n      length strides in the row and column dimensions.\n      Specifying any stride value != 1 is incompatible with specifying\n      any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n      to the left/right or up/down of the input such that output has the same\n      height/width dimension as the input.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n    dilation_rate: An integer or tuple/list of 2 integers, specifying\n      the dilation rate to use for dilated convolution.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any `strides` value != 1.\n    depth_multiplier: The number of depthwise convolution output channels\n      for each input channel.\n      The total number of depthwise convolution output\n      channels will be equal to `filters_in * depth_multiplier`.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    depthwise_initializer: An initializer for the depthwise convolution kernel (\n      see `keras.initializers`). If None, then the default initializer (\n      'glorot_uniform') will be used.\n    pointwise_initializer: An initializer for the pointwise convolution kernel (\n      see `keras.initializers`). If None, then the default initializer \n      ('glorot_uniform') will be used.\n    bias_initializer: An initializer for the bias vector. If None, the default\n      initializer ('zeros') will be used (see `keras.initializers`).\n    depthwise_regularizer: Regularizer function applied to\n      the depthwise kernel matrix (see `keras.regularizers`).\n    pointwise_regularizer: Regularizer function applied to\n      the pointwise kernel matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its \"activation\") (\n      see `keras.regularizers`).\n    depthwise_constraint: Constraint function applied to\n      the depthwise kernel matrix (\n      see `keras.constraints`).\n    pointwise_constraint: Constraint function applied to\n      the pointwise kernel matrix (\n      see `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (\n      see `keras.constraints`).\n\n  Input shape:\n    4D tensor with shape:\n    `(batch_size, channels, rows, cols)` if data_format='channels_first'\n    or 4D tensor with shape:\n    `(batch_size, rows, cols, channels)` if data_format='channels_last'.\n\n  Output shape:\n    4D tensor with shape:\n    `(batch_size, filters, new_rows, new_cols)` if data_format='channels_first'\n    or 4D tensor with shape:\n    `(batch_size, new_rows, new_cols, filters)` if data_format='channels_last'.\n    `rows` and `cols` values might have changed due to padding.\n\n  Returns:\n    A tensor of rank 4 representing\n    `activation(separableconv2d(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is \"causal\".\n    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "depth_multiplier",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "depthwise_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "pointwise_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "depthwise_regularizer",
        "default": "None"
      },
      {
        "name": "pointwise_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "depthwise_constraint",
        "default": "None"
      },
      {
        "name": "pointwise_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": [
      "SeparableConvolution2D"
    ]
  },
  {
    "name": "SimpleRNN",
    "base": "RNN",
    "docstring": "Fully-connected RNN where the output is to be fed back to input.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  Args:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n      Default: hyperbolic tangent (`tanh`).\n      If you pass None, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n      used for the linear transformation of the inputs. Default:\n      `glorot_uniform`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n      weights matrix, used for the linear transformation of the recurrent state.\n      Default: `orthogonal`.\n    bias_initializer: Initializer for the bias vector. Default: `zeros`.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector. Default:\n      `None`.\n    activity_regularizer: Regularizer function applied to the output of the\n      layer (its \"activation\"). Default: `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix.  Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector. Default:\n      `None`.\n    dropout: Float between 0 and 1.\n      Fraction of the units to drop for the linear transformation of the inputs.\n      Default: 0.\n    recurrent_dropout: Float between 0 and 1.\n      Fraction of the units to drop for the linear transformation of the\n      recurrent state. Default: 0.\n    return_sequences: Boolean. Whether to return the last output\n      in the output sequence, or the full sequence. Default: `False`.\n    return_state: Boolean. Whether to return the last state\n      in addition to the output. Default: `False`\n    go_backwards: Boolean (default False).\n      If True, process the input sequence backwards and return the\n      reversed sequence.\n    stateful: Boolean (default False). If True, the last state\n      for each sample at index i in a batch will be used as initial\n      state for the sample of index i in the following batch.\n    unroll: Boolean (default False).\n      If True, the network will be unrolled,\n      else a symbolic loop will be used.\n      Unrolling can speed-up a RNN,\n      although it tends to be more memory-intensive.\n      Unrolling is only suitable for short sequences.\n\n  Call arguments:\n    inputs: A 3D tensor, with shape `[batch, timesteps, feature]`.\n    mask: Binary tensor of shape `[batch, timesteps]` indicating whether\n      a given timestep should be masked. An individual `True` entry indicates\n      that the corresponding timestep should be utilized, while a `False` entry\n      indicates that the corresponding timestep should be ignored.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the cell\n      when calling it. This is only relevant if `dropout` or\n      `recurrent_dropout` is used.\n    initial_state: List of initial state tensors to be passed to the first\n      call of the cell.\n\n  Examples:\n\n  ```python\n  inputs = np.random.random([32, 10, 8]).astype(np.float32)\n  simple_rnn = tf.keras.layers.SimpleRNN(4)\n\n  output = simple_rnn(inputs)  # The output has shape `[32, 4]`.\n\n  simple_rnn = tf.keras.layers.SimpleRNN(\n      4, return_sequences=True, return_state=True)\n\n  # whole_sequence_output has shape `[32, 10, 4]`.\n  # final_state has shape `[32, 4]`.\n  whole_sequence_output, final_state = simple_rnn(inputs)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      },
      {
        "name": "return_sequences",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "return_state",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "go_backwards",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "stateful",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "unroll",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "initial_state",
        "default": "None"
      }
    ],
    "file": "keras/layers/recurrent.py",
    "aliases": []
  },
  {
    "name": "SimpleRNNCell",
    "base": "DropoutRNNCellMixin",
    "docstring": "Cell class for SimpleRNN.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  This class processes one step within the whole time sequence input, whereas\n  `tf.keras.layer.SimpleRNN` processes the whole sequence.\n\n  Args:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n      Default: hyperbolic tangent (`tanh`).\n      If you pass `None`, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n      used for the linear transformation of the inputs. Default:\n      `glorot_uniform`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n      weights matrix, used for the linear transformation of the recurrent state.\n      Default: `orthogonal`.\n    bias_initializer: Initializer for the bias vector. Default: `zeros`.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector. Default:\n      `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector. Default:\n      `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the linear\n      transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state. Default: 0.\n\n  Call arguments:\n    inputs: A 2D tensor, with shape of `[batch, feature]`.\n    states: A 2D tensor with shape of `[batch, units]`, which is the state from\n      the previous time step. For timestep 0, the initial state provided by user\n      will be feed to cell.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. Only relevant when `dropout` or\n      `recurrent_dropout` is used.\n\n  Examples:\n\n  ```python\n  inputs = np.random.random([32, 10, 8]).astype(np.float32)\n  rnn = tf.keras.layers.RNN(tf.keras.layers.SimpleRNNCell(4))\n\n  output = rnn(inputs)  # The output has shape `[32, 4]`.\n\n  rnn = tf.keras.layers.RNN(\n      tf.keras.layers.SimpleRNNCell(4),\n      return_sequences=True,\n      return_state=True)\n\n  # whole_sequence_output has shape `[32, 10, 4]`.\n  # final_state has shape `[32, 4]`.\n  whole_sequence_output, final_state = rnn(inputs)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "states",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/recurrent.py",
    "aliases": []
  },
  {
    "name": "Softmax",
    "base": "Layer",
    "docstring": "Softmax activation function.\n\n  Example without mask:\n\n  >>> inp = np.asarray([1., 2., 1.])\n  >>> layer = tf.keras.layers.Softmax()\n  >>> layer(inp).numpy()\n  array([0.21194157, 0.5761169 , 0.21194157], dtype=float32)\n  >>> mask = np.asarray([True, False, True], dtype=bool)\n  >>> layer(inp, mask).numpy()\n  array([0.5, 0. , 0.5], dtype=float32)\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as the input.\n\n  Args:\n    axis: Integer, or list of Integers, axis along which the softmax\n      normalization is applied.\n  Call arguments:\n    inputs: The inputs, or logits to the softmax layer.\n    mask: A boolean mask of the same shape as `inputs`. Defaults to `None`. The\n      mask specifies 1 to keep and 0 to mask.\n\n  Returns:\n    softmaxed output with the same shape as `inputs`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "axis",
        "default": -1
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "keras/layers/advanced_activations.py",
    "aliases": []
  },
  {
    "name": "SpatialDropout1D",
    "base": "Dropout",
    "docstring": "Spatial 1D version of Dropout.\n\n  This version performs the same function as Dropout, however, it drops\n  entire 1D feature maps instead of individual elements. If adjacent frames\n  within feature maps are strongly correlated (as is normally the case in\n  early convolution layers) then regular dropout will not regularize the\n  activations and will otherwise just result in an effective learning rate\n  decrease. In this case, SpatialDropout1D will help promote independence\n  between feature maps and should be used instead.\n\n  Args:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n\n  Call arguments:\n    inputs: A 3D tensor.\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n\n  Input shape:\n    3D tensor with shape:\n    `(samples, timesteps, channels)`\n\n  Output shape:\n    Same as input.\n\n  References:\n    - [Efficient Object Localization Using Convolutional\n      Networks](https://arxiv.org/abs/1411.4280)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "SpatialDropout2D",
    "base": "Dropout",
    "docstring": "Spatial 2D version of Dropout.\n\n  This version performs the same function as Dropout, however, it drops\n  entire 2D feature maps instead of individual elements. If adjacent pixels\n  within feature maps are strongly correlated (as is normally the case in\n  early convolution layers) then regular dropout will not regularize the\n  activations and will otherwise just result in an effective learning rate\n  decrease. In this case, SpatialDropout2D will help promote independence\n  between feature maps and should be used instead.\n\n  Args:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n    data_format: 'channels_first' or 'channels_last'.\n      In 'channels_first' mode, the channels dimension\n      (the depth) is at index 1,\n      in 'channels_last' mode is it at index 3.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Call arguments:\n    inputs: A 4D tensor.\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n\n  Input shape:\n    4D tensor with shape:\n    `(samples, channels, rows, cols)` if data_format='channels_first'\n    or 4D tensor with shape:\n    `(samples, rows, cols, channels)` if data_format='channels_last'.\n\n  Output shape:\n    Same as input.\n\n  References:\n    - [Efficient Object Localization Using Convolutional\n      Networks](https://arxiv.org/abs/1411.4280)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "SpatialDropout3D",
    "base": "Dropout",
    "docstring": "Spatial 3D version of Dropout.\n\n  This version performs the same function as Dropout, however, it drops\n  entire 3D feature maps instead of individual elements. If adjacent voxels\n  within feature maps are strongly correlated (as is normally the case in\n  early convolution layers) then regular dropout will not regularize the\n  activations and will otherwise just result in an effective learning rate\n  decrease. In this case, SpatialDropout3D will help promote independence\n  between feature maps and should be used instead.\n\n  Args:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n    data_format: 'channels_first' or 'channels_last'.\n        In 'channels_first' mode, the channels dimension (the depth)\n        is at index 1, in 'channels_last' mode is it at index 4.\n        It defaults to the `image_data_format` value found in your\n        Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\".\n\n  Call arguments:\n    inputs: A 5D tensor.\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n\n  Input shape:\n    5D tensor with shape:\n    `(samples, channels, dim1, dim2, dim3)` if data_format='channels_first'\n    or 5D tensor with shape:\n    `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'.\n\n  Output shape:\n    Same as input.\n\n  References:\n    - [Efficient Object Localization Using Convolutional\n      Networks](https://arxiv.org/abs/1411.4280)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "StackedRNNCells",
    "base": "Layer",
    "docstring": "Wrapper allowing a stack of RNN cells to behave as a single cell.\n\n  Used to implement efficient stacked RNNs.\n\n  Args:\n    cells: List of RNN cell instances.\n\n  Examples:\n\n  ```python\n  batch_size = 3\n  sentence_max_length = 5\n  n_features = 2\n  new_shape = (batch_size, sentence_max_length, n_features)\n  x = tf.constant(np.reshape(np.arange(30), new_shape), dtype = tf.float32)\n\n  rnn_cells = [tf.keras.layers.LSTMCell(128) for _ in range(2)]\n  stacked_lstm = tf.keras.layers.StackedRNNCells(rnn_cells)\n  lstm_layer = tf.keras.layers.RNN(stacked_lstm)\n\n  result = lstm_layer(x)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "cells",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "states",
        "default": null
      },
      {
        "name": "constants",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "keras/layers/recurrent.py",
    "aliases": []
  },
  {
    "name": "StringLookup",
    "base": "IndexLookup",
    "docstring": "Maps strings from a vocabulary to integer indices.\n\n  This layer translates a set of arbitrary strings into an integer output via a\n  table-based vocabulary lookup.\n\n  The vocabulary for the layer can be supplied on construction or learned via\n  `adapt()`. During `adapt()`, the layer will analyze a data set, determine the\n  frequency of individual strings tokens, and create a vocabulary from them. If\n  the vocabulary is capped in size, the most frequent tokens will be used to\n  create the vocabulary and all others will be treated as out-of-vocabulary\n  (OOV).\n\n  There are two possible output modes for the layer.\n  When `output_mode` is `\"int\"`,\n  input strings are converted to their index in the vocabulary (an integer).\n  When `output_mode` is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`, input strings\n  are encoded into an array where each dimension corresponds to an element in\n  the vocabulary.\n\n  The vocabulary can optionally contain a mask token as well as an OOV token\n  (which can optionally occupy multiple indices in the vocabulary, as set\n  by `num_oov_indices`).\n  The position of these tokens in the vocabulary is fixed. When `output_mode` is\n  `\"int\"`, the vocabulary will begin with the mask token (if set), followed by\n  OOV indices, followed by the rest of the vocabulary. When `output_mode` is\n  `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"` the vocabulary will begin with OOV\n  indices and instances of the mask token will be dropped.\n\n  Args:\n    max_tokens: The maximum size of the vocabulary for this layer. If None,\n      there is no cap on the size of the vocabulary. Note that this size\n      includes the OOV and mask tokens. Default to None.\n    num_oov_indices: The number of out-of-vocabulary tokens to use. If this\n      value is more than 1, OOV inputs are hashed to determine their OOV value.\n      If this value is 0, OOV inputs will cause an error when calling the layer.\n      Defaults to 1.\n    mask_token: A token that represents masked inputs. When `output_mode` is\n      `\"int\"`, the token is included in vocabulary and mapped to index 0. In\n      other output modes, the token will not appear in the vocabulary and\n      instances of the mask token in the input will be dropped. If set to None,\n      no mask term will be added. Defaults to `None`.\n    oov_token: Only used when `invert` is True. The token to return for OOV\n      indices. Defaults to `\"[UNK]\"`.\n    vocabulary: Optional. Either an array of strings or a string path to a text\n      file. If passing an array, can pass a tuple, list, 1D numpy array, or 1D\n      tensor containing the string vocbulary terms. If passing a file path, the\n      file should contain one line per term in the vocabulary. If this argument\n      is set, there is no need to `adapt` the layer.\n    invert: Only valid when `output_mode` is `\"int\"`. If True, this layer will\n      map indices to vocabulary items instead of mapping vocabulary items to\n      indices. Default to False.\n    output_mode: Specification for the output of the layer. Defaults to `\"int\"`.\n      Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, `\"count\"`, or\n      `\"tf_idf\"` configuring the layer as follows:\n        - `\"int\"`: Return the raw integer indices of the input tokens.\n        - `\"one_hot\"`: Encodes each individual element in the input into an\n          array the same size as the vocabulary, containing a 1 at the element\n          index. If the last dimension is size 1, will encode on that dimension.\n          If the last dimension is not size 1, will append a new dimension for\n          the encoded output.\n        - `\"multi_hot\"`: Encodes each sample in the input into a single array\n          the same size as the vocabulary, containing a 1 for each vocabulary\n          term present in the sample. Treats the last dimension as the sample\n          dimension, if input shape is (..., sample_length), output shape will\n          be (..., num_tokens).\n        - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of the\n          number of times the token at that index appeared in the sample.\n        - `\"tf_idf\"`: As `\"multi_hot\"`, but the TF-IDF algorithm is applied to\n          find the value in each token slot.\n      For `\"int\"` output, any shape of input and output is supported. For all\n      other output modes, currently only output up to rank 2 is supported.\n    pad_to_max_tokens: Only applicable when `output_mode` is `\"multi_hot\"`,\n      `\"count\"`, or `\"tf_idf\"`. If True, the output will have its feature axis\n      padded to `max_tokens` even if the number of unique tokens in the\n      vocabulary is less than max_tokens, resulting in a tensor of shape\n      [batch_size, max_tokens] regardless of vocabulary size. Defaults to False.\n    sparse: Boolean. Only applicable when `output_mode` is `\"multi_hot\"`,\n      `\"count\"`, or `\"tf_idf\"`. If True, returns a `SparseTensor` instead of a\n      dense `Tensor`. Defaults to False.\n\n  Examples:\n\n  **Creating a lookup layer with a known vocabulary**\n\n  This example creates a lookup layer with a pre-existing vocabulary.\n\n  >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n  >>> data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n  >>> layer = tf.keras.layers.StringLookup(vocabulary=vocab)\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n  array([[1, 3, 4],\n         [4, 0, 2]])>\n\n  **Creating a lookup layer with an adapted vocabulary**\n\n  This example creates a lookup layer and generates the vocabulary by analyzing\n  the dataset.\n\n  >>> data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n  >>> layer = tf.keras.layers.StringLookup()\n  >>> layer.adapt(data)\n  >>> layer.get_vocabulary()\n  ['[UNK]', 'd', 'z', 'c', 'b', 'a']\n\n  Note that the OOV token `\"[UNK]\"` has been added to the vocabulary.\n  The remaining tokens are sorted by frequency\n  (`\"d\"`, which has 2 occurrences, is first) then by inverse sort order.\n\n  >>> data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n  >>> layer = tf.keras.layers.StringLookup()\n  >>> layer.adapt(data)\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n  array([[5, 3, 1],\n         [1, 2, 4]])>\n\n  **Lookups with multiple OOV indices**\n\n  This example demonstrates how to use a lookup layer with multiple OOV indices.\n  When a layer is created with more than one OOV index, any OOV values are\n  hashed into the number of OOV buckets, distributing OOV values in a\n  deterministic fashion across the set.\n\n  >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n  >>> data = tf.constant([[\"a\", \"c\", \"d\"], [\"m\", \"z\", \"b\"]])\n  >>> layer = tf.keras.layers.StringLookup(vocabulary=vocab, num_oov_indices=2)\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n  array([[2, 4, 5],\n         [0, 1, 3]])>\n\n  Note that the output for OOV value 'm' is 0, while the output for OOV value\n  'z' is 1. The in-vocab terms have their output index increased by 1 from\n  earlier examples (a maps to 2, etc) in order to make space for the extra OOV\n  value.\n\n  **One-hot output**\n\n  Configure the layer with `output_mode='one_hot'`. Note that the first\n  `num_oov_indices` dimensions in the ont_hot encoding represent OOV values.\n\n  >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n  >>> data = tf.constant([\"a\", \"b\", \"c\", \"d\", \"z\"])\n  >>> layer = tf.keras.layers.StringLookup(\n  ...     vocabulary=vocab, output_mode='one_hot')\n  >>> layer(data)\n  <tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n    array([[0., 1., 0., 0., 0.],\n           [0., 0., 1., 0., 0.],\n           [0., 0., 0., 1., 0.],\n           [0., 0., 0., 0., 1.],\n           [1., 0., 0., 0., 0.]], dtype=float32)>\n\n  **Multi-hot output**\n\n  Configure the layer with `output_mode='multi_hot'`. Note that the first\n  `num_oov_indices` dimensions in the multi_hot encoding represent OOV values.\n\n  >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n  >>> data = tf.constant([[\"a\", \"c\", \"d\", \"d\"], [\"d\", \"z\", \"b\", \"z\"]])\n  >>> layer = tf.keras.layers.StringLookup(\n  ...     vocabulary=vocab, output_mode='multi_hot')\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n    array([[0., 1., 0., 1., 1.],\n           [1., 0., 1., 0., 1.]], dtype=float32)>\n\n  **Token count output**\n\n  Configure the layer with `output_mode='count'`. As with multi_hot output, the\n  first `num_oov_indices` dimensions in the output represent OOV values.\n\n  >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n  >>> data = tf.constant([[\"a\", \"c\", \"d\", \"d\"], [\"d\", \"z\", \"b\", \"z\"]])\n  >>> layer = tf.keras.layers.StringLookup(\n  ...     vocabulary=vocab, output_mode='count')\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n    array([[0., 1., 0., 1., 2.],\n           [2., 0., 1., 0., 1.]], dtype=float32)>\n\n  **TF-IDF output**\n\n  Configure the layer with `output_mode=\"tf_idf\"`. As with multi_hot output, the\n  first `num_oov_indices` dimensions in the output represent OOV values.\n\n  Each token bin will output `token_count * idf_weight`, where the idf weights\n  are the inverse document frequency weights per token. These should be provided\n  along with the vocabulary. Note that the `idf_weight` for OOV values will\n  default to the average of all idf weights passed in.\n\n  >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n  >>> idf_weights = [0.25, 0.75, 0.6, 0.4]\n  >>> data = tf.constant([[\"a\", \"c\", \"d\", \"d\"], [\"d\", \"z\", \"b\", \"z\"]])\n  >>> layer = tf.keras.layers.StringLookup(output_mode=\"tf_idf\")\n  >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n           [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)>\n\n  To specify the idf weights for oov values, you will need to pass the entire\n  vocabularly including the leading oov token.\n\n  >>> vocab = [\"[UNK]\", \"a\", \"b\", \"c\", \"d\"]\n  >>> idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]\n  >>> data = tf.constant([[\"a\", \"c\", \"d\", \"d\"], [\"d\", \"z\", \"b\", \"z\"]])\n  >>> layer = tf.keras.layers.StringLookup(output_mode=\"tf_idf\")\n  >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n           [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)>\n\n  When adapting the layer in `\"tf_idf\"` mode, each input sample will be\n  considered a document, and IDF weight per token will be calculated as\n  `log(1 + num_documents / (1 + token_document_count))`.\n\n  **Inverse lookup**\n\n  This example demonstrates how to map indices to strings using this layer. (You\n  can also use `adapt()` with `inverse=True`, but for simplicity we'll pass the\n  vocab in this example.)\n\n  >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n  >>> data = tf.constant([[1, 3, 4], [4, 0, 2]])\n  >>> layer = tf.keras.layers.StringLookup(vocabulary=vocab, invert=True)\n  >>> layer(data)\n  <tf.Tensor: shape=(2, 3), dtype=string, numpy=\n  array([[b'a', b'c', b'd'],\n         [b'd', b'[UNK]', b'b']], dtype=object)>\n\n  Note that the first index correspond to the oov token by default.\n\n\n  **Forward and inverse lookup pairs**\n\n  This example demonstrates how to use the vocabulary of a standard lookup\n  layer to create an inverse lookup layer.\n\n  >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n  >>> data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n  >>> layer = tf.keras.layers.StringLookup(vocabulary=vocab)\n  >>> i_layer = tf.keras.layers.StringLookup(vocabulary=vocab, invert=True)\n  >>> int_data = layer(data)\n  >>> i_layer(int_data)\n  <tf.Tensor: shape=(2, 3), dtype=string, numpy=\n  array([[b'a', b'c', b'd'],\n         [b'd', b'[UNK]', b'b']], dtype=object)>\n\n  In this example, the input value `\"z\"` resulted in an output of `\"[UNK]\"`,\n  since 1000 was not in the vocabulary - it got represented as an OOV, and all\n  OOV values are returned as `\"[UNK]\"` in the inverse layer. Also, note that\n  for the inverse to work, you must have already set the forward layer\n  vocabulary either directly or via `adapt()` before calling `get_vocabulary()`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "max_tokens",
        "default": "None"
      },
      {
        "name": "num_oov_indices",
        "default": 1
      },
      {
        "name": "mask_token",
        "default": "None"
      },
      {
        "name": "oov_token",
        "default": "[UNK]"
      },
      {
        "name": "vocabulary",
        "default": "None"
      },
      {
        "name": "encoding",
        "default": "None"
      },
      {
        "name": "invert",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "output_mode",
        "default": "int"
      },
      {
        "name": "sparse",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "pad_to_max_tokens",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/preprocessing/string_lookup.py",
    "aliases": []
  },
  {
    "name": "Subtract",
    "base": "_Merge",
    "docstring": "Layer that subtracts two inputs.\n\n  It takes as input a list of tensors of size 2,\n  both of the same shape, and returns a single tensor, (inputs[0] - inputs[1]),\n  also of the same shape.\n\n  Examples:\n\n  ```python\n      import keras\n\n      input1 = keras.layers.Input(shape=(16,))\n      x1 = keras.layers.Dense(8, activation='relu')(input1)\n      input2 = keras.layers.Input(shape=(32,))\n      x2 = keras.layers.Dense(8, activation='relu')(input2)\n      # Equivalent to subtracted = keras.layers.subtract([x1, x2])\n      subtracted = keras.layers.Subtract()([x1, x2])\n\n      out = keras.layers.Dense(4)(subtracted)\n      model = keras.models.Model(inputs=[input1, input2], outputs=out)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "TextVectorization",
    "base": "PreprocessingLayer",
    "docstring": "Text vectorization layer.\n\n  This layer has basic options for managing text in a Keras model. It\n  transforms a batch of strings (one example = one string) into either a list of\n  token indices (one example = 1D tensor of integer token indices) or a dense\n  representation (one example = 1D tensor of float values representing data\n  about the example's tokens).\n\n  If desired, the user can call this layer's `adapt()` method on a dataset.\n  When this layer is adapted, it will analyze the dataset, determine the\n  frequency of individual string values, and create a 'vocabulary' from them.\n  This vocabulary can have unlimited size or be capped, depending on the\n  configuration options for this layer; if there are more unique values in the\n  input than the maximum vocabulary size, the most frequent terms will be used\n  to create the vocabulary.\n\n  The processing of each example contains the following steps:\n\n  1. Standardize each example (usually lowercasing + punctuation stripping)\n  2. Split each example into substrings (usually words)\n  3. Recombine substrings into tokens (usually ngrams)\n  4. Index tokens (associate a unique int value with each token)\n  5. Transform each example using this index, either into a vector of ints or\n     a dense float vector.\n\n  Some notes on passing callables to customize splitting and normalization for\n  this layer:\n\n  1. Any callable can be passed to this Layer, but if you want to serialize\n     this object you should only pass functions that are registered Keras\n     serializables (see `tf.keras.utils.register_keras_serializable` for more\n     details).\n  2. When using a custom callable for `standardize`, the data received\n     by the callable will be exactly as passed to this layer. The callable\n     should return a tensor of the same shape as the input.\n  3. When using a custom callable for `split`, the data received by the\n     callable will have the 1st dimension squeezed out - instead of\n     `[[\"string to split\"], [\"another string to split\"]]`, the Callable will\n     see `[\"string to split\", \"another string to split\"]`. The callable should\n     return a Tensor with the first dimension containing the split tokens -\n     in this example, we should see something like `[[\"string\", \"to\",\n     \"split\"], [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable\n     site natively compatible with `tf.strings.split()`.\n\n  Args:\n    max_tokens: The maximum size of the vocabulary for this layer. If None,\n      there is no cap on the size of the vocabulary. Note that this vocabulary\n      contains 1 OOV token, so the effective number of tokens is `(max_tokens -\n      1 - (1 if output_mode == \"int\" else 0))`.\n    standardize: Optional specification for standardization to apply to the\n      input text. Values can be None (no standardization),\n      `\"lower_and_strip_punctuation\"` (lowercase and remove punctuation) or a\n      Callable. Default is `\"lower_and_strip_punctuation\"`.\n    split: Optional specification for splitting the input text. Values can be\n      None (no splitting), `\"whitespace\"` (split on ASCII whitespace), or a\n      Callable. The default is `\"whitespace\"`.\n    ngrams: Optional specification for ngrams to create from the possibly-split\n      input text. Values can be None, an integer or tuple of integers; passing\n      an integer will create ngrams up to that integer, and passing a tuple of\n      integers will create ngrams for the specified values in the tuple. Passing\n      None means that no ngrams will be created.\n    output_mode: Optional specification for the output of the layer. Values can\n      be `\"int\"`, `\"multi_hot\"`, `\"count\"` or `\"tf_idf\"`, configuring the layer\n      as follows:\n        - `\"int\"`: Outputs integer indices, one integer index per split string\n          token. When `output_mode == \"int\"`, 0 is reserved for masked\n          locations; this reduces the vocab size to\n          `max_tokens - 2` instead of `max_tokens - 1`.\n        - `\"multi_hot\"`: Outputs a single int array per batch, of either\n          vocab_size or max_tokens size, containing 1s in all elements where the\n          token mapped to that index exists at least once in the batch item.\n        - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of\n          the number of times the token at that index appeared in the\n          batch item.\n        - `\"tf_idf\"`: Like `\"multi_hot\"`, but the TF-IDF algorithm is applied to\n          find the value in each token slot.\n      For `\"int\"` output, any shape of input and output is supported. For all\n      other output modes, currently only rank 1 inputs (and rank 2 outputs after\n      splitting) are supported.\n    output_sequence_length: Only valid in INT mode. If set, the output will have\n      its time dimension padded or truncated to exactly `output_sequence_length`\n      values, resulting in a tensor of shape\n      `(batch_size, output_sequence_length)` regardless of how many tokens\n      resulted from the splitting step. Defaults to None.\n    pad_to_max_tokens: Only valid in  `\"multi_hot\"`, `\"count\"`, and `\"tf_idf\"`\n      modes. If True, the output will have its feature axis padded to\n      `max_tokens` even if the number of unique tokens in the vocabulary is less\n      than max_tokens, resulting in a tensor of shape `(batch_size, max_tokens)`\n      regardless of vocabulary size. Defaults to False.\n    vocabulary: Optional. Either an array of strings or a string path to a text\n      file. If passing an array, can pass a tuple, list, 1D numpy array, or 1D\n      tensor containing the string vocbulary terms. If passing a file path, the\n      file should contain one line per term in the vocabulary. If this argument\n      is set, there is no need to `adapt` the layer.\n\n  Example:\n\n  This example instantiates a `TextVectorization` layer that lowercases text,\n  splits on whitespace, strips punctuation, and outputs integer vocab indices.\n\n  >>> text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n  >>> max_features = 5000  # Maximum vocab size.\n  >>> max_len = 4  # Sequence length to pad the outputs to.\n  >>>\n  >>> # Create the layer.\n  >>> vectorize_layer = tf.keras.layers.TextVectorization(\n  ...  max_tokens=max_features,\n  ...  output_mode='int',\n  ...  output_sequence_length=max_len)\n  >>>\n  >>> # Now that the vocab layer has been created, call `adapt` on the text-only\n  >>> # dataset to create the vocabulary. You don't have to batch, but for large\n  >>> # datasets this means we're not keeping spare copies of the dataset.\n  >>> vectorize_layer.adapt(text_dataset.batch(64))\n  >>>\n  >>> # Create the model that uses the vectorize text layer\n  >>> model = tf.keras.models.Sequential()\n  >>>\n  >>> # Start by creating an explicit input layer. It needs to have a shape of\n  >>> # (1,) (because we need to guarantee that there is exactly one string\n  >>> # input per batch), and the dtype needs to be 'string'.\n  >>> model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n  >>>\n  >>> # The first layer in our model is the vectorization layer. After this\n  >>> # layer, we have a tensor of shape (batch_size, max_len) containing vocab\n  >>> # indices.\n  >>> model.add(vectorize_layer)\n  >>>\n  >>> # Now, the model can map strings to integers, and you can add an embedding\n  >>> # layer to map these integers to learned embeddings.\n  >>> input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n  >>> model.predict(input_data)\n  array([[2, 1, 4, 0],\n         [1, 3, 0, 0]])\n\n  Example:\n\n  This example instantiates a `TextVectorization` layer by passing a list\n  of vocabulary terms to the layer's `__init__()` method.\n\n  >>> vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n  >>> max_len = 4  # Sequence length to pad the outputs to.\n  >>>\n  >>> # Create the layer, passing the vocab directly. You can also pass the\n  >>> # vocabulary arg a path to a file containing one vocabulary word per\n  >>> # line.\n  >>> vectorize_layer = tf.keras.layers.TextVectorization(\n  ...  max_tokens=max_features,\n  ...  output_mode='int',\n  ...  output_sequence_length=max_len,\n  ...  vocabulary=vocab_data)\n  >>>\n  >>> # Because we've passed the vocabulary directly, we don't need to adapt\n  >>> # the layer - the vocabulary is already set. The vocabulary contains the\n  >>> # padding token ('') and OOV token ('[UNK]') as well as the passed tokens.\n  >>> vectorize_layer.get_vocabulary()\n  ['', '[UNK]', 'earth', 'wind', 'and', 'fire']\n\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "max_tokens",
        "default": "None"
      },
      {
        "name": "standardize",
        "default": "lower_and_strip_punctuation"
      },
      {
        "name": "split",
        "default": "whitespace"
      },
      {
        "name": "ngrams",
        "default": "None"
      },
      {
        "name": "output_mode",
        "default": "int"
      },
      {
        "name": "output_sequence_length",
        "default": "None"
      },
      {
        "name": "pad_to_max_tokens",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "vocabulary",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/preprocessing/text_vectorization.py",
    "aliases": []
  },
  {
    "name": "ThresholdedReLU",
    "base": "Layer",
    "docstring": "Thresholded Rectified Linear Unit.\n\n  It follows:\n\n  ```\n    f(x) = x for x > theta\n    f(x) = 0 otherwise`\n  ```\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as the input.\n\n  Args:\n    theta: Float >= 0. Threshold location of activation.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "theta",
        "default": 1.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/advanced_activations.py",
    "aliases": []
  },
  {
    "name": "TimeDistributed",
    "base": "Wrapper",
    "docstring": "This wrapper allows to apply a layer to every temporal slice of an input.\n\n  Every input should be at least 3D, and the dimension of index one of the\n  first input will be considered to be the temporal dimension.\n\n  Consider a batch of 32 video samples, where each sample is a 128x128 RGB image\n  with `channels_last` data format, across 10 timesteps.\n  The batch input shape is `(32, 10, 128, 128, 3)`.\n\n  You can then use `TimeDistributed` to apply the same `Conv2D` layer to each\n  of the 10 timesteps, independently:\n\n  >>> inputs = tf.keras.Input(shape=(10, 128, 128, 3))\n  >>> conv_2d_layer = tf.keras.layers.Conv2D(64, (3, 3))\n  >>> outputs = tf.keras.layers.TimeDistributed(conv_2d_layer)(inputs)\n  >>> outputs.shape\n  TensorShape([None, 10, 126, 126, 64])\n\n  Because `TimeDistributed` applies the same instance of `Conv2D` to each of the\n  timestamps, the same set of weights are used at each timestamp.\n\n  Args:\n    layer: a `tf.keras.layers.Layer` instance.\n\n  Call arguments:\n    inputs: Input tensor of shape (batch, time, ...) or nested tensors,\n      and each of which has shape (batch, time, ...).\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the\n      wrapped layer (only if the layer supports this argument).\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether\n      a given timestep should be masked. This argument is passed to the\n      wrapped layer (only if the layer supports this argument).\n\n  Raises:\n    ValueError: If not initialized with a `tf.keras.layers.Layer` instance.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "layer",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "keras/layers/wrappers.py",
    "aliases": []
  },
  {
    "name": "UpSampling1D",
    "base": "Layer",
    "docstring": "Upsampling layer for 1D inputs.\n\n  Repeats each temporal step `size` times along the time axis.\n\n  Examples:\n\n  >>> input_shape = (2, 2, 3)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> print(x)\n  [[[ 0  1  2]\n    [ 3  4  5]]\n   [[ 6  7  8]\n    [ 9 10 11]]]\n  >>> y = tf.keras.layers.UpSampling1D(size=2)(x)\n  >>> print(y)\n  tf.Tensor(\n    [[[ 0  1  2]\n      [ 0  1  2]\n      [ 3  4  5]\n      [ 3  4  5]]\n     [[ 6  7  8]\n      [ 6  7  8]\n      [ 9 10 11]\n      [ 9 10 11]]], shape=(2, 4, 3), dtype=int64)\n\n  Args:\n    size: Integer. Upsampling factor.\n\n  Input shape:\n    3D tensor with shape: `(batch_size, steps, features)`.\n\n  Output shape:\n    3D tensor with shape: `(batch_size, upsampled_steps, features)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "size",
        "default": 2
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "UpSampling2D",
    "base": "Layer",
    "docstring": "Upsampling layer for 2D inputs.\n\n  Repeats the rows and columns of the data\n  by `size[0]` and `size[1]` respectively.\n\n  Examples:\n\n  >>> input_shape = (2, 2, 1, 3)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> print(x)\n  [[[[ 0  1  2]]\n    [[ 3  4  5]]]\n   [[[ 6  7  8]]\n    [[ 9 10 11]]]]\n  >>> y = tf.keras.layers.UpSampling2D(size=(1, 2))(x)\n  >>> print(y)\n  tf.Tensor(\n    [[[[ 0  1  2]\n       [ 0  1  2]]\n      [[ 3  4  5]\n       [ 3  4  5]]]\n     [[[ 6  7  8]\n       [ 6  7  8]]\n      [[ 9 10 11]\n       [ 9 10 11]]]], shape=(2, 2, 2, 3), dtype=int64)\n\n  Args:\n    size: Int, or tuple of 2 integers.\n      The upsampling factors for rows and columns.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n    interpolation: A string, one of `nearest` or `bilinear`.\n\n  Input shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, rows, cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, rows, cols)`\n\n  Output shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, upsampled_rows, upsampled_cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, upsampled_rows, upsampled_cols)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "size",
        "default": [
          2,
          2
        ]
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "interpolation",
        "default": "nearest"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "UpSampling3D",
    "base": "Layer",
    "docstring": "Upsampling layer for 3D inputs.\n\n  Repeats the 1st, 2nd and 3rd dimensions\n  of the data by `size[0]`, `size[1]` and `size[2]` respectively.\n\n  Examples:\n\n  >>> input_shape = (2, 1, 2, 1, 3)\n  >>> x = tf.constant(1, shape=input_shape)\n  >>> y = tf.keras.layers.UpSampling3D(size=2)(x)\n  >>> print(y.shape)\n  (2, 2, 4, 2, 3)\n\n  Args:\n    size: Int, or tuple of 3 integers.\n      The upsampling factors for dim1, dim2 and dim3.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, dim1, dim2, dim3, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, dim1, dim2, dim3)`\n\n  Output shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "size",
        "default": [
          2,
          2,
          2
        ]
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "ZeroPadding1D",
    "base": "Layer",
    "docstring": "Zero-padding layer for 1D input (e.g. temporal sequence).\n\n  Examples:\n\n  >>> input_shape = (2, 2, 3)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> print(x)\n  [[[ 0  1  2]\n    [ 3  4  5]]\n   [[ 6  7  8]\n    [ 9 10 11]]]\n  >>> y = tf.keras.layers.ZeroPadding1D(padding=2)(x)\n  >>> print(y)\n  tf.Tensor(\n    [[[ 0  0  0]\n      [ 0  0  0]\n      [ 0  1  2]\n      [ 3  4  5]\n      [ 0  0  0]\n      [ 0  0  0]]\n     [[ 0  0  0]\n      [ 0  0  0]\n      [ 6  7  8]\n      [ 9 10 11]\n      [ 0  0  0]\n      [ 0  0  0]]], shape=(2, 6, 3), dtype=int64)\n\n  Args:\n      padding: Int, or tuple of int (length 2), or dictionary.\n          - If int:\n          How many zeros to add at the beginning and end of\n          the padding dimension (axis 1).\n          - If tuple of int (length 2):\n          How many zeros to add at the beginning and the end of\n          the padding dimension (`(left_pad, right_pad)`).\n\n  Input shape:\n      3D tensor with shape `(batch_size, axis_to_pad, features)`\n\n  Output shape:\n      3D tensor with shape `(batch_size, padded_axis, features)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "padding",
        "default": 1
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "ZeroPadding2D",
    "base": "Layer",
    "docstring": "Zero-padding layer for 2D input (e.g. picture).\n\n  This layer can add rows and columns of zeros\n  at the top, bottom, left and right side of an image tensor.\n\n  Examples:\n\n  >>> input_shape = (1, 1, 2, 2)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> print(x)\n  [[[[0 1]\n     [2 3]]]]\n  >>> y = tf.keras.layers.ZeroPadding2D(padding=1)(x)\n  >>> print(y)\n  tf.Tensor(\n    [[[[0 0]\n       [0 0]\n       [0 0]\n       [0 0]]\n      [[0 0]\n       [0 1]\n       [2 3]\n       [0 0]]\n      [[0 0]\n       [0 0]\n       [0 0]\n       [0 0]]]], shape=(1, 3, 4, 2), dtype=int64)\n\n  Args:\n    padding: Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n      - If int: the same symmetric padding\n        is applied to height and width.\n      - If tuple of 2 ints:\n        interpreted as two different\n        symmetric padding values for height and width:\n        `(symmetric_height_pad, symmetric_width_pad)`.\n      - If tuple of 2 tuples of 2 ints:\n        interpreted as\n        `((top_pad, bottom_pad), (left_pad, right_pad))`\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, rows, cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, rows, cols)`\n\n  Output shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, padded_rows, padded_cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, padded_rows, padded_cols)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "padding",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "ZeroPadding3D",
    "base": "Layer",
    "docstring": "Zero-padding layer for 3D data (spatial or spatio-temporal).\n\n  Examples:\n\n  >>> input_shape = (1, 1, 2, 2, 3)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> y = tf.keras.layers.ZeroPadding3D(padding=2)(x)\n  >>> print(y.shape)\n  (1, 5, 6, 6, 3)\n\n  Args:\n    padding: Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n      - If int: the same symmetric padding\n        is applied to height and width.\n      - If tuple of 3 ints:\n        interpreted as two different\n        symmetric padding values for height and width:\n        `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)`.\n      - If tuple of 3 tuples of 2 ints:\n        interpreted as\n        `((left_dim1_pad, right_dim1_pad), (left_dim2_pad,\n          right_dim2_pad), (left_dim3_pad, right_dim3_pad))`\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad,\n          depth)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, depth, first_axis_to_pad, second_axis_to_pad,\n          third_axis_to_pad)`\n\n  Output shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, first_padded_axis, second_padded_axis, third_axis_to_pad,\n          depth)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, depth, first_padded_axis, second_padded_axis,\n          third_axis_to_pad)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "padding",
        "default": [
          1,
          1,
          1
        ]
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "AGNNConv",
    "base": "MessagePassing",
    "docstring": "\n    An Attention-based Graph Neural Network (AGNN) from the paper\n\n    > [Attention-based Graph Neural Network for Semi-supervised Learning](https://arxiv.org/abs/1803.03735)<br>\n    > Kiran K. Thekumparampil et al.\n\n    **Mode**: single, disjoint, mixed.\n\n    **This layer expects a sparse adjacency matrix.**\n\n    This layer computes:\n    $$\n        \\X' = \\P\\X\n    $$\n    where\n    $$\n        \\P_{ij} = \\frac{\n            \\exp \\left( \\beta \\cos \\left( \\x_i, \\x_j \\right) \\right)\n        }{\n            \\sum\\limits_{k \\in \\mathcal{N}(i) \\cup \\{ i \\}}\n            \\exp \\left( \\beta \\cos \\left( \\x_i, \\x_k \\right) \\right)\n        }\n    $$\n    and \\(\\beta\\) is a trainable parameter.\n\n    **Input**\n\n    - Node features of shape `(n_nodes, n_node_features)`;\n    - Binary adjacency matrix of shape `(n_nodes, n_nodes)`.\n\n    **Output**\n\n    - Node features with the same shape of the input.\n\n    **Arguments**\n\n    - `trainable`: boolean, if True, then beta is a trainable parameter.\n    Otherwise, beta is fixed to 1;\n    - `activation`: activation function;\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "trainable",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "aggregate",
        "default": "sum"
      },
      {
        "name": "activation",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/convolutional/agnn_conv.py",
    "aliases": []
  },
  {
    "name": "APPNPConv",
    "base": "Conv",
    "docstring": "\n    The APPNP operator from the paper\n\n    > [Predict then Propagate: Graph Neural Networks meet Personalized PageRank](https://arxiv.org/abs/1810.05997)<br>\n    > Johannes Klicpera et al.\n\n    **Mode**: single, disjoint, mixed, batch.\n\n    This layer computes:\n    $$\n        \\Z^{(0)} = \\textrm{MLP}(\\X); \\\\\n        \\Z^{(K)} = (1 - \\alpha) \\hat \\D^{-1/2} \\hat \\A \\hat \\D^{-1/2} \\Z^{(K - 1)} +\n                   \\alpha \\Z^{(0)},\n    $$\n    where \\(\\alpha\\) is the teleport probability, \\(\\textrm{MLP}\\) is a\n    multi-layer perceptron, and \\(K\\) is defined by the `propagations` argument.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Modified Laplacian of shape `([batch], n_nodes, n_nodes)`; can be computed with\n    `spektral.utils.convolution.gcn_filter`.\n\n    **Output**\n\n    - Node features with the same shape as the input, but with the last\n    dimension changed to `channels`.\n\n    **Arguments**\n\n    - `channels`: number of output channels;\n    - `alpha`: teleport probability during propagation;\n    - `propagations`: number of propagation steps;\n    - `mlp_hidden`: list of integers, number of hidden units for each hidden\n    layer in the MLP (if None, the MLP has only the output layer);\n    - `mlp_activation`: activation for the MLP layers;\n    - `dropout_rate`: dropout rate for Laplacian and MLP layers;\n    - `activation`: activation function;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "alpha",
        "default": 0.2
      },
      {
        "name": "propagations",
        "default": 1
      },
      {
        "name": "mlp_hidden",
        "default": "None"
      },
      {
        "name": "mlp_activation",
        "default": "relu"
      },
      {
        "name": "dropout_rate",
        "default": 0.0
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "spektral/layers/convolutional/appnp_conv.py",
    "aliases": []
  },
  {
    "name": "ARMAConv",
    "base": "Conv",
    "docstring": "\n    An Auto-Regressive Moving Average convolutional layer (ARMA) from the paper\n\n    > [Graph Neural Networks with convolutional ARMA filters](https://arxiv.org/abs/1901.01343)<br>\n    > Filippo Maria Bianchi et al.\n\n    **Mode**: single, disjoint, mixed, batch.\n\n    This layer computes:\n    $$\n        \\X' = \\frac{1}{K} \\sum\\limits_{k=1}^K \\bar\\X_k^{(T)},\n    $$\n    where \\(K\\) is the order of the ARMA\\(_K\\) filter, and where:\n    $$\n        \\bar \\X_k^{(t + 1)} =\n        \\sigma \\left(\\tilde \\A \\bar \\X^{(t)} \\W^{(t)} + \\X \\V^{(t)} \\right)\n    $$\n    is a recursive approximation of an ARMA\\(_1\\) filter, where\n    \\( \\bar \\X^{(0)} = \\X \\)\n    and\n    $$\n        \\tilde \\A =  \\D^{-1/2} \\A \\D^{-1/2}.\n    $$\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Normalized and rescaled Laplacian of shape `([batch], n_nodes, n_nodes)`; can be\n    computed with `spektral.utils.convolution.normalized_laplacian` and\n    `spektral.utils.convolution.rescale_laplacian`.\n\n    **Output**\n\n    - Node features with the same shape as the input, but with the last\n    dimension changed to `channels`.\n\n    **Arguments**\n\n    - `channels`: number of output channels;\n    - `order`: order of the full ARMA\\(_K\\) filter, i.e., the number of parallel\n    stacks in the layer;\n    - `iterations`: number of iterations to compute each ARMA\\(_1\\) approximation;\n    - `share_weights`: share the weights in each ARMA\\(_1\\) stack.\n    - `gcn_activation`: activation function to compute each ARMA\\(_1\\)\n    stack;\n    - `dropout_rate`: dropout rate for skip connection;\n    - `activation`: activation function;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "order",
        "default": 1
      },
      {
        "name": "iterations",
        "default": 1
      },
      {
        "name": "share_weights",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "gcn_activation",
        "default": "relu"
      },
      {
        "name": "dropout_rate",
        "default": 0.0
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "spektral/layers/convolutional/arma_conv.py",
    "aliases": []
  },
  {
    "name": "ChebConv",
    "base": "Conv",
    "docstring": "\n    A Chebyshev convolutional layer from the paper\n\n    > [Convolutional Neural Networks on Graphs with Fast Localized Spectral\n  Filtering](https://arxiv.org/abs/1606.09375)<br>\n    > Micha\u00ebl Defferrard et al.\n\n    **Mode**: single, disjoint, mixed, batch.\n\n    This layer computes:\n    $$\n        \\X' = \\sum \\limits_{k=0}^{K - 1} \\T^{(k)} \\W^{(k)}  + \\b^{(k)},\n    $$\n    where \\( \\T^{(0)}, ..., \\T^{(K - 1)} \\) are Chebyshev polynomials of \\(\\tilde \\L\\)\n    defined as\n    $$\n        \\T^{(0)} = \\X \\\\\n        \\T^{(1)} = \\tilde \\L \\X \\\\\n        \\T^{(k \\ge 2)} = 2 \\cdot \\tilde \\L \\T^{(k - 1)} - \\T^{(k - 2)},\n    $$\n    where\n    $$\n        \\tilde \\L =  \\frac{2}{\\lambda_{max}} \\cdot (\\I - \\D^{-1/2} \\A \\D^{-1/2}) - \\I.\n    $$\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - A list of K Chebyshev polynomials of shape\n    `[([batch], n_nodes, n_nodes), ..., ([batch], n_nodes, n_nodes)]`; can be computed with\n    `spektral.utils.convolution.chebyshev_filter`.\n\n    **Output**\n\n    - Node features with the same shape of the input, but with the last\n    dimension changed to `channels`.\n\n    **Arguments**\n\n    - `channels`: number of output channels;\n    - `K`: order of the Chebyshev polynomials;\n    - `activation`: activation function;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "K",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "spektral/layers/convolutional/cheb_conv.py",
    "aliases": []
  },
  {
    "name": "CrystalConv",
    "base": "MessagePassing",
    "docstring": "\n    A crystal graph convolutional layer from the paper\n\n    > [Crystal Graph Convolutional Neural Networks for an Accurate and\n    Interpretable Prediction of Material Properties](https://arxiv.org/abs/1710.10324)<br>\n    > Tian Xie and Jeffrey C. Grossman\n\n    **Mode**: single, disjoint, mixed.\n\n    **This layer expects a sparse adjacency matrix.**\n\n    This layer computes:\n    $$\n        \\x_i' = \\x_i + \\sum\\limits_{j \\in \\mathcal{N}(i)} \\sigma \\left( \\z_{ij}\n        \\W^{(f)} + \\b^{(f)} \\right) \\odot \\g \\left( \\z_{ij} \\W^{(s)} + \\b^{(s)}\n        \\right)\n    $$\n    where \\(\\z_{ij} = \\x_i \\| \\x_j \\| \\e_{ji} \\), \\(\\sigma\\) is a sigmoid\n    activation, and \\(g\\) is the activation function (defined by the `activation`\n    argument).\n\n    **Input**\n\n    - Node features of shape `(n_nodes, n_node_features)`;\n    - Binary adjacency matrix of shape `(n_nodes, n_nodes)`.\n    - Edge features of shape `(num_edges, n_edge_features)`.\n\n    **Output**\n\n    - Node features with the same shape of the input, but the last dimension\n    changed to `channels`.\n\n    **Arguments**\n\n    - `channels`: integer, number of output channels;\n    - `activation`: activation function;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "aggregate",
        "default": "sum"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/convolutional/crystal_conv.py",
    "aliases": []
  },
  {
    "name": "DiffPool",
    "base": "Pool",
    "docstring": "\n    A DiffPool layer from the paper\n\n    > [Hierarchical Graph Representation Learning with Differentiable Pooling](https://arxiv.org/abs/1806.08804)<br>\n    > Rex Ying et al.\n\n    **Mode**: batch.\n\n    This layer computes a soft clustering \\(\\S\\) of the input graphs using a GNN,\n    and reduces graphs as follows:\n    $$\n        \\begin{align}\n            \\S &= \\textrm{GNN}_{embed}(\\A, \\X); \\\\\n            \\Z &= \\textrm{GNN}_{pool}(\\A, \\X); \\\\\n            \\A' &= \\S^\\top \\A \\S; \\\\\n            \\X' &= \\S^\\top \\Z\n        \\end{align}\n    $$\n    where:\n    $$\n        \\textrm{GNN}_{\\square}(\\A, \\X) = \\D^{-1/2} \\A \\D^{-1/2} \\X \\W_{\\square}.\n    $$\n    The number of output channels of \\(\\textrm{GNN}_{embed}\\) is controlled by \n    the `channels` parameter.\n\n    Two auxiliary loss terms are also added to the model: the _link prediction\n    loss_\n    $$\n        L_{LP} = \\big\\| \\A - \\S\\S^\\top \\big\\|_F\n    $$\n    and the _entropy loss_\n    $$\n        L_{E} - \\frac{1}{N} \\sum\\limits_{i = 1}^{N} \\S \\log (\\S).\n    $$\n\n    The layer can be used without a supervised loss, to compute node clustering\n    simply by minimizing the two auxiliary losses.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Adjacency matrix of shape `([batch], n_nodes, n_nodes)`;\n\n    **Output**\n\n    - Reduced node features of shape `([batch], K, channels)`;\n    - Reduced adjacency matrix of shape `([batch], K, K)`;\n    - If `return_mask=True`, the soft clustering matrix of shape `([batch], n_nodes, K)`.\n\n    **Arguments**\n\n    - `k`: number of output nodes;\n    - `channels`: number of output channels (if None, the number of output\n    channels is assumed to be the same as the input);\n    - `return_mask`: boolean, whether to return the cluster assignment matrix;\n    - `kernel_initializer`: initializer for the weights;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `kernel_constraint`: constraint applied to the weights;\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "k",
        "default": null
      },
      {
        "name": "channels",
        "default": "None"
      },
      {
        "name": "return_mask",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "spektral/layers/pooling/diff_pool.py",
    "aliases": []
  },
  {
    "name": "DiffusionConv",
    "base": "Conv",
    "docstring": "\n      A diffusion convolution operator from the paper\n\n      > [Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic\n    Forecasting](https://arxiv.org/abs/1707.01926)<br>\n      > Yaguang Li et al.\n\n      **Mode**: single, disjoint, mixed, batch.\n\n      **This layer expects a dense adjacency matrix.**\n\n      Given a number of diffusion steps \\(K\\) and a row-normalized adjacency\n      matrix \\(\\hat \\A \\), this layer calculates the \\(q\\)-th channel as:\n      $$\n      \\mathbf{X}_{~:,~q}' = \\sigma\\left( \\sum_{f=1}^{F} \\left( \\sum_{k=0}^{K-1}\n      \\theta_k {\\hat \\A}^k \\right) \\X_{~:,~f} \\right)\n      $$\n\n      **Input**\n\n      - Node features of shape `([batch], n_nodes, n_node_features)`;\n      - Normalized adjacency or attention coef. matrix \\(\\hat \\A \\) of shape\n      `([batch], n_nodes, n_nodes)`; Use `DiffusionConvolution.preprocess` to normalize.\n\n      **Output**\n\n      - Node features with the same shape as the input, but with the last\n      dimension changed to `channels`.\n\n      **Arguments**\n\n      - `channels`: number of output channels;\n      - `K`: number of diffusion steps.\n      - `activation`: activation function \\(\\sigma\\); (\\(\\tanh\\) by default)\n      - `kernel_initializer`: initializer for the weights;\n      - `kernel_regularizer`: regularization applied to the weights;\n      - `kernel_constraint`: constraint applied to the weights;\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "K",
        "default": 6
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "spektral/layers/convolutional/diffusion_conv.py",
    "aliases": []
  },
  {
    "name": "Disjoint2Batch",
    "base": "Layer",
    "docstring": "Utility layer that converts data from disjoint mode to batch mode by\n    zero-padding the node features and adjacency matrices.\n\n    **Mode**: disjoint.\n\n    **This layer expects a sparse adjacency matrix.**\n\n    **Input**\n\n    - Node features of shape `(n_nodes, n_node_features)`;\n    - Binary adjacency matrix of shape `(n_nodes, n_nodes)`;\n    - Graph IDs of shape `(n_nodes, )`;\n\n    **Output**\n\n    - Batched node features of shape `(batch, N_max, n_node_features)`;\n    - Batched adjacency matrix of shape `(batch, N_max, N_max)`;\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/base.py",
    "aliases": []
  },
  {
    "name": "ECCConv",
    "base": "Conv",
    "docstring": "\n      An edge-conditioned convolutional layer (ECC) from the paper\n\n      > [Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on\n    Graphs](https://arxiv.org/abs/1704.02901)<br>\n      > Martin Simonovsky and Nikos Komodakis\n\n    **Mode**: single, disjoint, batch, mixed.\n\n    **In single, disjoint, and mixed mode, this layer expects a sparse adjacency\n    matrix. If a dense adjacency is given as input, it will be automatically\n    cast to sparse, which might be expensive.**\n\n      This layer computes:\n      $$\n          \\x_i' = \\x_{i} \\W_{\\textrm{root}} + \\sum\\limits_{j \\in \\mathcal{N}(i)}\n          \\x_{j} \\textrm{MLP}(\\e_{j \\rightarrow i}) + \\b\n      $$\n      where \\(\\textrm{MLP}\\) is a multi-layer perceptron that outputs an\n      edge-specific weight as a function of edge attributes.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Binary adjacency matrices of shape `([batch], n_nodes, n_nodes)`;\n    - Edge features. In single mode, shape `(num_edges, n_edge_features)`; in\n    batch mode, shape `(batch, n_nodes, n_nodes, n_edge_features)`.\n\n      **Output**\n\n      - node features with the same shape of the input, but the last dimension\n      changed to `channels`.\n\n      **Arguments**\n\n      - `channels`: integer, number of output channels;\n      - `kernel_network`: a list of integers representing the hidden neurons of\n      the kernel-generating network;\n      - 'root': if False, the layer will not consider the root node for computing\n      the message passing (first term in equation above), but only the neighbours.\n      - `activation`: activation function;\n      - `use_bias`: bool, add a bias vector to the output;\n      - `kernel_initializer`: initializer for the weights;\n      - `bias_initializer`: initializer for the bias vector;\n      - `kernel_regularizer`: regularization applied to the weights;\n      - `bias_regularizer`: regularization applied to the bias vector;\n      - `activity_regularizer`: regularization applied to the output;\n      - `kernel_constraint`: constraint applied to the weights;\n      - `bias_constraint`: constraint applied to the bias vector.\n\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "kernel_network",
        "default": "None"
      },
      {
        "name": "root",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "spektral/layers/convolutional/ecc_conv.py",
    "aliases": []
  },
  {
    "name": "EdgeConv",
    "base": "MessagePassing",
    "docstring": "\n    An edge convolutional layer from the paper\n\n    > [Dynamic Graph CNN for Learning on Point Clouds](https://arxiv.org/abs/1801.07829)<br>\n    > Yue Wang et al.\n\n    **Mode**: single, disjoint, mixed.\n\n    **This layer expects a sparse adjacency matrix.**\n\n    This layer computes for each node \\(i\\):\n    $$\n        \\x_i' = \\sum\\limits_{j \\in \\mathcal{N}(i)} \\textrm{MLP}\\big( \\x_i \\|\n        \\x_j - \\x_i \\big)\n    $$\n    where \\(\\textrm{MLP}\\) is a multi-layer perceptron.\n\n    **Input**\n\n    - Node features of shape `(n_nodes, n_node_features)`;\n    - Binary adjacency matrix of shape `(n_nodes, n_nodes)`.\n\n    **Output**\n\n    - Node features with the same shape of the input, but the last dimension\n    changed to `channels`.\n\n    **Arguments**\n\n    - `channels`: integer, number of output channels;\n    - `mlp_hidden`: list of integers, number of hidden units for each hidden\n    layer in the MLP (if None, the MLP has only the output layer);\n    - `mlp_activation`: activation for the MLP layers;\n    - `activation`: activation function;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "mlp_hidden",
        "default": "None"
      },
      {
        "name": "mlp_activation",
        "default": "relu"
      },
      {
        "name": "aggregate",
        "default": "sum"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/convolutional/edge_conv.py",
    "aliases": []
  },
  {
    "name": "GATConv",
    "base": "Conv",
    "docstring": "\n    A Graph Attention layer (GAT) from the paper\n\n    > [Graph Attention Networks](https://arxiv.org/abs/1710.10903)<br>\n    > Petar Veli\u010dkovi\u0107 et al.\n\n    **Mode**: single, disjoint, mixed, batch.\n\n    **This layer expects dense inputs when working in batch mode.**\n\n    This layer computes a convolution similar to `layers.GraphConv`, but\n    uses the attention mechanism to weight the adjacency matrix instead of\n    using the normalized Laplacian:\n    $$\n        \\X' = \\mathbf{\\alpha}\\X\\W + \\b\n    $$\n    where\n    $$\n        \\mathbf{\\alpha}_{ij} =\\frac{ \\exp\\left(\\mathrm{LeakyReLU}\\left(\n        \\a^{\\top} [(\\X\\W)_i \\, \\| \\, (\\X\\W)_j]\\right)\\right)}{\\sum\\limits_{k\n        \\in \\mathcal{N}(i) \\cup \\{ i \\}} \\exp\\left(\\mathrm{LeakyReLU}\\left(\n        \\a^{\\top} [(\\X\\W)_i \\, \\| \\, (\\X\\W)_k]\\right)\\right)}\n    $$\n    where \\(\\a \\in \\mathbb{R}^{2F'}\\) is a trainable attention kernel.\n    Dropout is also applied to \\(\\alpha\\) before computing \\(\\Z\\).\n    Parallel attention heads are computed in parallel and their results are\n    aggregated by concatenation or average.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Binary adjacency matrix of shape `([batch], n_nodes, n_nodes)`;\n\n    **Output**\n\n    - Node features with the same shape as the input, but with the last\n    dimension changed to `channels`;\n    - if `return_attn_coef=True`, a list with the attention coefficients for\n    each attention head. Each attention coefficient matrix has shape\n    `([batch], n_nodes, n_nodes)`.\n\n    **Arguments**\n\n    - `channels`: number of output channels;\n    - `attn_heads`: number of attention heads to use;\n    - `concat_heads`: bool, whether to concatenate the output of the attention\n     heads instead of averaging;\n    - `dropout_rate`: internal dropout rate for attention coefficients;\n    - `return_attn_coef`: if True, return the attention coefficients for\n    the given input (one n_nodes x n_nodes matrix for each head).\n    - `add_self_loops`: if True, add self loops to the adjacency matrix.\n    - `activation`: activation function;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `attn_kernel_initializer`: initializer for the attention weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `attn_kernel_regularizer`: regularization applied to the attention kernels;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `attn_kernel_constraint`: constraint applied to the attention kernels;\n    - `bias_constraint`: constraint applied to the bias vector.\n\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "attn_heads",
        "default": 1
      },
      {
        "name": "concat_heads",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "dropout_rate",
        "default": 0.5
      },
      {
        "name": "return_attn_coef",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "add_self_loops",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "attn_kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "attn_kernel_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "attn_kernel_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "spektral/layers/convolutional/gat_conv.py",
    "aliases": []
  },
  {
    "name": "GCNConv",
    "base": "Conv",
    "docstring": "\n    A graph convolutional layer (GCN) from the paper\n\n    > [Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907)<br>\n    > Thomas N. Kipf and Max Welling\n\n    **Mode**: single, disjoint, mixed, batch.\n\n    This layer computes:\n    $$\n        \\X' = \\hat \\D^{-1/2} \\hat \\A \\hat \\D^{-1/2} \\X \\W + \\b\n    $$\n    where \\( \\hat \\A = \\A + \\I \\) is the adjacency matrix with added self-loops\n    and \\(\\hat\\D\\) is its degree matrix.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Modified Laplacian of shape `([batch], n_nodes, n_nodes)`; can be computed with\n    `spektral.utils.convolution.gcn_filter`.\n\n    **Output**\n\n    - Node features with the same shape as the input, but with the last\n    dimension changed to `channels`.\n\n    **Arguments**\n\n    - `channels`: number of output channels;\n    - `activation`: activation function;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "spektral/layers/convolutional/gcn_conv.py",
    "aliases": []
  },
  {
    "name": "GCSConv",
    "base": "Conv",
    "docstring": "\n    A `GraphConv` layer with a trainable skip connection.\n\n    **Mode**: single, disjoint, mixed, batch.\n\n    This layer computes:\n    $$\n        \\Z' = \\D^{-1/2} \\A \\D^{-1/2} \\X \\W_1 + \\X \\W_2 + \\b\n    $$\n    where \\( \\A \\) does not have self-loops.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Normalized adjacency matrix of shape `([batch], n_nodes, n_nodes)`; can be computed\n    with `spektral.utils.convolution.normalized_adjacency`.\n\n    **Output**\n\n    - Node features with the same shape as the input, but with the last\n    dimension changed to `channels`.\n\n    **Arguments**\n\n    - `channels`: number of output channels;\n    - `activation`: activation function;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "spektral/layers/convolutional/gcs_conv.py",
    "aliases": []
  },
  {
    "name": "GINConv",
    "base": "MessagePassing",
    "docstring": "\n    A Graph Isomorphism Network (GIN) from the paper\n\n    > [How Powerful are Graph Neural Networks?](https://arxiv.org/abs/1810.00826)<br>\n    > Keyulu Xu et al.\n\n    **Mode**: single, disjoint, mixed.\n\n    **This layer expects a sparse adjacency matrix.**\n\n    This layer computes for each node \\(i\\):\n    $$\n        \\x_i' = \\textrm{MLP}\\big( (1 + \\epsilon) \\cdot \\x_i + \\sum\\limits_{j\n        \\in \\mathcal{N}(i)} \\x_j \\big)\n    $$\n    where \\(\\textrm{MLP}\\) is a multi-layer perceptron.\n\n    **Input**\n\n    - Node features of shape `(n_nodes, n_node_features)`;\n    - Binary adjacency matrix of shape `(n_nodes, n_nodes)`.\n\n    **Output**\n\n    - Node features with the same shape of the input, but the last dimension\n    changed to `channels`.\n\n    **Arguments**\n\n    - `channels`: integer, number of output channels;\n    - `epsilon`: unnamed parameter, see the original paper and the equation\n    above.\n    By setting `epsilon=None`, the parameter will be learned (default behaviour).\n    If given as a value, the parameter will stay fixed.\n    - `mlp_hidden`: list of integers, number of hidden units for each hidden\n    layer in the MLP (if None, the MLP has only the output layer);\n    - `mlp_activation`: activation for the MLP layers;\n    - `mlp_batchnorm`: apply batch normalization after every hidden layer of the MLP;\n    - `activation`: activation function;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "epsilon",
        "default": "None"
      },
      {
        "name": "mlp_hidden",
        "default": "None"
      },
      {
        "name": "mlp_activation",
        "default": "relu"
      },
      {
        "name": "mlp_batchnorm",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "aggregate",
        "default": "sum"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/convolutional/gin_conv.py",
    "aliases": []
  },
  {
    "name": "GatedGraphConv",
    "base": "MessagePassing",
    "docstring": "\n    A gated graph convolutional layer from the paper\n\n    > [Gated Graph Sequence Neural Networks](https://arxiv.org/abs/1511.05493)<br>\n    > Yujia Li et al.\n\n    **Mode**: single, disjoint, mixed.\n\n    **This layer expects a sparse adjacency matrix.**\n\n    This layer computes \\(\\x_i' = \\h^{(L)}_i\\) where:\n    $$\n    \\begin{align}\n        & \\h^{(0)}_i = \\x_i \\| \\mathbf{0} \\\\\n        & \\m^{(l)}_i = \\sum\\limits_{j \\in \\mathcal{N}(i)} \\h^{(l - 1)}_j \\W \\\\\n        & \\h^{(l)}_i = \\textrm{GRU} \\left(\\m^{(l)}_i, \\h^{(l - 1)}_i \\right) \\\\\n    \\end{align}\n    $$\n    where \\(\\textrm{GRU}\\) is a gated recurrent unit cell.\n\n    **Input**\n\n    - Node features of shape `(n_nodes, n_node_features)`; note that\n    `n_node_features` must be smaller or equal than `channels`.\n    - Binary adjacency matrix of shape `(n_nodes, n_nodes)`.\n\n    **Output**\n\n    - Node features with the same shape of the input, but the last dimension\n    changed to `channels`.\n\n    **Arguments**\n\n    - `channels`: integer, number of output channels;\n    - `n_layers`: integer, number of iterations with the GRU cell;\n    - `activation`: activation function;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "n_layers",
        "default": null
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/convolutional/gated_graph_conv.py",
    "aliases": []
  },
  {
    "name": "GeneralConv",
    "base": "MessagePassing",
    "docstring": "\n    A general convolutional layer from the paper\n\n    > [Design Space for Graph Neural Networks](https://arxiv.org/abs/2011.08843)<br>\n    > Jiaxuan You et al.\n\n    **Mode**: single, disjoint, mixed.\n\n    **This layer expects a sparse adjacency matrix.**\n\n    This layer computes:\n    $$\n        \\x_i' = \\mathrm{Agg} \\left( \\left\\{ \\mathrm{Act} \\left( \\mathrm{Dropout}\n        \\left( \\mathrm{BN} \\left( \\x_j \\W + \\b \\right) \\right) \\right),\n        j \\in \\mathcal{N}(i) \\right\\} \\right)\n    $$\n\n    where \\( \\mathrm{Agg} \\) is an aggregation function for the messages,\n    \\( \\mathrm{Act} \\) is an activation function, \\( \\mathrm{Dropout} \\)\n    applies dropout to the node features, and \\( \\mathrm{BN} \\) applies batch\n    normalization to the node features.\n\n    This layer supports the PReLU activation via the 'prelu' keyword.\n\n    The default parameters of this layer are selected according to the best\n    results obtained in the paper, and should provide a good performance on\n    many node-level and graph-level tasks, without modifications.\n    The defaults are as follows:\n\n    - 256 channels\n    - Batch normalization\n    - No dropout\n    - PReLU activation\n    - Sum aggregation\n\n    If you are uncertain about which layers to use for your GNN, this is a\n    safe choice. Check out the original paper for more specific configurations.\n\n    **Input**\n\n    - Node features of shape `(n_nodes, n_node_features)`;\n    - Binary adjacency matrix of shape `(n_nodes, n_nodes)`.\n\n    **Output**\n\n    - Node features with the same shape of the input, but the last dimension\n    changed to `channels`.\n\n    **Arguments**\n\n    - `channels`: integer, number of output channels;\n    - `batch_norm`: bool, whether to use batch normalization;\n    - `dropout`: float, dropout rate;\n    - `aggregate`: string or callable, an aggregation function. Supported\n    aggregations: 'sum', 'mean', 'max', 'min', 'prod'.\n    - `activation`: activation function. This layer also supports the\n    advanced activation PReLU by passing `activation='prelu'`.\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": 256
      },
      {
        "name": "batch_norm",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "aggregate",
        "default": "sum"
      },
      {
        "name": "activation",
        "default": "prelu"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/convolutional/general_conv.py",
    "aliases": []
  },
  {
    "name": "GlobalAttentionPool",
    "base": "GlobalPool",
    "docstring": "\n    A gated attention global pooling layer from the paper\n\n    > [Gated Graph Sequence Neural Networks](https://arxiv.org/abs/1511.05493)<br>\n    > Yujia Li et al.\n\n    This layer computes:\n    $$\n        \\X' = \\sum\\limits_{i=1}^{N} (\\sigma(\\X \\W_1 + \\b_1) \\odot (\\X \\W_2 + \\b_2))_i\n    $$\n    where \\(\\sigma\\) is the sigmoid activation function.\n\n    **Mode**: single, disjoint, mixed, batch.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Graph IDs of shape `(n_nodes, )` (only in disjoint mode);\n\n    **Output**\n\n    - Pooled node features of shape `(batch, channels)` (if single mode,\n    shape will be `(1, channels)`).\n\n    **Arguments**\n\n    - `channels`: integer, number of output channels;\n    - `bias_initializer`: initializer for the bias vectors;\n    - `kernel_regularizer`: regularization applied to the kernel matrices;\n    - `bias_regularizer`: regularization applied to the bias vectors;\n    - `kernel_constraint`: constraint applied to the kernel matrices;\n    - `bias_constraint`: constraint applied to the bias vectors.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/pooling/global_pool.py",
    "aliases": []
  },
  {
    "name": "GlobalAttnSumPool",
    "base": "GlobalPool",
    "docstring": "\n    A node-attention global pooling layer. Pools a graph by learning attention\n    coefficients to sum node features.\n\n    This layer computes:\n    $$\n        \\alpha = \\textrm{softmax}( \\X \\a); \\\\\n        \\X' = \\sum\\limits_{i=1}^{N} \\alpha_i \\cdot \\X_i\n    $$\n    where \\(\\a \\in \\mathbb{R}^F\\) is a trainable vector. Note that the softmax\n    is applied across nodes, and not across features.\n\n    **Mode**: single, disjoint, mixed, batch.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Graph IDs of shape `(n_nodes, )` (only in disjoint mode);\n\n    **Output**\n\n    - Pooled node features of shape `(batch, n_node_features)` (if single mode, shape will\n    be `(1, n_node_features)`).\n\n    **Arguments**\n\n    - `attn_kernel_initializer`: initializer for the attention weights;\n    - `attn_kernel_regularizer`: regularization applied to the attention kernel\n    matrix;\n    - `attn_kernel_constraint`: constraint applied to the attention kernel\n    matrix;\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "attn_kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "attn_kernel_regularizer",
        "default": "None"
      },
      {
        "name": "attn_kernel_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/pooling/global_pool.py",
    "aliases": []
  },
  {
    "name": "GlobalAvgPool",
    "base": "GlobalPool",
    "docstring": "\n    An average pooling layer. Pools a graph by computing the average of its node\n    features.\n\n    **Mode**: single, disjoint, mixed, batch.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Graph IDs of shape `(n_nodes, )` (only in disjoint mode);\n\n    **Output**\n\n    - Pooled node features of shape `(batch, n_node_features)` (if single mode, shape will\n    be `(1, n_node_features)`).\n\n    **Arguments**\n\n    None.\n\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/pooling/global_pool.py",
    "aliases": []
  },
  {
    "name": "GlobalMaxPool",
    "base": "GlobalPool",
    "docstring": "\n    A max pooling layer. Pools a graph by computing the maximum of its node\n    features.\n\n    **Mode**: single, disjoint, mixed, batch.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Graph IDs of shape `(n_nodes, )` (only in disjoint mode);\n\n    **Output**\n\n    - Pooled node features of shape `(batch, n_node_features)` (if single mode, shape will\n    be `(1, n_node_features)`).\n\n    **Arguments**\n\n    None.\n\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/pooling/global_pool.py",
    "aliases": []
  },
  {
    "name": "GlobalSumPool",
    "base": "GlobalPool",
    "docstring": "\n    A global sum pooling layer. Pools a graph by computing the sum of its node\n    features.\n\n    **Mode**: single, disjoint, mixed, batch.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Graph IDs of shape `(n_nodes, )` (only in disjoint mode);\n\n    **Output**\n\n    - Pooled node features of shape `(batch, n_node_features)` (if single mode, shape will\n    be `(1, n_node_features)`).\n\n    **Arguments**\n\n    None.\n\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/pooling/global_pool.py",
    "aliases": []
  },
  {
    "name": "GraphMasking",
    "base": "Layer",
    "docstring": "\n    A layer that starts the propagation of masks in a model.\n\n    This layer assumes that the node features given as input have been extended with a\n    binary mask that indicates which nodes are valid in each graph.\n    The layer is useful when using a `data.BatchLoader` with `mask=True` or in general\n    when zero-padding graphs so that all batches have the same size. The binary mask\n    indicates with a 1 those nodes that should be taken into account by the model.\n\n    The layer will remove the rightmost feature from the nodes and start a mask\n    propagation to all subsequent layers:\n\n    ```python\n    print(x.shape)  # shape (batch, n_nodes, n_node_features + 1)\n    mask = x[..., -1:]  # shape (batch, n_nodes, 1)\n    x_new = x[..., :-1] # shape (batch, n_nodes, n_node_features)\n    ```\n\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "trainable",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "name",
        "default": "None"
      },
      {
        "name": "dtype",
        "default": "None"
      },
      {
        "name": "dynamic",
        "default": "False",
        "type": "boolean"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/base.py",
    "aliases": []
  },
  {
    "name": "GraphSageConv",
    "base": "MessagePassing",
    "docstring": "\n    A GraphSAGE layer from the paper\n\n    > [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216)<br>\n    > William L. Hamilton et al.\n\n    **Mode**: single, disjoint, mixed.\n\n    **This layer expects a sparse adjacency matrix.**\n\n    This layer computes:\n    $$\n        \\X' = \\big[ \\textrm{AGGREGATE}(\\X) \\| \\X \\big] \\W + \\b; \\\\\n        \\X' = \\frac{\\X'}{\\|\\X'\\|}\n    $$\n    where \\( \\textrm{AGGREGATE} \\) is a function to aggregate a node's\n    neighbourhood. The supported aggregation methods are: sum, mean,\n    max, min, and product.\n\n    **Input**\n\n    - Node features of shape `(n_nodes, n_node_features)`;\n    - Binary adjacency matrix of shape `(n_nodes, n_nodes)`.\n\n    **Output**\n\n    - Node features with the same shape as the input, but with the last\n    dimension changed to `channels`.\n\n    **Arguments**\n\n    - `channels`: number of output channels;\n    - `aggregate_op`: str, aggregation method to use (`'sum'`, `'mean'`,\n    `'max'`, `'min'`, `'prod'`);\n    - `activation`: activation function;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "aggregate",
        "default": "mean"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/convolutional/graphsage_conv.py",
    "aliases": []
  },
  {
    "name": "InnerProduct",
    "base": "Layer",
    "docstring": "\n    Computes the inner product between elements of a 2d Tensor:\n    $$\n        \\langle \\x, \\x \\rangle = \\x\\x^\\top.\n    $$\n\n    **Mode**: single.\n\n    **Input**\n\n    - Tensor of shape `(n_nodes, n_features)`;\n\n    **Output**\n\n    - Tensor of shape `(n_nodes, n_nodes)`.\n\n    :param trainable_kernel: add a trainable square matrix between the inner\n    product (e.g., `X @ W @ X.T`);\n    :param activation: activation function;\n    :param kernel_initializer: initializer for the weights;\n    :param kernel_regularizer: regularization applied to the kernel;\n    :param kernel_constraint: constraint applied to the kernel;\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "trainable_kernel",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/base.py",
    "aliases": []
  },
  {
    "name": "MessagePassing",
    "base": "Layer",
    "docstring": "\n    A general class for message passing networks from the paper\n\n    > [Neural Message Passing for Quantum Chemistry](https://arxiv.org/abs/1704.01212)<br>\n    > Justin Gilmer et al.\n\n    **Mode**: single, disjoint.\n\n    **This layer and all of its extensions expect a sparse adjacency matrix.**\n\n    This layer computes:\n    $$\n        \\x_i' = \\gamma \\left( \\x_i, \\square_{j \\in \\mathcal{N}(i)} \\,\n        \\phi \\left(\\x_i, \\x_j, \\e_{j \\rightarrow i} \\right) \\right),\n    $$\n\n    where \\( \\gamma \\) is a differentiable update function, \\( \\phi \\) is a\n    differentiable message function, \\( \\square \\) is a permutation-invariant\n    function to aggregate the messages (like the sum or the average), and\n    \\(\\E_{ij}\\) is the edge attribute of edge i-j.\n\n    By extending this class, it is possible to create any message-passing layer\n    in single/disjoint mode.\n\n    **API**\n\n    ```python\n    propagate(x, a, e=None, **kwargs)\n    ```\n    Propagates the messages and computes embeddings for each node in the graph. <br>\n    Any `kwargs` will be forwarded as keyword arguments to `message()`,\n    `aggregate()` and `update()`.\n\n    ```python\n    message(x, **kwargs)\n    ```\n    Computes messages, equivalent to \\(\\phi\\) in the definition. <br>\n    Any extra keyword argument of this function will be populated by\n    `propagate()` if a matching keyword is found. <br>\n    Use `self.get_i()` and  `self.get_j()` to gather the elements using the\n    indices `i` or `j` of the adjacency matrix. Equivalently, you can access\n    the indices themselves via the `index_i` and `index_j` attributes.\n\n    ```python\n    aggregate(messages, **kwargs)\n    ```\n    Aggregates the messages, equivalent to \\(\\square\\) in the definition. <br>\n    The behaviour of this function can also be controlled using the `aggregate`\n    keyword in the constructor of the layer (supported aggregations: sum, mean,\n    max, min, prod). <br>\n    Any extra keyword argument of this function will be  populated by\n    `propagate()` if a matching keyword is found.\n\n    ```python\n    update(embeddings, **kwargs)\n    ```\n    Updates the aggregated messages to obtain the final node embeddings,\n    equivalent to \\(\\gamma\\) in the definition. <br>\n    Any extra keyword argument of this function will be  populated by\n    `propagate()` if a matching keyword is found.\n\n    **Arguments**:\n\n    - `aggregate`: string or callable, an aggregation function. This flag can be\n    used to control the behaviour of `aggregate()` wihtout re-implementing it.\n    Supported aggregations: 'sum', 'mean', 'max', 'min', 'prod'.\n    If callable, the function must have the signature `foo(updates, indices, n_nodes)`\n    and return a rank 2 tensor with shape `(n_nodes, ...)`.\n    - `kwargs`: additional keyword arguments specific to Keras' Layers, like\n    regularizers, initializers, constraints, etc.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "aggregate",
        "default": "sum"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/convolutional/message_passing.py",
    "aliases": []
  },
  {
    "name": "MinCutPool",
    "base": "Pool",
    "docstring": "\n    A MinCut pooling layer from the paper\n\n    > [Spectral Clustering with Graph Neural Networks for Graph Pooling](https://arxiv.org/abs/1907.00481)<br>\n    > Filippo Maria Bianchi et al.\n\n    **Mode**: batch.\n\n    This layer computes a soft clustering \\(\\S\\) of the input graphs using a MLP,\n    and reduces graphs as follows:\n    $$\n    \\begin{align}\n        \\S &= \\textrm{MLP}(\\X); \\\\\n        \\A' &= \\S^\\top \\A \\S; \\\\ \n        \\X' &= \\S^\\top \\X\n    \\end{align}\n    $$\n    where MLP is a multi-layer perceptron with softmax output.\n\n    Two auxiliary loss terms are also added to the model: the _minCUT loss_\n    $$\n        L_c = - \\frac{ \\mathrm{Tr}(\\S^\\top \\A \\S) }{ \\mathrm{Tr}(\\S^\\top \\D \\S) }\n    $$\n    and the _orthogonality loss_\n    $$\n        L_o = \\left\\|\n            \\frac{\\S^\\top \\S}{\\| \\S^\\top \\S \\|_F}\n            - \\frac{\\I_K}{\\sqrt{K}}\n        \\right\\|_F.\n    $$\n\n    The layer can be used without a supervised loss, to compute node clustering\n    simply by minimizing the two auxiliary losses.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Symmetrically normalized adjacency matrix of shape `([batch], n_nodes, n_nodes)`;\n\n    **Output**\n\n    - Reduced node features of shape `([batch], K, n_node_features)`;\n    - Reduced adjacency matrix of shape `([batch], K, K)`;\n    - If `return_mask=True`, the soft clustering matrix of shape `([batch], n_nodes, K)`.\n\n    **Arguments**\n\n    - `k`: number of output nodes;\n    - `mlp_hidden`: list of integers, number of hidden units for each hidden\n    layer in the MLP used to compute cluster assignments (if None, the MLP has\n    only the output layer);\n    - `mlp_activation`: activation for the MLP layers;\n    - `return_mask`: boolean, whether to return the cluster assignment matrix;\n    - `use_bias`: use bias in the MLP;\n    - `kernel_initializer`: initializer for the weights of the MLP;\n    - `bias_initializer`: initializer for the bias of the MLP;\n    - `kernel_regularizer`: regularization applied to the weights of the MLP;\n    - `bias_regularizer`: regularization applied to the bias of the MLP;\n    - `kernel_constraint`: constraint applied to the weights of the MLP;\n    - `bias_constraint`: constraint applied to the bias of the MLP;\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "k",
        "default": null
      },
      {
        "name": "mlp_hidden",
        "default": "None"
      },
      {
        "name": "mlp_activation",
        "default": "relu"
      },
      {
        "name": "return_mask",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "spektral/layers/pooling/mincut_pool.py",
    "aliases": []
  },
  {
    "name": "MinkowskiProduct",
    "base": "Layer",
    "docstring": "\n    Computes the hyperbolic inner product between elements of a rank 2 Tensor:\n    $$\n        \\langle \\x, \\x \\rangle = \\x \\,\n        \\begin{pmatrix}\n            \\I_{d \\times d} & 0 \\\\\n            0              & -1\n        \\end{pmatrix} \\, \\x^\\top.\n    $$\n\n    **Mode**: single.\n\n    **Input**\n\n    - Tensor of shape `(n_nodes, n_features)`;\n\n    **Output**\n\n    - Tensor of shape `(n_nodes, n_nodes)`.\n\n    :param activation: activation function;\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "activation",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/base.py",
    "aliases": []
  },
  {
    "name": "SAGPool",
    "base": "TopKPool",
    "docstring": "\n    A self-attention graph pooling layer from the paper\n\n    > [Self-Attention Graph Pooling](https://arxiv.org/abs/1904.08082)<br>\n    > Junhyun Lee et al.\n\n    **Mode**: single, disjoint.\n\n    This layer computes the following operations:\n    $$\n        \\y = \\textrm{GNN}(\\A, \\X); \\;\\;\\;\\;\n        \\i = \\textrm{rank}(\\y, K); \\;\\;\\;\\;\n        \\X' = (\\X \\odot \\textrm{tanh}(\\y))_\\i; \\;\\;\\;\\;\n        \\A' = \\A_{\\i, \\i}\n    $$\n    where \\(\\textrm{rank}(\\y, K)\\) returns the indices of the top K values of\n    \\(\\y\\) and\n    $$\n        \\textrm{GNN}(\\A, \\X) = \\A \\X \\W.\n    $$\n\n    \\(K\\) is defined for each graph as a fraction of the number of nodes,\n    controlled by the `ratio` argument.\n\n    **Input**\n\n    - Node features of shape `(n_nodes, n_node_features)`;\n    - Binary adjacency matrix of shape `(n_nodes, n_nodes)`;\n    - Graph IDs of shape `(n_nodes, )` (only in disjoint mode);\n\n    **Output**\n\n    - Reduced node features of shape `(ratio * n_nodes, n_node_features)`;\n    - Reduced adjacency matrix of shape `(ratio * n_nodes, ratio * n_nodes)`;\n    - Reduced graph IDs of shape `(ratio * n_nodes, )` (only in disjoint mode);\n    - If `return_mask=True`, the binary pooling mask of shape `(ratio * n_nodes, )`.\n\n    **Arguments**\n\n    - `ratio`: float between 0 and 1, ratio of nodes to keep in each graph;\n    - `return_mask`: boolean, whether to return the binary mask used for pooling;\n    - `sigmoid_gating`: boolean, use a sigmoid gating activation instead of a\n        tanh;\n    - `kernel_initializer`: initializer for the weights;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `kernel_constraint`: constraint applied to the weights;\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "ratio",
        "default": null
      },
      {
        "name": "return_mask",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "sigmoid_gating",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/pooling/sag_pool.py",
    "aliases": []
  },
  {
    "name": "SortPool",
    "base": "Layer",
    "docstring": "\n    A SortPool layer as described by\n    [Zhang et al](https://www.cse.wustl.edu/~muhan/papers/AAAI_2018_DGCNN.pdf).\n    This layers takes a graph signal \\(\\mathbf{X}\\) and returns the topmost k\n    rows according to the last column.\n    If \\(\\mathbf{X}\\) has less than k rows, the result is zero-padded to k.\n\n    **Mode**: single, disjoint, batch.\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Graph IDs of shape `(n_nodes, )` (only in disjoint mode);\n\n    **Output**\n\n    - Pooled node features of shape `(batch, k, n_node_features)` (if single mode, shape will\n    be `(1, k, n_node_features)`).\n\n    **Arguments**\n\n    - `k`: integer, number of nodes to keep;\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "k",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/pooling/global_pool.py",
    "aliases": []
  },
  {
    "name": "SparseDropout",
    "base": "Layer",
    "docstring": "Applies Dropout to the input.\n\n    Dropout consists in randomly setting\n    a fraction `rate` of input units to 0 at each update during training time,\n    which helps prevent overfitting.\n\n    Arguments:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n    noise_shape: 1D integer tensor representing the shape of the\n      binary dropout mask that will be multiplied with the input.\n      For instance, if your inputs have shape\n      `(batch_size, timesteps, features)` and\n      you want the dropout mask to be the same for all timesteps,\n      you can use `noise_shape=(batch_size, 1, features)`.\n    seed: A Python integer to use as random seed.\n\n    Call arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      },
      {
        "name": "noise_shape",
        "default": "None"
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "spektral/layers/base.py",
    "aliases": []
  },
  {
    "name": "TAGConv",
    "base": "MessagePassing",
    "docstring": "\n    A Topology Adaptive Graph Convolutional layer (TAG) from the paper\n\n    > [Topology Adaptive Graph Convolutional Networks](https://arxiv.org/abs/1710.10370)<br>\n    > Jian Du et al.\n\n    **Mode**: single, disjoint, mixed.\n\n    **This layer expects a sparse adjacency matrix.**\n\n    This layer computes:\n    $$\n        \\Z = \\sum\\limits_{k=0}^{K} \\D^{-1/2}\\A^k\\D^{-1/2}\\X\\W^{(k)}\n    $$\n\n    **Input**\n\n    - Node features of shape `(n_nodes, n_node_features)`;\n    - Binary adjacency matrix of shape `(n_nodes, n_nodes)`.\n\n    **Output**\n\n    - Node features with the same shape of the input, but the last dimension\n    changed to `channels`.\n\n    **Arguments**\n\n    - `channels`: integer, number of output channels;\n    - `K`: the order of the layer (i.e., the layer will consider a K-hop\n    neighbourhood for each node);\n    - `activation`: activation function;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "channels",
        "default": null
      },
      {
        "name": "K",
        "default": 3
      },
      {
        "name": "aggregate",
        "default": "sum"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/convolutional/tag_conv.py",
    "aliases": []
  },
  {
    "name": "TopKPool",
    "base": "Pool",
    "docstring": "\n    A gPool/Top-K layer from the papers\n\n    > [Graph U-Nets](https://arxiv.org/abs/1905.05178)<br>\n    > Hongyang Gao and Shuiwang Ji\n\n    and\n\n    > [Towards Sparse Hierarchical Graph Classifiers](https://arxiv.org/abs/1811.01287)<br>\n    > C\u0103t\u0103lina Cangea et al.\n\n    **Mode**: single, disjoint.\n\n    This layer computes the following operations:\n    $$\n        \\y = \\frac{\\X\\p}{\\|\\p\\|}; \\;\\;\\;\\;\n        \\i = \\textrm{rank}(\\y, K); \\;\\;\\;\\;\n        \\X' = (\\X \\odot \\textrm{tanh}(\\y))_\\i; \\;\\;\\;\\;\n        \\A' = \\A_{\\i, \\i}\n    $$\n    where \\(\\textrm{rank}(\\y, K)\\) returns the indices of the top K values of\n    \\(\\y\\), and \\(\\p\\) is a learnable parameter vector of size \\(F\\).\n\n    \\(K\\) is defined for each graph as a fraction of the number of nodes,\n    controlled by the `ratio` argument.\n\n    Note that the the gating operation \\(\\textrm{tanh}(\\y)\\) (Cangea et al.)\n    can be replaced with a sigmoid (Gao & Ji).\n\n    **Input**\n\n    - Node features of shape `(n_nodes, n_node_features)`;\n    - Binary adjacency matrix of shape `(n_nodes, n_nodes)`;\n    - Graph IDs of shape `(n_nodes, )` (only in disjoint mode);\n\n    **Output**\n\n    - Reduced node features of shape `(ratio * n_nodes, n_node_features)`;\n    - Reduced adjacency matrix of shape `(ratio * n_nodes, ratio * n_nodes)`;\n    - Reduced graph IDs of shape `(ratio * n_nodes, )` (only in disjoint mode);\n    - If `return_mask=True`, the binary pooling mask of shape `(ratio * n_nodes, )`.\n\n    **Arguments**\n\n    - `ratio`: float between 0 and 1, ratio of nodes to keep in each graph;\n    - `return_mask`: boolean, whether to return the binary mask used for pooling;\n    - `sigmoid_gating`: boolean, use a sigmoid gating activation instead of a\n        tanh;\n    - `kernel_initializer`: initializer for the weights;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `kernel_constraint`: constraint applied to the weights;\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "ratio",
        "default": null
      },
      {
        "name": "return_mask",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "sigmoid_gating",
        "default": "False",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/pooling/topk_pool.py",
    "aliases": []
  },
  {
    "name": "XENetConv",
    "base": "MessagePassing",
    "docstring": "\n    A XENet convolutional layer from the paper\n\n      > [XENet: Using a new graph convolution to accelerate the timeline for protein design on quantum computers](https://www.biorxiv.org/content/10.1101/2021.05.05.442729v1)<br>\n      > Jack B. Maguire, Daniele Grattarola, Eugene Klyshko, Vikram Khipple Mulligan, Hans Melo\n\n    **Mode**: single, disjoint, mixed.\n\n    **This layer expects a sparse adjacency matrix.**\n\n    For a version of this layer that supports batch mode, you can use\n    `spektral.layers.XENetDenseConv` as a drop-in replacement.\n\n    This layer computes for each node \\(i\\):\n    $$\n        \\s_{ij} = \\text{PReLU} \\left( (\\x_{i} \\| \\x_{j} \\| \\e_{ij} \\| \\e_{ji}) \\W^{(s)} + \\b^{(s)} \\right) \\\\\n        \\s^{(\\text{out})}_{i} = \\sum\\limits_{j \\in \\mathcal{N}(i)} \\s_{ij} \\\\\n        \\s^{(\\text{in})}_{i} = \\sum\\limits_{j \\in \\mathcal{N}(i)} \\s_{ji} \\\\\n        \\x_{i}' = \\sigma\\left( (\\x_{i} \\| \\s^{(\\text{out})}_{i} \\| \\s^{(\\text{in})}_{i}) \\W^{(n)} + \\b^{(n)} \\right) \\\\\n        \\e_{ij}' = \\sigma\\left( \\s_{ij} \\W^{(e)} + \\b^{(e)} \\right)\n    $$\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Binary adjacency matrices of shape `([batch], n_nodes, n_nodes)`;\n    - Edge features of shape `(num_edges, n_edge_features)`;\n\n    **Output**\n\n    - Node features with the same shape of the input, but the last dimension\n    changed to `node_channels`.\n    - Edge features with the same shape of the input, but the last dimension\n    changed to `edge_channels`.\n\n    **Arguments**\n\n    - `stack_channels`: integer or list of integers, number of channels for the hidden layers;\n    - `node_channels`: integer, number of output channels for the nodes;\n    - `edge_channels`: integer, number of output channels for the edges;\n    - `attention`: whether to use attention when aggregating the stacks;\n    - `node_activation`: activation function for nodes;\n    - `edge_activation`: activation function for edges;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "stack_channels",
        "default": null
      },
      {
        "name": "node_channels",
        "default": null
      },
      {
        "name": "edge_channels",
        "default": null
      },
      {
        "name": "attention",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "node_activation",
        "default": "None"
      },
      {
        "name": "edge_activation",
        "default": "None"
      },
      {
        "name": "aggregate",
        "default": "sum"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/convolutional/xenet_conv.py",
    "aliases": []
  },
  {
    "name": "XENetDenseConv",
    "base": "Conv",
    "docstring": "\n    A XENet convolutional layer from the paper\n\n      > [XENet: Using a new graph convolution to accelerate the timeline for protein design on quantum computers](https://www.biorxiv.org/content/10.1101/2021.05.05.442729v1)<br>\n      > Jack B. Maguire, Daniele Grattarola, Eugene Klyshko, Vikram Khipple Mulligan, Hans Melo\n\n    **Mode**: batch.\n\n    **This layer expects a dense adjacency matrix.**\n\n    This layer computes for each node \\(i\\):\n    $$\n        \\s_{ij} = \\text{PReLU} \\left( (\\x_{i} \\| \\x_{j} \\| \\e_{ij} \\| \\e_{ji}) \\W^{(s)} + \\b^{(s)} \\right) \\\\\n        \\s^{(\\text{out})}_{i} = \\sum\\limits_{j \\in \\mathcal{N}(i)} \\s_{ij} \\\\\n        \\s^{(\\text{in})}_{i} = \\sum\\limits_{j \\in \\mathcal{N}(i)} \\s_{ji} \\\\\n        \\x_{i}' = \\sigma\\left( (\\x_{i} \\| \\s^{(\\text{out})}_{i} \\| \\s^{(\\text{in})}_{i}) \\W^{(n)} + \\b^{(n)} \\right) \\\\\n        \\e_{ij}' = \\sigma\\left( \\s_{ij} \\W^{(e)} + \\b^{(e)} \\right)\n    $$\n\n    **Input**\n\n    - Node features of shape `([batch], n_nodes, n_node_features)`;\n    - Binary adjacency matrices of shape `([batch], n_nodes, n_nodes)`;\n    - Edge features of shape `(batch, n_nodes, n_nodes, n_edge_features)`.\n\n    **Output**\n\n    - Node features with the same shape of the input, but the last dimension\n    changed to `node_channels`.\n    - Edge features with the same shape of the input, but the last dimension\n    changed to `edge_channels`.\n\n    **Arguments**\n\n    - `stack_channels`: integer or list of integers, number of channels for the hidden layers;\n    - `node_channels`: integer, number of output channels for the nodes;\n    - `edge_channels`: integer, number of output channels for the edges;\n    - `attention`: whether to use attention when aggregating the stacks;\n    - `node_activation`: activation function for nodes;\n    - `edge_activation`: activation function for edges;\n    - `use_bias`: bool, add a bias vector to the output;\n    - `kernel_initializer`: initializer for the weights;\n    - `bias_initializer`: initializer for the bias vector;\n    - `kernel_regularizer`: regularization applied to the weights;\n    - `bias_regularizer`: regularization applied to the bias vector;\n    - `activity_regularizer`: regularization applied to the output;\n    - `kernel_constraint`: constraint applied to the weights;\n    - `bias_constraint`: constraint applied to the bias vector.\n    ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "stack_channels",
        "default": null
      },
      {
        "name": "node_channels",
        "default": null
      },
      {
        "name": "edge_channels",
        "default": null
      },
      {
        "name": "attention",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "node_activation",
        "default": "None"
      },
      {
        "name": "edge_activation",
        "default": "None"
      },
      {
        "name": "aggregate",
        "default": "sum"
      },
      {
        "name": "use_bias",
        "default": "True",
        "type": "boolean"
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "spektral/layers/convolutional/xenet_conv.py",
    "aliases": []
  },
  {
    "name": "Input",
    "arguments": [
      {
        "name": "shape",
        "default": "None"
      },
      {
        "name": "batch_size",
        "default": "None"
      },
      {
        "name": "name",
        "default": "None"
      },
      {
        "name": "dtype",
        "default": "None"
      },
      {
        "name": "sparse",
        "default": "None"
      },
      {
        "name": "tensor",
        "default": "None"
      },
      {
        "name": "ragged",
        "default": "None"
      },
      {
        "name": "type_spec",
        "default": "None"
      }
    ],
    "docstring": "`Input()` is used to instantiate a Keras tensor.\n\n  A Keras tensor is a symbolic tensor-like object,\n  which we augment with certain attributes that allow us to build a Keras model\n  just by knowing the inputs and outputs of the model.\n\n  For instance, if `a`, `b` and `c` are Keras tensors,\n  it becomes possible to do:\n  `model = Model(input=[a, b], output=c)`\n\n  Args:\n      shape: A shape tuple (integers), not including the batch size.\n          For instance, `shape=(32,)` indicates that the expected input\n          will be batches of 32-dimensional vectors. Elements of this tuple\n          can be None; 'None' elements represent dimensions where the shape is\n          not known.\n      batch_size: optional static batch size (integer).\n      name: An optional name string for the layer.\n          Should be unique in a model (do not reuse the same name twice).\n          It will be autogenerated if it isn't provided.\n      dtype: The data type expected by the input, as a string\n          (`float32`, `float64`, `int32`...)\n      sparse: A boolean specifying whether the placeholder to be created is\n          sparse. Only one of 'ragged' and 'sparse' can be True. Note that,\n          if `sparse` is False, sparse tensors can still be passed into the\n          input - they will be densified with a default value of 0.\n      tensor: Optional existing tensor to wrap into the `Input` layer.\n          If set, the layer will use the `tf.TypeSpec` of this tensor rather\n          than creating a new placeholder tensor.\n      ragged: A boolean specifying whether the placeholder to be created is\n          ragged. Only one of 'ragged' and 'sparse' can be True. In this case,\n          values of 'None' in the 'shape' argument represent ragged dimensions.\n          For more information about RaggedTensors, see\n          [this guide](https://www.tensorflow.org/guide/ragged_tensors).\n      type_spec: A `tf.TypeSpec` object to create the input placeholder from.\n          When provided, all other args except name must be None.\n      **kwargs: deprecated arguments support. Supports `batch_shape` and\n          `batch_input_shape`.\n\n  Returns:\n    A `tensor`.\n\n  Example:\n\n  ```python\n  # this is a logistic regression in Keras\n  x = Input(shape=(32,))\n  y = Dense(16, activation='softmax')(x)\n  model = Model(x, y)\n  ```\n\n  Note that even if eager execution is enabled,\n  `Input` produces a symbolic tensor-like object (i.e. a placeholder).\n  This symbolic tensor-like object can be used with lower-level\n  TensorFlow ops that take tensors as inputs, as such:\n\n  ```python\n  x = Input(shape=(32,))\n  y = tf.square(x)  # This op will be treated like a layer\n  model = Model(x, y)\n  ```\n\n  (This behavior does not work for higher-order TensorFlow APIs such as\n  control flow and being directly watched by a `tf.GradientTape`).\n\n  However, the resulting model will not track any variables that were\n  used as inputs to TensorFlow ops. All variable usages must happen within\n  Keras layers to make sure they will be tracked by the model's weights.\n\n  The Keras Input can also create a placeholder from an arbitrary `tf.TypeSpec`,\n  e.g:\n\n  ```python\n  x = Input(type_spec=tf.RaggedTensorSpec(shape=[None, None],\n                                          dtype=tf.float32, ragged_rank=1))\n  y = x.values\n  model = Model(x, y)\n  ```\n  When passing an arbitrary `tf.TypeSpec`, it must represent the signature of an\n  entire batch instead of just one example.\n\n  Raises:\n    ValueError: If both `sparse` and `ragged` are provided.\n    ValueError: If both `shape` and (`batch_input_shape` or `batch_shape`) are\n      provided.\n    ValueError: If `shape`, `tensor` and `type_spec` are None.\n    ValueError: If arguments besides `type_spec` are non-None while `type_spec`\n                is passed.\n    ValueError: if any unrecognized parameters are provided.\n  ",
    "file": "keras/engine/input_layer.py",
    "aliases": [],
    "abstract": false
  }
]