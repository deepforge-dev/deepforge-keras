[
  {
    "name": "AbstractRNNCell",
    "base": "Layer",
    "docstring": "Abstract object representing an RNN cell.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  This is the base class for implementing RNN cells with custom behavior.\n\n  Every `RNNCell` must have the properties below and implement `call` with\n  the signature `(output, next_state) = call(input, state)`.\n\n  Examples:\n\n  ```python\n    class MinimalRNNCell(AbstractRNNCell):\n\n      def __init__(self, units, **kwargs):\n        self.units = units\n        super(MinimalRNNCell, self).__init__(**kwargs)\n\n      @property\n      def state_size(self):\n        return self.units\n\n      def build(self, input_shape):\n        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                      initializer='uniform',\n                                      name='kernel')\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units),\n            initializer='uniform',\n            name='recurrent_kernel')\n        self.built = True\n\n      def call(self, inputs, states):\n        prev_output = states[0]\n        h = K.dot(inputs, self.kernel)\n        output = h + K.dot(prev_output, self.recurrent_kernel)\n        return output, output\n  ```\n\n  This definition of cell differs from the definition used in the literature.\n  In the literature, 'cell' refers to an object with a single scalar output.\n  This definition refers to a horizontal array of such units.\n\n  An RNN cell, in the most abstract setting, is anything that has\n  a state and performs some operation that takes a matrix of inputs.\n  This operation results in an output matrix with `self.output_size` columns.\n  If `self.state_size` is an integer, this operation also results in a new\n  state matrix with `self.state_size` columns.  If `self.state_size` is a\n  (possibly nested tuple of) TensorShape object(s), then it should return a\n  matching structure of Tensors having shape `[batch_size].concatenate(s)`\n  for each `s` in `self.batch_size`.\n  ",
    "arguments": null,
    "abstract": true,
    "outputs": [],
    "inputs": null,
    "file": "tensorflow/python/keras/layers/recurrent.py",
    "aliases": []
  },
  {
    "name": "Activation",
    "base": "Layer",
    "docstring": "Applies an activation function to an output.\n\n  Arguments:\n    activation: Activation function, such as `tf.nn.relu`, or string name of\n      built-in activation function, such as \"relu\".\n\n  Usage:\n\n  >>> layer = tf.keras.layers.Activation('relu')\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [0.0, 0.0, 0.0, 2.0]\n  >>> layer = tf.keras.layers.Activation(tf.nn.relu)\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [0.0, 0.0, 0.0, 2.0]\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the batch axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as input.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "activation",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "ActivityRegularization",
    "base": "Layer",
    "docstring": "Layer that applies an update to the cost function based input activity.\n\n  Arguments:\n    l1: L1 regularization factor (positive float).\n    l2: L2 regularization factor (positive float).\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as input.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "l1",
        "default": 0.0
      },
      {
        "name": "l2",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "Add",
    "base": "_Merge",
    "docstring": "Layer that adds a list of inputs.\n\n  It takes as input a list of tensors,\n  all of the same shape, and returns\n  a single tensor (also of the same shape).\n\n  Examples:\n\n  >>> input_shape = (2, 3, 4)\n  >>> x1 = tf.random.normal(input_shape)\n  >>> x2 = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Add()([x1, x2])\n  >>> print(y.shape)\n  (2, 3, 4)\n\n  Used in a functional model:\n\n  >>> input1 = tf.keras.layers.Input(shape=(16,))\n  >>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1)\n  >>> input2 = tf.keras.layers.Input(shape=(32,))\n  >>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2)\n  >>> # equivalent to `added = tf.keras.layers.add([x1, x2])`\n  >>> added = tf.keras.layers.Add()([x1, x2])\n  >>> out = tf.keras.layers.Dense(4)(added)\n  >>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "AdditiveAttention",
    "base": "BaseDenseAttention",
    "docstring": "Additive attention layer, a.k.a. Bahdanau-style attention.\n\n  Inputs are `query` tensor of shape `[batch_size, Tq, dim]`, `value` tensor of\n  shape `[batch_size, Tv, dim]` and `key` tensor of shape\n  `[batch_size, Tv, dim]`. The calculation follows the steps:\n\n  1. Reshape `query` and `value` into shapes `[batch_size, Tq, 1, dim]`\n     and `[batch_size, 1, Tv, dim]` respectively.\n  2. Calculate scores with shape `[batch_size, Tq, Tv]` as a non-linear\n     sum: `scores = tf.reduce_sum(tf.tanh(query + value), axis=-1)`\n  3. Use scores to calculate a distribution with shape\n     `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.\n  4. Use `distribution` to create a linear combination of `value` with\n     shape `batch_size, Tq, dim]`:\n     `return tf.matmul(distribution, value)`.\n\n  Args:\n    use_scale: If `True`, will create a variable to scale the attention scores.\n    causal: Boolean. Set to `True` for decoder self-attention. Adds a mask such\n      that position `i` cannot attend to positions `j > i`. This prevents the\n      flow of information from the future towards the past.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n      attention scores.\n\n  Call Arguments:\n\n    inputs: List of the following tensors:\n      * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n      * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n      * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n        given, will use `value` for both `key` and `value`, which is the\n        most common case.\n    mask: List of the following tensors:\n      * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n        If given, the output will be zero at the positions where\n        `mask==False`.\n      * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n        If given, will apply the mask such that values at positions where\n        `mask==False` do not contribute to the result.\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (no dropout).\n\n  Output shape:\n\n    Attention outputs of shape `[batch_size, Tq, dim]`.\n\n  The meaning of `query`, `value` and `key` depend on the application. In the\n  case of text similarity, for example, `query` is the sequence embeddings of\n  the first piece of text and `value` is the sequence embeddings of the second\n  piece of text. `key` is usually the same tensor as `value`.\n\n  Here is a code example for using `AdditiveAttention` in a CNN+Attention\n  network:\n\n  ```python\n  # Variable-length int sequences.\n  query_input = tf.keras.Input(shape=(None,), dtype='int32')\n  value_input = tf.keras.Input(shape=(None,), dtype='int32')\n\n  # Embedding lookup.\n  token_embedding = tf.keras.layers.Embedding(max_tokens, dimension)\n  # Query embeddings of shape [batch_size, Tq, dimension].\n  query_embeddings = token_embedding(query_input)\n  # Value embeddings of shape [batch_size, Tv, dimension].\n  value_embeddings = token_embedding(value_input)\n\n  # CNN layer.\n  cnn_layer = tf.keras.layers.Conv1D(\n      filters=100,\n      kernel_size=4,\n      # Use 'same' padding so outputs have the same shape as inputs.\n      padding='same')\n  # Query encoding of shape [batch_size, Tq, filters].\n  query_seq_encoding = cnn_layer(query_embeddings)\n  # Value encoding of shape [batch_size, Tv, filters].\n  value_seq_encoding = cnn_layer(value_embeddings)\n\n  # Query-value attention of shape [batch_size, Tq, filters].\n  query_value_attention_seq = tf.keras.layers.AdditiveAttention()(\n      [query_seq_encoding, value_seq_encoding])\n\n  # Reduce over the sequence axis to produce encodings of shape\n  # [batch_size, filters].\n  query_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n      query_seq_encoding)\n  query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n      query_value_attention_seq)\n\n  # Concatenate query and document encodings to produce a DNN input layer.\n  input_layer = tf.keras.layers.Concatenate()(\n      [query_encoding, query_value_attention])\n\n  # Add DNN layers, and create Model.\n  # ...\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "use_scale",
        "default": true
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/dense_attention.py",
    "aliases": []
  },
  {
    "name": "AlphaDropout",
    "base": "Layer",
    "docstring": "Applies Alpha Dropout to the input.\n\n  Alpha Dropout is a `Dropout` that keeps mean and variance of inputs\n  to their original values, in order to ensure the self-normalizing property\n  even after this dropout.\n  Alpha Dropout fits well to Scaled Exponential Linear Units\n  by randomly setting activations to the negative saturation value.\n\n  Arguments:\n    rate: float, drop probability (as with `Dropout`).\n      The multiplicative noise will have\n      standard deviation `sqrt(rate / (1 - rate))`.\n    seed: A Python integer to use as random seed.\n\n  Call arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as input.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      },
      {
        "name": "noise_shape",
        "default": "None"
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/noise.py",
    "aliases": []
  },
  {
    "name": "Attention",
    "base": "BaseDenseAttention",
    "docstring": "Dot-product attention layer, a.k.a. Luong-style attention.\n\n  Inputs are `query` tensor of shape `[batch_size, Tq, dim]`, `value` tensor of\n  shape `[batch_size, Tv, dim]` and `key` tensor of shape\n  `[batch_size, Tv, dim]`. The calculation follows the steps:\n\n  1. Calculate scores with shape `[batch_size, Tq, Tv]` as a `query`-`key` dot\n     product: `scores = tf.matmul(query, key, transpose_b=True)`.\n  2. Use scores to calculate a distribution with shape\n     `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.\n  3. Use `distribution` to create a linear combination of `value` with\n     shape `[batch_size, Tq, dim]`:\n     `return tf.matmul(distribution, value)`.\n\n  Args:\n    use_scale: If `True`, will create a scalar variable to scale the attention\n      scores.\n    causal: Boolean. Set to `True` for decoder self-attention. Adds a mask such\n      that position `i` cannot attend to positions `j > i`. This prevents the\n      flow of information from the future towards the past.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n      attention scores.\n\n  Call Arguments:\n\n    inputs: List of the following tensors:\n      * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n      * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n      * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n        given, will use `value` for both `key` and `value`, which is the\n        most common case.\n    mask: List of the following tensors:\n      * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n        If given, the output will be zero at the positions where\n        `mask==False`.\n      * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n        If given, will apply the mask such that values at positions where\n        `mask==False` do not contribute to the result.\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (no dropout).\n\n  Output shape:\n\n    Attention outputs of shape `[batch_size, Tq, dim]`.\n\n  The meaning of `query`, `value` and `key` depend on the application. In the\n  case of text similarity, for example, `query` is the sequence embeddings of\n  the first piece of text and `value` is the sequence embeddings of the second\n  piece of text. `key` is usually the same tensor as `value`.\n\n  Here is a code example for using `Attention` in a CNN+Attention network:\n\n  ```python\n  # Variable-length int sequences.\n  query_input = tf.keras.Input(shape=(None,), dtype='int32')\n  value_input = tf.keras.Input(shape=(None,), dtype='int32')\n\n  # Embedding lookup.\n  token_embedding = tf.keras.layers.Embedding(max_tokens, dimension)\n  # Query embeddings of shape [batch_size, Tq, dimension].\n  query_embeddings = token_embedding(query_input)\n  # Value embeddings of shape [batch_size, Tv, dimension].\n  value_embeddings = token_embedding(value_input)\n\n  # CNN layer.\n  cnn_layer = tf.keras.layers.Conv1D(\n      filters=100,\n      kernel_size=4,\n      # Use 'same' padding so outputs have the same shape as inputs.\n      padding='same')\n  # Query encoding of shape [batch_size, Tq, filters].\n  query_seq_encoding = cnn_layer(query_embeddings)\n  # Value encoding of shape [batch_size, Tv, filters].\n  value_seq_encoding = cnn_layer(value_embeddings)\n\n  # Query-value attention of shape [batch_size, Tq, filters].\n  query_value_attention_seq = tf.keras.layers.Attention()(\n      [query_seq_encoding, value_seq_encoding])\n\n  # Reduce over the sequence axis to produce encodings of shape\n  # [batch_size, filters].\n  query_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n      query_seq_encoding)\n  query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n      query_value_attention_seq)\n\n  # Concatenate query and document encodings to produce a DNN input layer.\n  input_layer = tf.keras.layers.Concatenate()(\n      [query_encoding, query_value_attention])\n\n  # Add DNN layers, and create Model.\n  # ...\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "use_scale",
        "default": false
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/dense_attention.py",
    "aliases": []
  },
  {
    "name": "Average",
    "base": "_Merge",
    "docstring": "Layer that averages a list of inputs element-wise.\n\n  It takes as input a list of tensors, all of the same shape, and returns\n  a single tensor (also of the same shape).\n\n  Example:\n\n  >>> x1 = np.ones((2, 2))\n  >>> x2 = np.zeros((2, 2))\n  >>> y = tf.keras.layers.Average()([x1, x2])\n  >>> y.numpy().tolist()\n  [[0.5, 0.5], [0.5, 0.5]]\n\n  Usage in a functional model:\n\n  >>> input1 = tf.keras.layers.Input(shape=(16,))\n  >>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1)\n  >>> input2 = tf.keras.layers.Input(shape=(32,))\n  >>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2)\n  >>> avg = tf.keras.layers.Average()([x1, x2])\n  >>> out = tf.keras.layers.Dense(4)(avg)\n  >>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n\n  Raises:\n    ValueError: If there is a shape mismatch between the inputs and the shapes\n      cannot be broadcasted to match.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "AvgPool1D",
    "base": "Pooling1D",
    "docstring": "Average pooling for temporal data.\n\n  Arguments:\n    pool_size: Integer, size of the average pooling windows.\n    strides: Integer, or None. Factor by which to downscale.\n      E.g. 2 will halve the input.\n      If None, it will default to `pool_size`.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, steps, features)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, features, steps)`.\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      3D tensor with shape `(batch_size, steps, features)`.\n    - If `data_format='channels_first'`:\n      3D tensor with shape `(batch_size, features, steps)`.\n\n  Output shape:\n    - If `data_format='channels_last'`:\n      3D tensor with shape `(batch_size, downsampled_steps, features)`.\n    - If `data_format='channels_first'`:\n      3D tensor with shape `(batch_size, features, downsampled_steps)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "pool_size",
        "default": 2
      },
      {
        "name": "strides",
        "default": "None"
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "channels_last"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/pooling.py",
    "aliases": [
      "AveragePooling1D"
    ]
  },
  {
    "name": "AvgPool2D",
    "base": "Pooling2D",
    "docstring": "Average pooling operation for spatial data.\n\n  Arguments:\n    pool_size: integer or tuple of 2 integers,\n      factors by which to downscale (vertical, horizontal).\n      `(2, 2)` will halve the input in both spatial dimension.\n      If only one integer is specified, the same window length\n      will be used for both dimensions.\n    strides: Integer, tuple of 2 integers, or None.\n      Strides values.\n      If None, it will default to `pool_size`.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      4D tensor with shape `(batch_size, rows, cols, channels)`.\n    - If `data_format='channels_first'`:\n      4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n  Output shape:\n    - If `data_format='channels_last'`:\n      4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n    - If `data_format='channels_first'`:\n      4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "pool_size",
        "default": [
          2,
          2
        ]
      },
      {
        "name": "strides",
        "default": "None"
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/pooling.py",
    "aliases": [
      "AveragePooling2D"
    ]
  },
  {
    "name": "AvgPool3D",
    "base": "Pooling3D",
    "docstring": "Average pooling operation for 3D data (spatial or spatio-temporal).\n\n  Arguments:\n    pool_size: tuple of 3 integers,\n      factors by which to downscale (dim1, dim2, dim3).\n      `(2, 2, 2)` will halve the size of the 3D input in each dimension.\n    strides: tuple of 3 integers, or None. Strides values.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      5D tensor with shape:\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n      5D tensor with shape:\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\n  Output shape:\n    - If `data_format='channels_last'`:\n      5D tensor with shape:\n      `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n    - If `data_format='channels_first'`:\n      5D tensor with shape:\n      `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "pool_size",
        "default": [
          2,
          2,
          2
        ]
      },
      {
        "name": "strides",
        "default": "None"
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/pooling.py",
    "aliases": [
      "AveragePooling3D"
    ]
  },
  {
    "name": "BatchNormalization",
    "base": "BatchNormalizationBase",
    "docstring": "Normalize and scale inputs or activations.\n\n  Normalize the activations of the previous layer at each batch,\n  i.e. applies a transformation that maintains the mean activation\n  close to 0 and the activation standard deviation close to 1.\n\n  Batch normalization differs from other layers in several key aspects:\n\n  1) Adding BatchNormalization with `training=True` to a model causes the\n  result of one example to depend on the contents of all other examples in a\n  minibatch. Be careful when padding batches or masking examples, as these can\n  change the minibatch statistics and affect other examples.\n\n  2) Updates to the weights (moving statistics) are based on the forward pass\n  of a model rather than the result of gradient computations.\n\n  3) When performing inference using a model containing batch normalization, it\n  is generally (though not always) desirable to use accumulated statistics\n  rather than mini-batch statistics. This is accomplished by passing\n  `training=False` when calling the model, or using `model.predict`.\n\n  Arguments:\n    axis: Integer, the axis that should be normalized (typically the features\n      axis). For instance, after a `Conv2D` layer with\n      `data_format=\"channels_first\"`, set `axis=1` in `BatchNormalization`.\n    momentum: Momentum for the moving average.\n    epsilon: Small float added to variance to avoid dividing by zero.\n    center: If True, add offset of `beta` to normalized tensor. If False, `beta`\n      is ignored.\n    scale: If True, multiply by `gamma`. If False, `gamma` is not used. When the\n      next layer is linear (also e.g. `nn.relu`), this can be disabled since the\n      scaling will be done by the next layer.\n    beta_initializer: Initializer for the beta weight.\n    gamma_initializer: Initializer for the gamma weight.\n    moving_mean_initializer: Initializer for the moving mean.\n    moving_variance_initializer: Initializer for the moving variance.\n    beta_regularizer: Optional regularizer for the beta weight.\n    gamma_regularizer: Optional regularizer for the gamma weight.\n    beta_constraint: Optional constraint for the beta weight.\n    gamma_constraint: Optional constraint for the gamma weight.\n    renorm: Whether to use [Batch Renormalization](\n      https://arxiv.org/abs/1702.03275). This adds extra variables during\n        training. The inference is the same for either value of this parameter.\n    renorm_clipping: A dictionary that may map keys 'rmax', 'rmin', 'dmax' to\n      scalar `Tensors` used to clip the renorm correction. The correction `(r,\n      d)` is used as `corrected_value = normalized_value * r + d`, with `r`\n      clipped to [rmin, rmax], and `d` to [-dmax, dmax]. Missing rmax, rmin,\n      dmax are set to inf, 0, inf, respectively.\n    renorm_momentum: Momentum used to update the moving means and standard\n      deviations with renorm. Unlike `momentum`, this affects training and\n      should be neither too small (which would add noise) nor too large (which\n      would give stale estimates). Note that `momentum` is still applied to get\n      the means and variances for inference.\n    fused: if `True`, use a faster, fused implementation, or raise a ValueError\n      if the fused implementation cannot be used. If `None`, use the faster\n      implementation if possible. If False, do not used the fused\n      implementation.\n    trainable: Boolean, if `True` the variables will be marked as trainable.\n    virtual_batch_size: An `int`. By default, `virtual_batch_size` is `None`,\n      which means batch normalization is performed across the whole batch. When\n      `virtual_batch_size` is not `None`, instead perform \"Ghost Batch\n      Normalization\", which creates virtual sub-batches which are each\n      normalized separately (with shared gamma, beta, and moving statistics).\n      Must divide the actual batch size during execution.\n    adjustment: A function taking the `Tensor` containing the (dynamic) shape of\n      the input tensor and returning a pair (scale, bias) to apply to the\n      normalized values (before gamma and beta), only during training. For\n      example, if axis==-1,\n        `adjustment = lambda shape: (\n          tf.random.uniform(shape[-1:], 0.93, 1.07),\n          tf.random.uniform(shape[-1:], -0.1, 0.1))` will scale the normalized\n            value by up to 7% up or down, then shift the result by up to 0.1\n            (with independent scaling and bias for each feature but shared\n            across all examples), and finally apply gamma and/or beta. If\n            `None`, no adjustment is applied. Cannot be specified if\n            virtual_batch_size is specified.\n  Call arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode.\n      - `training=True`: The layer will normalize its inputs using the mean and\n        variance of the current batch of inputs.\n      - `training=False`: The layer will normalize its inputs using the mean and\n        variance of its moving statistics, learned during training.\n  Input shape: Arbitrary. Use the keyword argument `input_shape` (tuple of\n    integers, does not include the samples axis) when using this layer as the\n    first layer in a model.\n  Output shape: Same shape as input.  \n  **About setting `layer.trainable = False` on a `BatchNormalization layer:**\n\n  The meaning of setting `layer.trainable = False` is to freeze the layer,\n  i.e. its internal state will not change during training:\n  its trainable weights will not be updated\n  during `fit()` or `train_on_batch()`, and its state updates will not be run.\n\n  Usually, this does not necessarily mean that the layer is run in inference\n  mode (which is normally controlled by the `training` argument that can\n  be passed when calling a layer). \"Frozen state\" and \"inference mode\"\n  are two separate concepts.\n\n  However, in the case of the `BatchNormalization` layer, **setting\n  `trainable = False` on the layer means that the layer will be\n  subsequently run in inference mode** (meaning that it will use\n  the moving mean and the moving variance to normalize the current batch,\n  rather than using the mean and variance of the current batch).\n\n  This behavior has been introduced in TensorFlow 2.0, in order\n  to enable `layer.trainable = False` to produce the most commonly\n  expected behavior in the convnet fine-tuning use case.\n\n  Note that:\n    - This behavior only occurs as of TensorFlow 2.0. In 1.*,\n      setting `layer.trainable = False` would freeze the layer but would\n      not switch it to inference mode.\n    - Setting `trainable` on an model containing other layers will\n      recursively set the `trainable` value of all inner layers.\n    - If the value of the `trainable`\n      attribute is changed after calling `compile()` on a model,\n      the new value doesn't take effect for this model\n      until `compile()` is called again.\n      \n  Normalization equations: Consider the intermediate activations \\(x\\) of a\n    mini-batch of size\n    \\\\(m\\\\):  We can compute the mean and variance of the batch  \\\\({\\mu_B} =\n      \\frac{1}{m} \\sum_{i=1}^{m} {x_i}\\\\)  \\\\({\\sigma_B^2} = \\frac{1}{m}\n      \\sum_{i=1}^{m} ({x_i} - {\\mu_B})^2\\\\)  and then compute a normalized\n      \\\\(x\\\\), including a small factor \\\\({\\epsilon}\\\\) for numerical\n      stability.  \\\\(\\hat{x_i} = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 +\n      \\epsilon}}\\\\)  And finally \\\\(\\hat{x}\\) is linearly transformed by\n      \\({\\gamma}\\\\)\n    and \\\\({\\beta}\\\\), which are learned parameters:  \\\\({y_i} = {\\gamma *\n      \\hat{x_i} + \\beta}\\\\)\n  Reference:\n    - [Ioffe and Szegedy, 2015](https://arxiv.org/abs/1502.03167).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "axis",
        "default": -1
      },
      {
        "name": "momentum",
        "default": 0.99
      },
      {
        "name": "epsilon",
        "default": 0.001
      },
      {
        "name": "center",
        "default": true
      },
      {
        "name": "scale",
        "default": true
      },
      {
        "name": "beta_initializer",
        "default": "zeros"
      },
      {
        "name": "gamma_initializer",
        "default": "ones"
      },
      {
        "name": "moving_mean_initializer",
        "default": "zeros"
      },
      {
        "name": "moving_variance_initializer",
        "default": "ones"
      },
      {
        "name": "beta_regularizer",
        "default": "None"
      },
      {
        "name": "gamma_regularizer",
        "default": "None"
      },
      {
        "name": "beta_constraint",
        "default": "None"
      },
      {
        "name": "gamma_constraint",
        "default": "None"
      },
      {
        "name": "renorm",
        "default": false
      },
      {
        "name": "renorm_clipping",
        "default": "None"
      },
      {
        "name": "renorm_momentum",
        "default": 0.99
      },
      {
        "name": "fused",
        "default": "None"
      },
      {
        "name": "trainable",
        "default": true
      },
      {
        "name": "virtual_batch_size",
        "default": "None"
      },
      {
        "name": "adjustment",
        "default": "None"
      },
      {
        "name": "name",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/normalization_v2.py",
    "aliases": []
  },
  {
    "name": "Bidirectional",
    "base": "Wrapper",
    "docstring": "Bidirectional wrapper for RNNs.\n\n  Arguments:\n    layer: `keras.layers.RNN` instance, such as `keras.layers.LSTM` or\n      `keras.layers.GRU`. It could also be a `keras.layers.Layer` instance\n      that meets the following criteria:\n      1. Be a sequence-processing layer (accepts 3D+ inputs).\n      2. Have a `go_backwards`, `return_sequences` and `return_state`\n        attribute (with the same semantics as for the `RNN` class).\n      3. Have an `input_spec` attribute.\n      4. Implement serialization via `get_config()` and `from_config()`.\n      Note that the recommended way to create new RNN layers is to write a\n      custom RNN cell and use it with `keras.layers.RNN`, instead of\n      subclassing `keras.layers.Layer` directly.\n    merge_mode: Mode by which outputs of the forward and backward RNNs will be\n      combined. One of {'sum', 'mul', 'concat', 'ave', None}. If None, the\n      outputs will not be combined, they will be returned as a list. Default\n      value is 'concat'.\n    backward_layer: Optional `keras.layers.RNN`, or `keras.layers.Layer`\n      instance to be used to handle backwards input processing.\n      If `backward_layer` is not provided, the layer instance passed as the\n      `layer` argument will be used to generate the backward layer\n      automatically.\n      Note that the provided `backward_layer` layer should have properties\n      matching those of the `layer` argument, in particular it should have the\n      same values for `stateful`, `return_states`, `return_sequence`, etc.\n      In addition, `backward_layer` and `layer` should have different\n      `go_backwards` argument values.\n      A `ValueError` will be raised if these requirements are not met.\n\n  Call arguments:\n    The call arguments for this layer are the same as those of the wrapped RNN\n      layer.\n    Beware that when passing the `initial_state` argument during the call of\n    this layer, the first half in the list of elements in the `initial_state`\n    list will be passed to the forward RNN call and the last half in the list\n    of elements will be passed to the backward RNN call.\n\n  Raises:\n    ValueError:\n      1. If `layer` or `backward_layer` is not a `Layer` instance.\n      2. In case of invalid `merge_mode` argument.\n      3. If `backward_layer` has mismatched properties compared to `layer`.\n\n  Examples:\n\n  ```python\n  model = Sequential()\n  model.add(Bidirectional(LSTM(10, return_sequences=True), input_shape=(5, 10)))\n  model.add(Bidirectional(LSTM(10)))\n  model.add(Dense(5))\n  model.add(Activation('softmax'))\n  model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n   # With custom backward layer\n   model = Sequential()\n   forward_layer = LSTM(10, return_sequences=True)\n   backward_layer = LSTM(10, activation='relu', return_sequences=True,\n                         go_backwards=True)\n   model.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n                           input_shape=(5, 10)))\n   model.add(Dense(5))\n   model.add(Activation('softmax'))\n   model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "layer",
        "default": null
      },
      {
        "name": "merge_mode",
        "default": "concat"
      },
      {
        "name": "weights",
        "default": "None"
      },
      {
        "name": "backward_layer",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "initial_state",
        "default": "None"
      },
      {
        "name": "constants",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/wrappers.py",
    "aliases": []
  },
  {
    "name": "Concatenate",
    "base": "_Merge",
    "docstring": "Layer that concatenates a list of inputs.\n\n  It takes as input a list of tensors, all of the same shape except\n  for the concatenation axis, and returns a single tensor that is the\n  concatenation of all inputs.\n\n  >>> x = np.arange(20).reshape(2, 2, 5)\n  >>> print(x)\n  [[[ 0  1  2  3  4]\n    [ 5  6  7  8  9]]\n   [[10 11 12 13 14]\n    [15 16 17 18 19]]]\n  >>> y = np.arange(20, 30).reshape(2, 1, 5)\n  >>> print(y)\n  [[[20 21 22 23 24]]\n   [[25 26 27 28 29]]]\n  >>> tf.keras.layers.Concatenate(axis=1)([x, y])\n  <tf.Tensor: shape=(2, 3, 5), dtype=int64, numpy=\n  array([[[ 0,  1,  2,  3,  4],\n          [ 5,  6,  7,  8,  9],\n          [20, 21, 22, 23, 24]],\n         [[10, 11, 12, 13, 14],\n          [15, 16, 17, 18, 19],\n          [25, 26, 27, 28, 29]]])>\n\n  >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n  >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n  >>> concatted = tf.keras.layers.Concatenate()([x1, x2])\n  >>> concatted.shape\n  TensorShape([5, 16])\n\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "axis",
        "default": -1
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "Conv1D",
    "base": "Conv",
    "docstring": "1D convolution layer (e.g. temporal convolution).\n\n  This layer creates a convolution kernel that is convolved\n  with the layer input over a single spatial (or temporal) dimension\n  to produce a tensor of outputs.\n  If `use_bias` is True, a bias vector is created and added to the outputs.\n  Finally, if `activation` is not `None`,\n  it is applied to the outputs as well.\n\n  When using this layer as the first layer in a model,\n  provide an `input_shape` argument\n  (tuple of integers or `None`, e.g.\n  `(10, 128)` for sequences of 10 vectors of 128-dimensional vectors,\n  or `(None, 128)` for variable-length sequences of 128-dimensional vectors.\n\n  Examples:\n\n  >>> # The inputs are 128-length vectors with 10 timesteps, and the batch size\n  >>> # is 4.\n  >>> input_shape = (4, 10, 128)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv1D(\n  ... 32, 3, activation='relu',input_shape=input_shape[1:])(x)\n  >>> print(y.shape)\n  (4, 8, 32)\n\n  >>> # With extended batch shape [4, 7] (e.g. weather data where batch\n  >>> # dimensions correspond to spatial location and the third dimension\n  >>> # corresponds to time.)\n  >>> input_shape = (4, 7, 10, 128)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv1D(\n  ... 32, 3, activation='relu', input_shape=input_shape[2:])(x)\n  >>> print(y.shape)\n  (4, 7, 8, 32)\n\n  Arguments:\n    filters: Integer, the dimensionality of the output space\n      (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of a single integer,\n      specifying the length of the 1D convolution window.\n    strides: An integer or tuple/list of a single integer,\n      specifying the stride length of the convolution.\n      Specifying any stride value != 1 is incompatible with specifying\n      any `dilation_rate` value != 1.\n    padding: One of `\"valid\"`, `\"causal\"` or `\"same\"` (case-insensitive).\n      `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]`\n      does not depend on `input[t+1:]`. Useful when modeling temporal data\n      where the model should not violate the temporal order.\n      See [WaveNet: A Generative Model for Raw Audio, section\n        2.1](https://arxiv.org/abs/1609.03499).\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n    dilation_rate: an integer or tuple/list of a single integer, specifying\n      the dilation rate to use for dilated convolution.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any `strides` value != 1.\n    groups: A positive integer specifying the number of groups in which the\n      input is split along the channel axis. Each group is convolved\n      separately with `filters / groups` filters. The output is the\n      concatenation of all the `groups` results along the channel axis.\n      Input channels and `filters` must both be divisible by `groups`.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix (\n      see `keras.initializers`).\n    bias_initializer: Initializer for the bias vector (\n      see `keras.initializers`).\n    kernel_regularizer: Regularizer function applied to\n      the `kernel` weights matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its \"activation\") (\n      see `keras.regularizers`).\n    kernel_constraint: Constraint function applied to the kernel matrix (\n      see `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (\n      see `keras.constraints`).\n\n  Input shape:\n    3+D tensor with shape: `batch_shape + (steps, input_dim)`\n\n  Output shape:\n    3+D tensor with shape: `batch_shape + (new_steps, filters)`\n      `steps` value might have changed due to padding or strides.\n\n  Returns:\n    A tensor of rank 3 representing\n    `activation(conv1d(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": 1
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "channels_last"
      },
      {
        "name": "dilation_rate",
        "default": 1
      },
      {
        "name": "groups",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": [
      "Convolution1D"
    ]
  },
  {
    "name": "Conv1DTranspose",
    "base": "Conv1D",
    "docstring": "Transposed convolution layer (sometimes called Deconvolution).\n\n  The need for transposed convolutions generally arises\n  from the desire to use a transformation going in the opposite direction\n  of a normal convolution, i.e., from something that has the shape of the\n  output of some convolution to something that has the shape of its input\n  while maintaining a connectivity pattern that is compatible with\n  said convolution.\n\n  When using this layer as the first layer in a model,\n  provide the keyword argument `input_shape`\n  (tuple of integers, does not include the sample axis),\n  e.g. `input_shape=(128, 3)` for data with 128 time steps and 3 channels.\n\n  Arguments:\n    filters: Integer, the dimensionality of the output space\n      (i.e. the number of output filters in the convolution).\n    kernel_size: An integer length of the 1D convolution window.\n    strides: An integer specifying the stride of the convolution along the\n      time dimension. Specifying a stride value != 1 is incompatible with\n      specifying a `dilation_rate` value != 1. Defaults to 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    output_padding: An integer specifying the amount of padding along\n      the time dimension of the output tensor.\n      The amount of output padding must be lower than the stride.\n      If set to `None` (default), the output shape is inferred.\n    data_format: A string, one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, length, channels)` while `channels_first` corresponds to\n      inputs with shape `(batch_size, channels, length)`.\n    dilation_rate: an integer, specifying\n      the dilation rate to use for dilated convolution.\n      Currently, specifying a `dilation_rate` value != 1 is\n      incompatible with specifying a stride value != 1.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix (\n      see `keras.initializers`).\n    bias_initializer: Initializer for the bias vector (\n      see `keras.initializers`).\n    kernel_regularizer: Regularizer function applied to\n      the `kernel` weights matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its \"activation\") (see `keras.regularizers`).\n    kernel_constraint: Constraint function applied to the kernel matrix (\n      see `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (\n      see `keras.constraints`).\n\n  Input shape:\n    3D tensor with shape:\n    `(batch_size, steps, channels)`\n\n  Output shape:\n    3D tensor with shape:\n    `(batch_size, new_steps, filters)`\n    If `output_padding` is specified:\n    ```\n    new_timesteps = ((timesteps - 1) * strides + kernel_size -\n    2 * padding + output_padding)\n    ```\n\n  Returns:\n    A tensor of rank 3 representing\n    `activation(conv1dtranspose(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is \"causal\".\n    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n\n  References:\n    - [A guide to convolution arithmetic for deep learning](\n      https://arxiv.org/abs/1603.07285v1)\n    - [Deconvolutional Networks](\n      https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": 1
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "output_padding",
        "default": "None"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": [
      "Convolution1DTranspose"
    ]
  },
  {
    "name": "Conv2D",
    "base": "Conv",
    "docstring": "2D convolution layer (e.g. spatial convolution over images).\n\n  This layer creates a convolution kernel that is convolved\n  with the layer input to produce a tensor of\n  outputs. If `use_bias` is True,\n  a bias vector is created and added to the outputs. Finally, if\n  `activation` is not `None`, it is applied to the outputs as well.\n\n  When using this layer as the first layer in a model,\n  provide the keyword argument `input_shape`\n  (tuple of integers, does not include the sample axis),\n  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n  in `data_format=\"channels_last\"`.\n\n  Examples:\n\n  >>> # The inputs are 28x28 RGB images with `channels_last` and the batch\n  >>> # size is 4.\n  >>> input_shape = (4, 28, 28, 3)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv2D(\n  ... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n  >>> print(y.shape)\n  (4, 26, 26, 2)\n\n  >>> # With `dilation_rate` as 2.\n  >>> input_shape = (4, 28, 28, 3)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv2D(\n  ... 2, 3, activation='relu', dilation_rate=2, input_shape=input_shape[1:])(x)\n  >>> print(y.shape)\n  (4, 24, 24, 2)\n\n  >>> # With `padding` as \"same\".\n  >>> input_shape = (4, 28, 28, 3)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv2D(\n  ... 2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n  >>> print(y.shape)\n  (4, 28, 28, 2)\n\n  >>> # With extended batch shape [4, 7]:\n  >>> input_shape = (4, 7, 28, 28, 3)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv2D(\n  ... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n  >>> print(y.shape)\n  (4, 7, 26, 26, 2)\n\n\n  Arguments:\n    filters: Integer, the dimensionality of the output space (i.e. the number of\n      output filters in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers, specifying the height\n      and width of the 2D convolution window. Can be a single integer to specify\n      the same value for all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers, specifying the strides of\n      the convolution along the height and width. Can be a single integer to\n      specify the same value for all spatial dimensions. Specifying any stride\n      value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string, one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs. `channels_last` corresponds\n      to inputs with shape `(batch_size, height, width, channels)` while\n      `channels_first` corresponds to inputs with shape `(batch_size, channels,\n      height, width)`. It defaults to the `image_data_format` value found in\n      your Keras config file at `~/.keras/keras.json`. If you never set it, then\n      it will be `channels_last`.\n    dilation_rate: an integer or tuple/list of 2 integers, specifying the\n      dilation rate to use for dilated convolution. Can be a single integer to\n      specify the same value for all spatial dimensions. Currently, specifying\n      any `dilation_rate` value != 1 is incompatible with specifying any stride\n      value != 1.\n    groups: A positive integer specifying the number of groups in which the\n      input is split along the channel axis. Each group is convolved separately\n      with `filters / groups` filters. The output is the concatenation of all\n      the `groups` results along the channel axis. Input channels and `filters`\n      must both be divisible by `groups`.\n    activation: Activation function to use. If you don't specify anything, no\n      activation is applied (see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix (see\n      `keras.initializers`).\n    bias_initializer: Initializer for the bias vector (see\n      `keras.initializers`).\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (see\n      `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to the output of the\n      layer (its \"activation\") (see `keras.regularizers`).\n    kernel_constraint: Constraint function applied to the kernel matrix (see\n      `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (see\n      `keras.constraints`).\n  Input shape:\n    4+D tensor with shape: `batch_shape + (channels, rows, cols)` if\n      `data_format='channels_first'`\n    or 4+D tensor with shape: `batch_shape + (rows, cols, channels)` if\n      `data_format='channels_last'`.\n  Output shape:\n    4+D tensor with shape: `batch_shape + (filters, new_rows, new_cols)` if\n    `data_format='channels_first'` or 4+D tensor with shape: `batch_shape +\n      (new_rows, new_cols, filters)` if `data_format='channels_last'`.  `rows`\n      and `cols` values might have changed due to padding.\n\n  Returns:\n    A tensor of rank 4+ representing\n    `activation(conv2d(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is `\"causal\"`.\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "groups",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": [
      "Convolution2D"
    ]
  },
  {
    "name": "Conv2DTranspose",
    "base": "Conv2D",
    "docstring": "Transposed convolution layer (sometimes called Deconvolution).\n\n  The need for transposed convolutions generally arises\n  from the desire to use a transformation going in the opposite direction\n  of a normal convolution, i.e., from something that has the shape of the\n  output of some convolution to something that has the shape of its input\n  while maintaining a connectivity pattern that is compatible with\n  said convolution.\n\n  When using this layer as the first layer in a model,\n  provide the keyword argument `input_shape`\n  (tuple of integers, does not include the sample axis),\n  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n  in `data_format=\"channels_last\"`.\n\n  Arguments:\n    filters: Integer, the dimensionality of the output space\n      (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers, specifying the\n      height and width of the 2D convolution window.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers,\n      specifying the strides of the convolution along the height and width.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n      Specifying any stride value != 1 is incompatible with specifying\n      any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    output_padding: An integer or tuple/list of 2 integers,\n      specifying the amount of padding along the height and width\n      of the output tensor.\n      Can be a single integer to specify the same value for all\n      spatial dimensions.\n      The amount of output padding along a given dimension must be\n      lower than the stride along that same dimension.\n      If set to `None` (default), the output shape is inferred.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 2 integers, specifying\n      the dilation rate to use for dilated convolution.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any stride value != 1.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix (\n      see `keras.initializers`).\n    bias_initializer: Initializer for the bias vector (\n      see `keras.initializers`).\n    kernel_regularizer: Regularizer function applied to\n      the `kernel` weights matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its \"activation\") (see `keras.regularizers`).\n    kernel_constraint: Constraint function applied to the kernel matrix (\n      see `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (\n      see `keras.constraints`).\n\n  Input shape:\n    4D tensor with shape:\n    `(batch_size, channels, rows, cols)` if data_format='channels_first'\n    or 4D tensor with shape:\n    `(batch_size, rows, cols, channels)` if data_format='channels_last'.\n\n  Output shape:\n    4D tensor with shape:\n    `(batch_size, filters, new_rows, new_cols)` if data_format='channels_first'\n    or 4D tensor with shape:\n    `(batch_size, new_rows, new_cols, filters)` if data_format='channels_last'.\n    `rows` and `cols` values might have changed due to padding.\n    If `output_padding` is specified:\n    ```\n    new_rows = ((rows - 1) * strides[0] + kernel_size[0] - 2 * padding[0] +\n    output_padding[0])\n    new_cols = ((cols - 1) * strides[1] + kernel_size[1] - 2 * padding[1] +\n    output_padding[1])\n    ```\n\n  Returns:\n    A tensor of rank 4 representing\n    `activation(conv2dtranspose(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is \"causal\".\n    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n\n  References:\n    - [A guide to convolution arithmetic for deep\n      learning](https://arxiv.org/abs/1603.07285v1)\n    - [Deconvolutional\n      Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "output_padding",
        "default": "None"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": [
      "Convolution2DTranspose"
    ]
  },
  {
    "name": "Conv3D",
    "base": "Conv",
    "docstring": "3D convolution layer (e.g. spatial convolution over volumes).\n\n  This layer creates a convolution kernel that is convolved\n  with the layer input to produce a tensor of\n  outputs. If `use_bias` is True,\n  a bias vector is created and added to the outputs. Finally, if\n  `activation` is not `None`, it is applied to the outputs as well.\n\n  When using this layer as the first layer in a model,\n  provide the keyword argument `input_shape`\n  (tuple of integers, does not include the sample axis),\n  e.g. `input_shape=(128, 128, 128, 1)` for 128x128x128 volumes\n  with a single channel,\n  in `data_format=\"channels_last\"`.\n\n  Examples:\n\n  >>> # The inputs are 28x28x28 volumes with a single channel, and the\n  >>> # batch size is 4\n  >>> input_shape =(4, 28, 28, 28, 1)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv3D(\n  ... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n  >>> print(y.shape)\n  (4, 26, 26, 26, 2)\n\n  >>> # With extended batch shape [4, 7], e.g. a batch of 4 videos of 3D frames,\n  >>> # with 7 frames per video.\n  >>> input_shape = (4, 7, 28, 28, 28, 1)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.Conv3D(\n  ... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n  >>> print(y.shape)\n  (4, 7, 26, 26, 26, 2)\n\n  Arguments:\n    filters: Integer, the dimensionality of the output space (i.e. the number of\n      output filters in the convolution).\n    kernel_size: An integer or tuple/list of 3 integers, specifying the depth,\n      height and width of the 3D convolution window. Can be a single integer to\n      specify the same value for all spatial dimensions.\n    strides: An integer or tuple/list of 3 integers, specifying the strides of\n      the convolution along each spatial dimension. Can be a single integer to\n      specify the same value for all spatial dimensions. Specifying any stride\n      value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string, one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs. `channels_last` corresponds\n      to inputs with shape `batch_shape + (spatial_dim1, spatial_dim2,\n      spatial_dim3, channels)` while `channels_first` corresponds to inputs with\n      shape `batch_shape + (channels, spatial_dim1, spatial_dim2,\n      spatial_dim3)`. It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`. If you never set it, then it\n      will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 3 integers, specifying the\n      dilation rate to use for dilated convolution. Can be a single integer to\n      specify the same value for all spatial dimensions. Currently, specifying\n      any `dilation_rate` value != 1 is incompatible with specifying any stride\n      value != 1.\n    groups: A positive integer specifying the number of groups in which the\n      input is split along the channel axis. Each group is convolved separately\n      with `filters / groups` filters. The output is the concatenation of all\n      the `groups` results along the channel axis. Input channels and `filters`\n      must both be divisible by `groups`.\n    activation: Activation function to use. If you don't specify anything, no\n      activation is applied (see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix (see\n      `keras.initializers`).\n    bias_initializer: Initializer for the bias vector (see\n      `keras.initializers`).\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (see\n      `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to the output of the\n      layer (its \"activation\") (see `keras.regularizers`).\n    kernel_constraint: Constraint function applied to the kernel matrix (see\n      `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (see\n      `keras.constraints`).\n  Input shape:\n    5+D tensor with shape: `batch_shape + (channels, conv_dim1, conv_dim2,\n      conv_dim3)` if data_format='channels_first'\n    or 5+D tensor with shape: `batch_shape + (conv_dim1, conv_dim2, conv_dim3,\n      channels)` if data_format='channels_last'.\n  Output shape:\n    5+D tensor with shape: `batch_shape + (filters, new_conv_dim1,\n      new_conv_dim2, new_conv_dim3)` if data_format='channels_first'\n    or 5+D tensor with shape: `batch_shape + (new_conv_dim1, new_conv_dim2,\n      new_conv_dim3, filters)` if data_format='channels_last'. `new_conv_dim1`,\n      `new_conv_dim2` and `new_conv_dim3` values might have changed due to\n      padding.\n\n  Returns:\n    A tensor of rank 5+ representing\n    `activation(conv3d(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is \"causal\".\n    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1,
          1
        ]
      },
      {
        "name": "groups",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": [
      "Convolution3D"
    ]
  },
  {
    "name": "Conv3DTranspose",
    "base": "Conv3D",
    "docstring": "Transposed convolution layer (sometimes called Deconvolution).\n\n  The need for transposed convolutions generally arises\n  from the desire to use a transformation going in the opposite direction\n  of a normal convolution, i.e., from something that has the shape of the\n  output of some convolution to something that has the shape of its input\n  while maintaining a connectivity pattern that is compatible with\n  said convolution.\n\n  When using this layer as the first layer in a model,\n  provide the keyword argument `input_shape`\n  (tuple of integers, does not include the sample axis),\n  e.g. `input_shape=(128, 128, 128, 3)` for a 128x128x128 volume with 3 channels\n  if `data_format=\"channels_last\"`.\n\n  Arguments:\n    filters: Integer, the dimensionality of the output space\n        (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of 3 integers, specifying the\n        depth, height and width of the 3D convolution window.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n    strides: An integer or tuple/list of 3 integers,\n        specifying the strides of the convolution along the depth, height\n          and width.\n        Can be a single integer to specify the same value for\n        all spatial dimensions.\n        Specifying any stride value != 1 is incompatible with specifying\n        any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    output_padding: An integer or tuple/list of 3 integers,\n      specifying the amount of padding along the depth, height, and\n      width.\n      Can be a single integer to specify the same value for all\n      spatial dimensions.\n      The amount of output padding along a given dimension must be\n      lower than the stride along that same dimension.\n      If set to `None` (default), the output shape is inferred.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, depth, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, depth, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 3 integers, specifying\n      the dilation rate to use for dilated convolution.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any stride value != 1.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix.\n    bias_initializer: Initializer for the bias vector.\n    kernel_regularizer: Regularizer function applied to\n      the `kernel` weights matrix (\n      see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its \"activation\") (\n      see `keras.regularizers`).\n    kernel_constraint: Constraint function applied to the kernel matrix (\n      see `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (\n      see `keras.constraints`).\n\n  Input shape:\n    5D tensor with shape:\n    `(batch_size, channels, depth, rows, cols)` if data_format='channels_first'\n    or 5D tensor with shape:\n    `(batch_size, depth, rows, cols, channels)` if data_format='channels_last'.\n\n  Output shape:\n    5D tensor with shape:\n    `(batch_size, filters, new_depth, new_rows, new_cols)` if\n      data_format='channels_first'\n    or 5D tensor with shape:\n    `(batch_size, new_depth, new_rows, new_cols, filters)` if\n      data_format='channels_last'.\n    `depth` and `rows` and `cols` values might have changed due to padding.\n    If `output_padding` is specified::\n    ```\n    new_depth = ((depth - 1) * strides[0] + kernel_size[0] - 2 * padding[0] +\n    output_padding[0])\n    new_rows = ((rows - 1) * strides[1] + kernel_size[1] - 2 * padding[1] +\n    output_padding[1])\n    new_cols = ((cols - 1) * strides[2] + kernel_size[2] - 2 * padding[2] +\n    output_padding[2])\n    ```\n\n  Returns:\n    A tensor of rank 5 representing\n    `activation(conv3dtranspose(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is \"causal\".\n    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n\n  References:\n    - [A guide to convolution arithmetic for deep\n      learning](https://arxiv.org/abs/1603.07285v1)\n    - [Deconvolutional\n      Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "output_padding",
        "default": "None"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1,
          1
        ]
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": [
      "Convolution3DTranspose"
    ]
  },
  {
    "name": "ConvLSTM2D",
    "base": "ConvRNN2D",
    "docstring": "Convolutional LSTM.\n\n  It is similar to an LSTM layer, but the input transformations\n  and recurrent transformations are both convolutional.\n\n  Arguments:\n    filters: Integer, the dimensionality of the output space\n      (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of n integers, specifying the\n      dimensions of the convolution window.\n    strides: An integer or tuple/list of n integers,\n      specifying the strides of the convolution.\n      Specifying any stride value != 1 is incompatible with specifying\n      any `dilation_rate` value != 1.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, time, ..., channels)`\n      while `channels_first` corresponds to\n      inputs with shape `(batch, time, channels, ...)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n    dilation_rate: An integer or tuple/list of n integers, specifying\n      the dilation rate to use for dilated convolution.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any `strides` value != 1.\n    activation: Activation function to use.\n      By default hyperbolic tangent activation function is applied\n      (`tanh(x)`).\n    recurrent_activation: Activation function to use\n      for the recurrent step.\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n      used for the linear transformation of the inputs.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n      weights matrix,\n      used for the linear transformation of the recurrent state.\n    bias_initializer: Initializer for the bias vector.\n    unit_forget_bias: Boolean.\n      If True, add 1 to the bias of the forget gate at initialization.\n      Use in combination with `bias_initializer=\"zeros\"`.\n      This is recommended in [Jozefowicz et al., 2015](\n        http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n    kernel_regularizer: Regularizer function applied to\n      the `kernel` weights matrix.\n    recurrent_regularizer: Regularizer function applied to\n      the `recurrent_kernel` weights matrix.\n    bias_regularizer: Regularizer function applied to the bias vector.\n    activity_regularizer: Regularizer function applied to.\n    kernel_constraint: Constraint function applied to\n      the `kernel` weights matrix.\n    recurrent_constraint: Constraint function applied to\n      the `recurrent_kernel` weights matrix.\n    bias_constraint: Constraint function applied to the bias vector.\n    return_sequences: Boolean. Whether to return the last output\n      in the output sequence, or the full sequence. (default False)\n    return_state: Boolean Whether to return the last state\n      in addition to the output. (default False)\n    go_backwards: Boolean (default False).\n      If True, process the input sequence backwards.\n    stateful: Boolean (default False). If True, the last state\n      for each sample at index i in a batch will be used as initial\n      state for the sample of index i in the following batch.\n    dropout: Float between 0 and 1.\n      Fraction of the units to drop for\n      the linear transformation of the inputs.\n    recurrent_dropout: Float between 0 and 1.\n      Fraction of the units to drop for\n      the linear transformation of the recurrent state.\n\n  Call arguments:\n    inputs: A 5D tensor.\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether\n      a given timestep should be masked.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the cell\n      when calling it. This is only relevant if `dropout` or `recurrent_dropout`\n      are set.\n    initial_state: List of initial state tensors to be passed to the first\n      call of the cell.\n\n  Input shape:\n    - If data_format='channels_first'\n        5D tensor with shape:\n        `(samples, time, channels, rows, cols)`\n    - If data_format='channels_last'\n        5D tensor with shape:\n        `(samples, time, rows, cols, channels)`\n\n  Output shape:\n    - If `return_state`: a list of tensors. The first tensor is\n      the output. The remaining tensors are the last states,\n      each 4D tensor with shape:\n      `(samples, filters, new_rows, new_cols)`\n      if data_format='channels_first'\n      or 4D tensor with shape:\n      `(samples, new_rows, new_cols, filters)`\n      if data_format='channels_last'.\n      `rows` and `cols` values might have changed due to padding.\n    - If `return_sequences`: 5D tensor with shape:\n      `(samples, timesteps, filters, new_rows, new_cols)`\n      if data_format='channels_first'\n      or 5D tensor with shape:\n      `(samples, timesteps, new_rows, new_cols, filters)`\n      if data_format='channels_last'.\n    - Else, 4D tensor with shape:\n      `(samples, filters, new_rows, new_cols)`\n      if data_format='channels_first'\n      or 4D tensor with shape:\n      `(samples, new_rows, new_cols, filters)`\n      if data_format='channels_last'.\n\n  Raises:\n    ValueError: in case of invalid constructor arguments.\n\n  References:\n    - [Shi et al., 2015](http://arxiv.org/abs/1506.04214v1)\n    (the current implementation does not include the feedback loop on the\n    cells output).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "recurrent_activation",
        "default": "hard_sigmoid"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "unit_forget_bias",
        "default": true
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "return_sequences",
        "default": false
      },
      {
        "name": "return_state",
        "default": false
      },
      {
        "name": "go_backwards",
        "default": false
      },
      {
        "name": "stateful",
        "default": false
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "initial_state",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional_recurrent.py",
    "aliases": []
  },
  {
    "name": "Cropping1D",
    "base": "Layer",
    "docstring": "Cropping layer for 1D input (e.g. temporal sequence).\n\n  It crops along the time dimension (axis 1).\n\n  Examples:\n\n  >>> input_shape = (2, 3, 2)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> print(x)\n  [[[ 0  1]\n    [ 2  3]\n    [ 4  5]]\n   [[ 6  7]\n    [ 8  9]\n    [10 11]]]\n  >>> y = tf.keras.layers.Cropping1D(cropping=1)(x)\n  >>> print(y)\n  tf.Tensor(\n    [[[2 3]]\n     [[8 9]]], shape=(2, 1, 2), dtype=int64)\n\n  Arguments:\n    cropping: Int or tuple of int (length 2)\n      How many units should be trimmed off at the beginning and end of\n      the cropping dimension (axis 1).\n      If a single int is provided, the same value will be used for both.\n\n  Input shape:\n    3D tensor with shape `(batch_size, axis_to_crop, features)`\n\n  Output shape:\n    3D tensor with shape `(batch_size, cropped_axis, features)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "cropping",
        "default": [
          1,
          1
        ]
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "Cropping2D",
    "base": "Layer",
    "docstring": "Cropping layer for 2D input (e.g. picture).\n\n  It crops along spatial dimensions, i.e. height and width.\n\n  Examples:\n\n  >>> input_shape = (2, 28, 28, 3)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> y = tf.keras.layers.Cropping2D(cropping=((2, 2), (4, 4)))(x)\n  >>> print(y.shape)\n  (2, 24, 20, 3)\n\n  Arguments:\n    cropping: Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n      - If int: the same symmetric cropping\n        is applied to height and width.\n      - If tuple of 2 ints:\n        interpreted as two different\n        symmetric cropping values for height and width:\n        `(symmetric_height_crop, symmetric_width_crop)`.\n      - If tuple of 2 tuples of 2 ints:\n        interpreted as\n        `((top_crop, bottom_crop), (left_crop, right_crop))`\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, rows, cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, channels, rows, cols)`\n\n  Output shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, cropped_rows, cropped_cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, channels, cropped_rows, cropped_cols)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "cropping",
        "default": [
          [
            0,
            0
          ],
          [
            0,
            0
          ]
        ]
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "Cropping3D",
    "base": "Layer",
    "docstring": "Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n\n    Examples:\n\n  >>> input_shape = (2, 28, 28, 10, 3)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> y = tf.keras.layers.Cropping3D(cropping=(2, 4, 2))(x)\n  >>> print(y.shape)\n  (2, 24, 20, 6, 3)\n\n  Arguments:\n    cropping: Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n      - If int: the same symmetric cropping\n        is applied to depth, height, and width.\n      - If tuple of 3 ints: interpreted as two different\n        symmetric cropping values for depth, height, and width:\n        `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n      - If tuple of 3 tuples of 2 ints: interpreted as\n        `((left_dim1_crop, right_dim1_crop), (left_dim2_crop,\n          right_dim2_crop), (left_dim3_crop, right_dim3_crop))`\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop,\n        depth)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, depth, first_axis_to_crop, second_axis_to_crop,\n        third_axis_to_crop)`\n\n  Output shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n      `(batch_size, first_cropped_axis, second_cropped_axis, third_cropped_axis,\n        depth)`\n    - If `data_format` is `\"channels_first\"`:\n      `(batch_size, depth, first_cropped_axis, second_cropped_axis,\n        third_cropped_axis)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "cropping",
        "default": [
          [
            1,
            1
          ],
          [
            1,
            1
          ],
          [
            1,
            1
          ]
        ]
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "Dense",
    "base": "Layer",
    "docstring": "Just your regular densely-connected NN layer.\n\n  `Dense` implements the operation:\n  `output = activation(dot(input, kernel) + bias)`\n  where `activation` is the element-wise activation function\n  passed as the `activation` argument, `kernel` is a weights matrix\n  created by the layer, and `bias` is a bias vector created by the layer\n  (only applicable if `use_bias` is `True`).\n\n  Note: If the input to the layer has a rank greater than 2, then `Dense`\n  computes the dot product between the `inputs` and the `kernel` along the\n  last axis of the `inputs` and axis 1 of the `kernel` (using `tf.tensordot`).\n  For example, if input has dimensions `(batch_size, d0, d1)`,\n  then we create a `kernel` with shape `(d1, units)`, and the `kernel` operates\n  along axis 2 of the `input`, on every sub-tensor of shape `(1, 1, d1)`\n  (there are `batch_size * d0` such sub-tensors).\n  The output in this case will have shape `(batch_size, d0, units)`.\n\n  Besides, layer attributes cannot be modified after the layer has been called\n  once (except the `trainable` attribute).\n\n  Example:\n\n  >>> # Create a `Sequential` model and add a Dense layer as the first layer.\n  >>> model = tf.keras.models.Sequential()\n  >>> model.add(tf.keras.Input(shape=(16,)))\n  >>> model.add(tf.keras.layers.Dense(32, activation='relu'))\n  >>> # Now the model will take as input arrays of shape (None, 16)\n  >>> # and output arrays of shape (None, 32).\n  >>> # Note that after the first layer, you don't need to specify\n  >>> # the size of the input anymore:\n  >>> model.add(tf.keras.layers.Dense(32))\n  >>> model.output_shape\n  (None, 32)\n\n  Arguments:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix.\n    bias_initializer: Initializer for the bias vector.\n    kernel_regularizer: Regularizer function applied to\n      the `kernel` weights matrix.\n    bias_regularizer: Regularizer function applied to the bias vector.\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its \"activation\").\n    kernel_constraint: Constraint function applied to\n      the `kernel` weights matrix.\n    bias_constraint: Constraint function applied to the bias vector.\n\n  Input shape:\n    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n    The most common situation would be\n    a 2D input with shape `(batch_size, input_dim)`.\n\n  Output shape:\n    N-D tensor with shape: `(batch_size, ..., units)`.\n    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n    the output would have shape `(batch_size, units)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "DenseFeatures",
    "base": "DenseFeatures",
    "docstring": "A layer that produces a dense `Tensor` based on given `feature_columns`.\n\n  Generally a single example in training data is described with FeatureColumns.\n  At the first layer of the model, this column oriented data should be converted\n  to a single `Tensor`.\n\n  This layer can be called multiple times with different features.\n\n  This is the V2 version of this layer that uses name_scopes to create\n  variables instead of variable_scopes. But this approach currently lacks\n  support for partitioned variables. In that case, use the V1 version instead.\n\n  Example:\n\n  ```python\n  price = tf.feature_column.numeric_column('price')\n  keywords_embedded = tf.feature_column.embedding_column(\n      tf.feature_column.categorical_column_with_hash_bucket(\"keywords\", 10K),\n      dimensions=16)\n  columns = [price, keywords_embedded, ...]\n  feature_layer = tf.keras.layers.DenseFeatures(columns)\n\n  features = tf.io.parse_example(\n      ..., features=tf.feature_column.make_parse_example_spec(columns))\n  dense_tensor = feature_layer(features)\n  for units in [128, 64, 32]:\n    dense_tensor = tf.keras.layers.Dense(units, activation='relu')(dense_tensor)\n  prediction = tf.keras.layers.Dense(1)(dense_tensor)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "feature_columns",
        "default": null
      },
      {
        "name": "trainable",
        "default": true
      },
      {
        "name": "name",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "features",
        "default": null
      },
      {
        "name": "cols_to_output_tensors",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/feature_column/dense_features_v2.py",
    "aliases": []
  },
  {
    "name": "DepthwiseConv2D",
    "base": "Conv2D",
    "docstring": "Depthwise separable 2D convolution.\n\n  Depthwise Separable convolutions consist of performing\n  just the first step in a depthwise spatial convolution\n  (which acts on each input channel separately).\n  The `depth_multiplier` argument controls how many\n  output channels are generated per input channel in the depthwise step.\n\n  Arguments:\n    kernel_size: An integer or tuple/list of 2 integers, specifying the\n      height and width of the 2D convolution window.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers,\n      specifying the strides of the convolution along the height and width.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n      Specifying any stride value != 1 is incompatible with specifying\n      any `dilation_rate` value != 1.\n    padding: one of `'valid'` or `'same'` (case-insensitive).\n    depth_multiplier: The number of depthwise convolution output channels\n      for each input channel.\n      The total number of depthwise convolution output\n      channels will be equal to `filters_in * depth_multiplier`.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be 'channels_last'.\n    dilation_rate: An integer or tuple/list of 2 integers, specifying\n      the dilation rate to use for dilated convolution.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any `strides` value != 1.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    depthwise_initializer: Initializer for the depthwise kernel matrix (\n      see `keras.initializers`).\n    bias_initializer: Initializer for the bias vector (\n      see `keras.initializers`).\n    depthwise_regularizer: Regularizer function applied to\n      the depthwise kernel matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its 'activation') (\n      see `keras.regularizers`).\n    depthwise_constraint: Constraint function applied to\n      the depthwise kernel matrix (\n      see `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (\n      see `keras.constraints`).\n\n  Input shape:\n    4D tensor with shape:\n    `[batch_size, channels, rows, cols]` if data_format='channels_first'\n    or 4D tensor with shape:\n    `[batch_size, rows, cols, channels]` if data_format='channels_last'.\n\n  Output shape:\n    4D tensor with shape:\n    `[batch_size, filters, new_rows, new_cols]` if data_format='channels_first'\n    or 4D tensor with shape:\n    `[batch_size, new_rows, new_cols, filters]` if data_format='channels_last'.\n    `rows` and `cols` values might have changed due to padding.\n\n  Returns:\n    A tensor of rank 4 representing\n    `activation(depthwiseconv2d(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is \"causal\".\n    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "depth_multiplier",
        "default": 1
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "depthwise_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "depthwise_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "depthwise_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "Dot",
    "base": "_Merge",
    "docstring": "Layer that computes a dot product between samples in two tensors.\n\n  E.g. if applied to a list of two tensors `a` and `b` of shape\n  `(batch_size, n)`, the output will be a tensor of shape `(batch_size, 1)`\n  where each entry `i` will be the dot product between\n  `a[i]` and `b[i]`.\n\n  >>> x = np.arange(10).reshape(1, 5, 2)\n  >>> print(x)\n  [[[0 1]\n    [2 3]\n    [4 5]\n    [6 7]\n    [8 9]]]\n  >>> y = np.arange(10, 20).reshape(1, 2, 5)\n  >>> print(y)\n  [[[10 11 12 13 14]\n    [15 16 17 18 19]]]\n  >>> tf.keras.layers.Dot(axes=(1, 2))([x, y])\n  <tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\n  array([[[260, 360],\n          [320, 445]]])>\n\n  >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n  >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n  >>> dotted = tf.keras.layers.Dot(axes=1)([x1, x2])\n  >>> dotted.shape\n  TensorShape([5, 1])\n\n\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "axes",
        "default": null
      },
      {
        "name": "normalize",
        "default": false
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "Dropout",
    "base": "Layer",
    "docstring": "Applies Dropout to the input.\n\n  The Dropout layer randomly sets input units to 0 with a frequency of `rate`\n  at each step during training time, which helps prevent overfitting.\n  Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over\n  all inputs is unchanged.\n\n  Note that the Dropout layer only applies when `training` is set to True\n  such that no values are dropped during inference. When using `model.fit`,\n  `training` will be appropriately set to True automatically, and in other\n  contexts, you can set the kwarg explicitly to True when calling the layer.\n\n  (This is in contrast to setting `trainable=False` for a Dropout layer.\n  `trainable` does not affect the layer's behavior, as Dropout does\n  not have any variables/weights that can be frozen during training.)\n\n  >>> tf.random.set_seed(0)\n  >>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n  >>> data = np.arange(10).reshape(5, 2).astype(np.float32)\n  >>> print(data)\n  [[0. 1.]\n   [2. 3.]\n   [4. 5.]\n   [6. 7.]\n   [8. 9.]]\n  >>> outputs = layer(data, training=True)\n  >>> print(outputs)\n  tf.Tensor(\n  [[ 0.    1.25]\n   [ 2.5   3.75]\n   [ 5.    6.25]\n   [ 7.5   8.75]\n   [10.    0.  ]], shape=(5, 2), dtype=float32)\n\n  Arguments:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n    noise_shape: 1D integer tensor representing the shape of the\n      binary dropout mask that will be multiplied with the input.\n      For instance, if your inputs have shape\n      `(batch_size, timesteps, features)` and\n      you want the dropout mask to be the same for all timesteps,\n      you can use `noise_shape=(batch_size, 1, features)`.\n    seed: A Python integer to use as random seed.\n\n  Call arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      },
      {
        "name": "noise_shape",
        "default": "None"
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "ELU",
    "base": "Layer",
    "docstring": "Exponential Linear Unit.\n\n  It follows:\n\n  ```\n    f(x) =  alpha * (exp(x) - 1.) for x < 0\n    f(x) = x for x >= 0\n  ```\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as the input.\n\n  Arguments:\n    alpha: Scale for the negative factor.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "alpha",
        "default": 1.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/advanced_activations.py",
    "aliases": []
  },
  {
    "name": "Embedding",
    "base": "Layer",
    "docstring": "Turns positive integers (indexes) into dense vectors of fixed size.\n\n  e.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`\n\n  This layer can only be used as the first layer in a model.\n\n  Example:\n\n  >>> model = tf.keras.Sequential()\n  >>> model.add(tf.keras.layers.Embedding(1000, 64, input_length=10))\n  >>> # The model will take as input an integer matrix of size (batch,\n  >>> # input_length), and the largest integer (i.e. word index) in the input\n  >>> # should be no larger than 999 (vocabulary size).\n  >>> # Now model.output_shape is (None, 10, 64), where `None` is the batch\n  >>> # dimension.\n  >>> input_array = np.random.randint(1000, size=(32, 10))\n  >>> model.compile('rmsprop', 'mse')\n  >>> output_array = model.predict(input_array)\n  >>> print(output_array.shape)\n  (32, 10, 64)\n\n  Arguments:\n    input_dim: Integer. Size of the vocabulary,\n      i.e. maximum integer index + 1.\n    output_dim: Integer. Dimension of the dense embedding.\n    embeddings_initializer: Initializer for the `embeddings`\n      matrix (see `keras.initializers`).\n    embeddings_regularizer: Regularizer function applied to\n      the `embeddings` matrix (see `keras.regularizers`).\n    embeddings_constraint: Constraint function applied to\n      the `embeddings` matrix (see `keras.constraints`).\n    mask_zero: Boolean, whether or not the input value 0 is a special \"padding\"\n      value that should be masked out.\n      This is useful when using recurrent layers\n      which may take variable length input.\n      If this is `True`, then all subsequent layers\n      in the model need to support masking or an exception will be raised.\n      If mask_zero is set to True, as a consequence, index 0 cannot be\n      used in the vocabulary (input_dim should equal size of\n      vocabulary + 1).\n    input_length: Length of input sequences, when it is constant.\n      This argument is required if you are going to connect\n      `Flatten` then `Dense` layers upstream\n      (without it, the shape of the dense outputs cannot be computed).\n\n  Input shape:\n    2D tensor with shape: `(batch_size, input_length)`.\n\n  Output shape:\n    3D tensor with shape: `(batch_size, input_length, output_dim)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "input_dim",
        "default": null
      },
      {
        "name": "output_dim",
        "default": null
      },
      {
        "name": "embeddings_initializer",
        "default": "uniform"
      },
      {
        "name": "embeddings_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "embeddings_constraint",
        "default": "None"
      },
      {
        "name": "mask_zero",
        "default": false
      },
      {
        "name": "input_length",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/embeddings.py",
    "aliases": []
  },
  {
    "name": "Flatten",
    "base": "Layer",
    "docstring": "Flattens the input. Does not affect the batch size.\n\n  Note: If inputs are shaped `(batch,)` without a feature axis, then\n  flattening adds an extra channel dimension and output shape is `(batch, 1)`.\n\n  Arguments:\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, ..., channels)` while `channels_first` corresponds to\n      inputs with shape `(batch, channels, ...)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Example:\n\n  >>> model = tf.keras.Sequential()\n  >>> model.add(tf.keras.layers.Conv2D(64, 3, 3, input_shape=(3, 32, 32)))\n  >>> model.output_shape\n  (None, 1, 10, 64)\n\n  >>> model.add(Flatten())\n  >>> model.output_shape\n  (None, 640)\n\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "GRU",
    "base": "DropoutRNNCellMixin",
    "docstring": "Gated Recurrent Unit - Cho et al. 2014.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  Based on available runtime hardware and constraints, this layer\n  will choose different implementations (cuDNN-based or pure-TensorFlow)\n  to maximize the performance. If a GPU is available and all\n  the arguments to the layer meet the requirement of the CuDNN kernel\n  (see below for details), the layer will use a fast cuDNN implementation.\n\n  The requirements to use the cuDNN implementation are:\n\n  1. `activation` == `tanh`\n  2. `recurrent_activation` == `sigmoid`\n  3. `recurrent_dropout` == 0\n  4. `unroll` is `False`\n  5. `use_bias` is `True`\n  6. `reset_after` is `True`\n  7. Inputs, if use masking, are strictly right-padded.\n  8. Eager execution is enabled in the outermost context.\n\n  There are two variants of the GRU implementation. The default one is based on\n  [v3](https://arxiv.org/abs/1406.1078v3) and has reset gate applied to hidden\n  state before matrix multiplication. The other one is based on\n  [original](https://arxiv.org/abs/1406.1078v1) and has the order reversed.\n\n  The second variant is compatible with CuDNNGRU (GPU-only) and allows\n  inference on CPU. Thus it has separate biases for `kernel` and\n  `recurrent_kernel`. To use this variant, set `'reset_after'=True` and\n  `recurrent_activation='sigmoid'`.\n\n  For example:\n\n  >>> inputs = tf.random.normal([32, 10, 8])\n  >>> gru = tf.keras.layers.GRU(4)\n  >>> output = gru(inputs)\n  >>> print(output.shape)\n  (32, 4)\n  >>> gru = tf.keras.layers.GRU(4, return_sequences=True, return_state=True)\n  >>> whole_sequence_output, final_state = gru(inputs)\n  >>> print(whole_sequence_output.shape)\n  (32, 10, 4)\n  >>> print(final_state.shape)\n  (32, 4)\n\n  Arguments:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n      Default: hyperbolic tangent (`tanh`).\n      If you pass `None`, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation function to use\n      for the recurrent step.\n      Default: sigmoid (`sigmoid`).\n      If you pass `None`, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n      used for the linear transformation of the inputs. Default:\n      `glorot_uniform`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n       weights matrix, used for the linear transformation of the recurrent\n       state. Default: `orthogonal`.\n    bias_initializer: Initializer for the bias vector. Default: `zeros`.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector. Default:\n      `None`.\n    activity_regularizer: Regularizer function applied to the output of the\n      layer (its \"activation\"). Default: `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector. Default:\n      `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the linear\n      transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state. Default: 0.\n    implementation: Implementation mode, either 1 or 2.\n      Mode 1 will structure its operations as a larger number of\n      smaller dot products and additions, whereas mode 2 will\n      batch them into fewer, larger operations. These modes will\n      have different performance profiles on different hardware and\n      for different applications. Default: 2.\n    return_sequences: Boolean. Whether to return the last output\n      in the output sequence, or the full sequence. Default: `False`.\n    return_state: Boolean. Whether to return the last state in addition to the\n      output. Default: `False`.\n    go_backwards: Boolean (default `False`).\n      If True, process the input sequence backwards and return the\n      reversed sequence.\n    stateful: Boolean (default False). If True, the last state\n      for each sample at index i in a batch will be used as initial\n      state for the sample of index i in the following batch.\n    unroll: Boolean (default False).\n      If True, the network will be unrolled,\n      else a symbolic loop will be used.\n      Unrolling can speed-up a RNN,\n      although it tends to be more memory-intensive.\n      Unrolling is only suitable for short sequences.\n    time_major: The shape format of the `inputs` and `outputs` tensors.\n      If True, the inputs and outputs will be in shape\n      `[timesteps, batch, feature]`, whereas in the False case, it will be\n      `[batch, timesteps, feature]`. Using `time_major = True` is a bit more\n      efficient because it avoids transposes at the beginning and end of the\n      RNN calculation. However, most TensorFlow data is batch-major, so by\n      default this function accepts input and emits output in batch-major\n      form.\n    reset_after: GRU convention (whether to apply reset gate after or\n      before matrix multiplication). False = \"before\",\n      True = \"after\" (default and CuDNN compatible).\n\n  Call arguments:\n    inputs: A 3D tensor, with shape `[batch, timesteps, feature]`.\n    mask: Binary tensor of shape `[samples, timesteps]` indicating whether\n      a given timestep should be masked  (optional, defaults to `None`).\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the cell\n      when calling it. This is only relevant if `dropout` or\n      `recurrent_dropout` is used  (optional, defaults to `None`).\n    initial_state: List of initial state tensors to be passed to the first\n      call of the cell  (optional, defaults to `None` which causes creation\n      of zero-filled initial state tensors).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "recurrent_activation",
        "default": "sigmoid"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      },
      {
        "name": "implementation",
        "default": 2
      },
      {
        "name": "return_sequences",
        "default": false
      },
      {
        "name": "return_state",
        "default": false
      },
      {
        "name": "go_backwards",
        "default": false
      },
      {
        "name": "stateful",
        "default": false
      },
      {
        "name": "unroll",
        "default": false
      },
      {
        "name": "time_major",
        "default": false
      },
      {
        "name": "reset_after",
        "default": true
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "initial_state",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/recurrent_v2.py",
    "aliases": []
  },
  {
    "name": "GRUCell",
    "base": "GRUCell",
    "docstring": "Cell class for the GRU layer.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  This class processes one step within the whole time sequence input, whereas\n  `tf.keras.layer.GRU` processes the whole sequence.\n\n  For example:\n\n  >>> inputs = tf.random.normal([32, 10, 8])\n  >>> rnn = tf.keras.layers.RNN(tf.keras.layers.GRUCell(4))\n  >>> output = rnn(inputs)\n  >>> print(output.shape)\n  (32, 4)\n  >>> rnn = tf.keras.layers.RNN(\n  ...    tf.keras.layers.GRUCell(4),\n  ...    return_sequences=True,\n  ...    return_state=True)\n  >>> whole_sequence_output, final_state = rnn(inputs)\n  >>> print(whole_sequence_output.shape)\n  (32, 10, 4)\n  >>> print(final_state.shape)\n  (32, 4)\n\n  Arguments:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use. Default: hyperbolic tangent\n      (`tanh`). If you pass None, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation function to use for the recurrent step.\n      Default: sigmoid (`sigmoid`). If you pass `None`, no activation is\n      applied (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n      used for the linear transformation of the inputs. Default:\n      `glorot_uniform`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n      weights matrix, used for the linear transformation of the recurrent state.\n      Default: `orthogonal`.\n    bias_initializer: Initializer for the bias vector. Default: `zeros`.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector. Default:\n      `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector. Default:\n      `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the\n      linear transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state. Default: 0.\n    implementation: Implementation mode, either 1 or 2.\n      Mode 1 will structure its operations as a larger number of\n      smaller dot products and additions, whereas mode 2 (default) will\n      batch them into fewer, larger operations. These modes will\n      have different performance profiles on different hardware and\n      for different applications. Default: 2.\n    reset_after: GRU convention (whether to apply reset gate after or\n      before matrix multiplication). False = \"before\",\n      True = \"after\" (default and CuDNN compatible).\n\n  Call arguments:\n    inputs: A 2D tensor, with shape of `[batch, feature]`.\n    states: A 2D tensor with shape of `[batch, units]`, which is the state from\n      the previous time step. For timestep 0, the initial state provided by user\n      will be feed to cell.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. Only relevant when `dropout` or\n      `recurrent_dropout` is used.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "recurrent_activation",
        "default": "sigmoid"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      },
      {
        "name": "implementation",
        "default": 2
      },
      {
        "name": "reset_after",
        "default": true
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "states",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/recurrent_v2.py",
    "aliases": []
  },
  {
    "name": "GaussianDropout",
    "base": "Layer",
    "docstring": "Apply multiplicative 1-centered Gaussian noise.\n\n  As it is a regularization layer, it is only active at training time.\n\n  Arguments:\n    rate: Float, drop probability (as with `Dropout`).\n      The multiplicative noise will have\n      standard deviation `sqrt(rate / (1 - rate))`.\n\n  Call arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as input.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/noise.py",
    "aliases": []
  },
  {
    "name": "GaussianNoise",
    "base": "Layer",
    "docstring": "Apply additive zero-centered Gaussian noise.\n\n  This is useful to mitigate overfitting\n  (you could see it as a form of random data augmentation).\n  Gaussian Noise (GS) is a natural choice as corruption process\n  for real valued inputs.\n\n  As it is a regularization layer, it is only active at training time.\n\n  Arguments:\n    stddev: Float, standard deviation of the noise distribution.\n\n  Call arguments:\n    inputs: Input tensor (of any rank).\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding noise) or in inference mode (doing nothing).\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as input.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "stddev",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/noise.py",
    "aliases": []
  },
  {
    "name": "GlobalAvgPool1D",
    "base": "GlobalPooling1D",
    "docstring": "Global average pooling operation for temporal data.\n\n  Examples:\n\n  >>> input_shape = (2, 3, 4)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.GlobalAveragePooling1D()(x)\n  >>> print(y.shape)\n  (2, 4)\n\n  Arguments:\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, steps, features)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, features, steps)`.\n\n  Call arguments:\n    inputs: A 3D tensor.\n    mask: Binary tensor of shape `(batch_size, steps)` indicating whether\n      a given step should be masked (excluded from the average).\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      3D tensor with shape:\n      `(batch_size, steps, features)`\n    - If `data_format='channels_first'`:\n      3D tensor with shape:\n      `(batch_size, features, steps)`\n\n  Output shape:\n    2D tensor with shape `(batch_size, features)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "channels_last"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/pooling.py",
    "aliases": [
      "GlobalAveragePooling1D"
    ]
  },
  {
    "name": "GlobalAvgPool2D",
    "base": "GlobalPooling2D",
    "docstring": "Global average pooling operation for spatial data.\n\n  Examples:\n\n  >>> input_shape = (2, 4, 5, 3)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.GlobalAveragePooling2D()(x)\n  >>> print(y.shape)\n  (2, 3)\n\n  Arguments:\n      data_format: A string,\n        one of `channels_last` (default) or `channels_first`.\n        The ordering of the dimensions in the inputs.\n        `channels_last` corresponds to inputs with shape\n        `(batch, height, width, channels)` while `channels_first`\n        corresponds to inputs with shape\n        `(batch, channels, height, width)`.\n        It defaults to the `image_data_format` value found in your\n        Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      4D tensor with shape `(batch_size, rows, cols, channels)`.\n    - If `data_format='channels_first'`:\n      4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n  Output shape:\n    2D tensor with shape `(batch_size, channels)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/pooling.py",
    "aliases": [
      "GlobalAveragePooling2D"
    ]
  },
  {
    "name": "GlobalAvgPool3D",
    "base": "GlobalPooling3D",
    "docstring": "Global Average pooling operation for 3D data.\n\n  Arguments:\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      5D tensor with shape:\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n      5D tensor with shape:\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\n  Output shape:\n    2D tensor with shape `(batch_size, channels)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/pooling.py",
    "aliases": [
      "GlobalAveragePooling3D"
    ]
  },
  {
    "name": "GlobalMaxPool1D",
    "base": "GlobalPooling1D",
    "docstring": "Global max pooling operation for 1D temporal data.\n\n  Downsamples the input representation by taking the maximum value over\n  the time dimension.\n\n  For example:\n\n  >>> x = tf.constant([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])\n  >>> x = tf.reshape(x, [3, 3, 1])\n  >>> x\n  <tf.Tensor: shape=(3, 3, 1), dtype=float32, numpy=\n  array([[[1.], [2.], [3.]],\n         [[4.], [5.], [6.]],\n         [[7.], [8.], [9.]]], dtype=float32)>\n  >>> max_pool_1d = tf.keras.layers.GlobalMaxPooling1D()\n  >>> max_pool_1d(x)\n  <tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n  array([[3.],\n         [6.],\n         [9.], dtype=float32)>\n\n  Arguments:\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, steps, features)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, features, steps)`.\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      3D tensor with shape:\n      `(batch_size, steps, features)`\n    - If `data_format='channels_first'`:\n      3D tensor with shape:\n      `(batch_size, features, steps)`\n\n  Output shape:\n    2D tensor with shape `(batch_size, features)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "channels_last"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/pooling.py",
    "aliases": [
      "GlobalMaxPooling1D"
    ]
  },
  {
    "name": "GlobalMaxPool2D",
    "base": "GlobalPooling2D",
    "docstring": "Global max pooling operation for spatial data.\n\n  Examples:\n\n  >>> input_shape = (2, 4, 5, 3)\n  >>> x = tf.random.normal(input_shape)\n  >>> y = tf.keras.layers.GlobalMaxPool2D()(x)\n  >>> print(y.shape)\n  (2, 3)\n\n  Arguments:\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      4D tensor with shape `(batch_size, rows, cols, channels)`.\n    - If `data_format='channels_first'`:\n      4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n  Output shape:\n    2D tensor with shape `(batch_size, channels)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/pooling.py",
    "aliases": [
      "GlobalMaxPooling2D"
    ]
  },
  {
    "name": "GlobalMaxPool3D",
    "base": "GlobalPooling3D",
    "docstring": "Global Max pooling operation for 3D data.\n\n  Arguments:\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      5D tensor with shape:\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n      5D tensor with shape:\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\n  Output shape:\n    2D tensor with shape `(batch_size, channels)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/pooling.py",
    "aliases": [
      "GlobalMaxPooling3D"
    ]
  },
  {
    "name": "InputLayer",
    "base": "Layer",
    "docstring": "Layer to be used as an entry point into a Network (a graph of layers).\n\n  It can either wrap an existing tensor (pass an `input_tensor` argument)\n  or create a placeholder tensor (pass arguments `input_shape`, and\n  optionally, `dtype`).\n\n  It is generally recommend to use the functional layer API via `Input`,\n  (which creates an `InputLayer`) without directly using `InputLayer`.\n\n  When using InputLayer with Keras Sequential model, it can be skipped by\n  moving the input_shape parameter to the first layer after the InputLayer.\n\n  This class can create placeholders for tf.Tensors, tf.SparseTensors, and\n  tf.RaggedTensors by choosing 'sparse=True' or 'ragged=True'. Note that\n  'sparse' and 'ragged' can't be configured to True at same time.\n  Usage:\n\n  ```python\n  # With explicit InputLayer.\n  model = tf.keras.Sequential([\n    tf.keras.layers.InputLayer(input_shape=(4,)),\n    tf.keras.layers.Dense(8)])\n  model.compile(tf.optimizers.RMSprop(0.001), loss='mse')\n  model.fit(np.zeros((10, 4)),\n            np.ones((10, 8)))\n\n  # Without InputLayer and let the first layer to have the input_shape.\n  # Keras will add a input for the model behind the scene.\n  model = tf.keras.Sequential([\n    tf.keras.layers.Dense(8, input_shape=(4,))])\n  model.compile(tf.optimizers.RMSprop(0.001), loss='mse')\n  model.fit(np.zeros((10, 4)),\n            np.ones((10, 8)))\n  ```\n\n  Arguments:\n      input_shape: Shape tuple (not including the batch axis), or `TensorShape`\n        instance (not including the batch axis).\n      batch_size: Optional input batch size (integer or None).\n      dtype: Optional datatype of the input. When not provided, the Keras\n          default float type will be used.\n      input_tensor: Optional tensor to use as layer input\n          instead of creating a placeholder.\n      sparse: Boolean, whether the placeholder created is meant to be sparse.\n          Default to False.\n      ragged: Boolean, whether the placeholder created is meant to be ragged.\n          In this case, values of 'None' in the 'shape' argument represent\n          ragged dimensions. For more information about RaggedTensors, see\n          [this guide](https://www.tensorflow.org/guide/ragged_tensors).\n          Default to False.\n      name: Optional name of the layer (string).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "input_shape",
        "default": "None"
      },
      {
        "name": "batch_size",
        "default": "None"
      },
      {
        "name": "dtype",
        "default": "None"
      },
      {
        "name": "input_tensor",
        "default": "None"
      },
      {
        "name": "sparse",
        "default": false
      },
      {
        "name": "name",
        "default": "None"
      },
      {
        "name": "ragged",
        "default": false
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/engine/input_layer.py",
    "aliases": []
  },
  {
    "name": "InputSpec",
    "base": "object",
    "docstring": "Specifies the rank, dtype and shape of every input to a layer.\n\n  Layers can expose (if appropriate) an `input_spec` attribute:\n  an instance of `InputSpec`, or a nested structure of `InputSpec` instances\n  (one per input tensor). These objects enable the layer to run input\n  compatibility checks for input structure, input rank, input shape, and\n  input dtype.\n\n  A None entry in a shape is compatible with any dimension,\n  a None shape is compatible with any shape.\n\n  Arguments:\n      dtype: Expected DataType of the input.\n      shape: Shape tuple, expected shape of the input\n          (may include None for unchecked axes).\n      ndim: Integer, expected rank of the input.\n      max_ndim: Integer, maximum rank of the input.\n      min_ndim: Integer, minimum rank of the input.\n      axes: Dictionary mapping integer axes to\n          a specific dimension value.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "dtype",
        "default": "None"
      },
      {
        "name": "shape",
        "default": "None"
      },
      {
        "name": "ndim",
        "default": "None"
      },
      {
        "name": "max_ndim",
        "default": "None"
      },
      {
        "name": "min_ndim",
        "default": "None"
      },
      {
        "name": "axes",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": null,
    "file": "tensorflow/python/keras/engine/input_spec.py",
    "aliases": [
      "InputSpec"
    ]
  },
  {
    "name": "LSTM",
    "base": "DropoutRNNCellMixin",
    "docstring": "Long Short-Term Memory layer - Hochreiter 1997.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  Based on available runtime hardware and constraints, this layer\n  will choose different implementations (cuDNN-based or pure-TensorFlow)\n  to maximize the performance. If a GPU is available and all\n  the arguments to the layer meet the requirement of the CuDNN kernel\n  (see below for details), the layer will use a fast cuDNN implementation.\n\n  The requirements to use the cuDNN implementation are:\n\n  1. `activation` == `tanh`\n  2. `recurrent_activation` == `sigmoid`\n  3. `recurrent_dropout` == 0\n  4. `unroll` is `False`\n  5. `use_bias` is `True`\n  6. Inputs, if use masking, are strictly right-padded.\n  7. Eager execution is enabled in the outermost context.\n\n  For example:\n\n  >>> inputs = tf.random.normal([32, 10, 8])\n  >>> lstm = tf.keras.layers.LSTM(4)\n  >>> output = lstm(inputs)\n  >>> print(output.shape)\n  (32, 4)\n  >>> lstm = tf.keras.layers.LSTM(4, return_sequences=True, return_state=True)\n  >>> whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n  >>> print(whole_seq_output.shape)\n  (32, 10, 4)\n  >>> print(final_memory_state.shape)\n  (32, 4)\n  >>> print(final_carry_state.shape)\n  (32, 4)\n\n  Arguments:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n      Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation\n      is applied (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation function to use for the recurrent step.\n      Default: sigmoid (`sigmoid`). If you pass `None`, no activation is\n      applied (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean (default `True`), whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix, used for\n      the linear transformation of the inputs. Default: `glorot_uniform`.\n    recurrent_initializer: Initializer for the `recurrent_kernel` weights\n      matrix, used for the linear transformation of the recurrent state.\n      Default: `orthogonal`.\n    bias_initializer: Initializer for the bias vector. Default: `zeros`.\n    unit_forget_bias: Boolean (default `True`). If True, add 1 to the bias of\n      the forget gate at initialization. Setting it to true will also force\n      `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et\n          al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector. Default:\n      `None`.\n    activity_regularizer: Regularizer function applied to the output of the\n      layer (its \"activation\"). Default: `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector. Default:\n      `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the linear\n      transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state. Default: 0.\n    implementation: Implementation mode, either 1 or 2. Mode 1 will structure\n      its operations as a larger number of smaller dot products and additions,\n      whereas mode 2 will batch them into fewer, larger operations. These modes\n      will have different performance profiles on different hardware and for\n      different applications. Default: 2.\n    return_sequences: Boolean. Whether to return the last output. in the output\n      sequence, or the full sequence. Default: `False`.\n    return_state: Boolean. Whether to return the last state in addition to the\n      output. Default: `False`.\n    go_backwards: Boolean (default `False`). If True, process the input sequence\n      backwards and return the reversed sequence.\n    stateful: Boolean (default `False`). If True, the last state for each sample\n      at index i in a batch will be used as initial state for the sample of\n      index i in the following batch.\n    time_major: The shape format of the `inputs` and `outputs` tensors.\n      If True, the inputs and outputs will be in shape\n      `[timesteps, batch, feature]`, whereas in the False case, it will be\n      `[batch, timesteps, feature]`. Using `time_major = True` is a bit more\n      efficient because it avoids transposes at the beginning and end of the\n      RNN calculation. However, most TensorFlow data is batch-major, so by\n      default this function accepts input and emits output in batch-major\n      form.\n    unroll: Boolean (default `False`). If True, the network will be unrolled,\n      else a symbolic loop will be used. Unrolling can speed-up a RNN, although\n      it tends to be more memory-intensive. Unrolling is only suitable for short\n      sequences.\n\n  Call arguments:\n    inputs: A 3D tensor with shape `[batch, timesteps, feature]`.\n    mask: Binary tensor of shape `[batch, timesteps]` indicating whether\n      a given timestep should be masked (optional, defaults to `None`).\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the cell\n      when calling it. This is only relevant if `dropout` or\n      `recurrent_dropout` is used (optional, defaults to `None`).\n    initial_state: List of initial state tensors to be passed to the first\n      call of the cell (optional, defaults to `None` which causes creation\n      of zero-filled initial state tensors).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "recurrent_activation",
        "default": "sigmoid"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "unit_forget_bias",
        "default": true
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      },
      {
        "name": "implementation",
        "default": 2
      },
      {
        "name": "return_sequences",
        "default": false
      },
      {
        "name": "return_state",
        "default": false
      },
      {
        "name": "go_backwards",
        "default": false
      },
      {
        "name": "stateful",
        "default": false
      },
      {
        "name": "time_major",
        "default": false
      },
      {
        "name": "unroll",
        "default": false
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "initial_state",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/recurrent_v2.py",
    "aliases": []
  },
  {
    "name": "LSTMCell",
    "base": "LSTMCell",
    "docstring": "Cell class for the LSTM layer.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  This class processes one step within the whole time sequence input, whereas\n  `tf.keras.layer.LSTM` processes the whole sequence.\n\n  For example:\n\n  >>> inputs = tf.random.normal([32, 10, 8])\n  >>> rnn = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(4))\n  >>> output = rnn(inputs)\n  >>> print(output.shape)\n  (32, 4)\n  >>> rnn = tf.keras.layers.RNN(\n  ...    tf.keras.layers.LSTMCell(4),\n  ...    return_sequences=True,\n  ...    return_state=True)\n  >>> whole_seq_output, final_memory_state, final_carry_state = rnn(inputs)\n  >>> print(whole_seq_output.shape)\n  (32, 10, 4)\n  >>> print(final_memory_state.shape)\n  (32, 4)\n  >>> print(final_carry_state.shape)\n  (32, 4)\n\n  Arguments:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use. Default: hyperbolic tangent\n      (`tanh`). If you pass `None`, no activation is applied (ie. \"linear\"\n      activation: `a(x) = x`).\n    recurrent_activation: Activation function to use for the recurrent step.\n      Default: sigmoid (`sigmoid`). If you pass `None`, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix, used for\n      the linear transformation of the inputs. Default: `glorot_uniform`.\n    recurrent_initializer: Initializer for the `recurrent_kernel` weights\n      matrix, used for the linear transformation of the recurrent state.\n      Default: `orthogonal`.\n    bias_initializer: Initializer for the bias vector. Default: `zeros`.\n    unit_forget_bias: Boolean (default `True`). If True, add 1 to the bias of\n      the forget gate at initialization. Setting it to true will also force\n      `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et\n        al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to\n      the `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector. Default:\n      `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector. Default:\n      `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the linear\n      transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state. Default: 0.\n    implementation: Implementation mode, either 1 or 2.\n      Mode 1 will structure its operations as a larger number of smaller dot\n      products and additions, whereas mode 2 (default) will batch them into\n      fewer, larger operations. These modes will have different performance\n      profiles on different hardware and for different applications. Default: 2.\n\n  Call arguments:\n    inputs: A 2D tensor, with shape of `[batch, feature]`.\n    states: List of 2 tensors that corresponding to the cell's units. Both of\n      them have shape `[batch, units]`, the first tensor is the memory state\n      from previous time step, the second tensor is the carry state from\n      previous time step. For timestep 0, the initial state provided by user\n      will be feed to cell.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. Only relevant when `dropout` or\n      `recurrent_dropout` is used.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "recurrent_activation",
        "default": "sigmoid"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "unit_forget_bias",
        "default": true
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      },
      {
        "name": "implementation",
        "default": 2
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "states",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/recurrent_v2.py",
    "aliases": []
  },
  {
    "name": "Lambda",
    "base": "Layer",
    "docstring": "Wraps arbitrary expressions as a `Layer` object.\n\n  The `Lambda` layer exists so that arbitrary TensorFlow functions\n  can be used when constructing `Sequential` and Functional API\n  models. `Lambda` layers are best suited for simple operations or\n  quick experimentation. For more advanced use cases, follow\n  [this guide](https://www.tensorflow.org/guide/keras/custom_layers_and_models)\n  for subclassing `tf.keras.layers.Layer`.\n\n  The main reason to subclass `tf.keras.layers.Layer` instead of using a\n  `Lambda` layer is saving and inspecting a Model. `Lambda` layers\n  are saved by serializing the Python bytecode, whereas subclassed\n  Layers can be saved via overriding their `get_config` method. Overriding\n  `get_config` improves the portability of Models. Models that rely on\n  subclassed Layers are also often easier to visualize and reason about.\n\n  Examples:\n\n  ```python\n  # add a x -> x^2 layer\n  model.add(Lambda(lambda x: x ** 2))\n  ```\n  ```python\n  # add a layer that returns the concatenation\n  # of the positive part of the input and\n  # the opposite of the negative part\n\n  def antirectifier(x):\n      x -= K.mean(x, axis=1, keepdims=True)\n      x = K.l2_normalize(x, axis=1)\n      pos = K.relu(x)\n      neg = K.relu(-x)\n      return K.concatenate([pos, neg], axis=1)\n\n  model.add(Lambda(antirectifier))\n  ```\n\n  Variables:\n    While it is possible to use Variables with Lambda layers, this practice is\n    discouraged as it can easily lead to bugs. For instance, consider the\n    following layer:\n\n    ```python\n      scale = tf.Variable(1.)\n      scale_layer = tf.keras.layers.Lambda(lambda x: x * scale)\n    ```\n\n    Because scale_layer does not directly track the `scale` variable, it will\n    not appear in `scale_layer.trainable_weights` and will therefore not be\n    trained if `scale_layer` is used in a Model.\n\n    A better pattern is to write a subclassed Layer:\n\n    ```python\n      class ScaleLayer(tf.keras.layers.Layer):\n        def __init__(self):\n          super(ScaleLayer, self).__init__()\n          self.scale = tf.Variable(1.)\n\n        def call(self, inputs):\n          return inputs * self.scale\n    ```\n\n    In general, Lambda layers can be convenient for simple stateless\n    computation, but anything more complex should use a subclass Layer instead.\n\n  Arguments:\n    function: The function to be evaluated. Takes input tensor as first\n      argument.\n    output_shape: Expected output shape from function. This argument can be\n      inferred if not explicitly provided. Can be a tuple or function. If a\n      tuple, it only specifies the first dimension onward;\n      sample dimension is assumed either the same as the input: `output_shape =\n        (input_shape[0], ) + output_shape` or, the input is `None` and\n      the sample dimension is also `None`: `output_shape = (None, ) +\n        output_shape` If a function, it specifies the entire shape as a function\n        of the\n      input shape: `output_shape = f(input_shape)`\n    mask: Either None (indicating no masking) or a callable with the same\n      signature as the `compute_mask` layer method, or a tensor that will be\n      returned as output mask regardless of what the input is.\n    arguments: Optional dictionary of keyword arguments to be passed to the\n      function.\n\n  Input shape:\n    Arbitrary. Use the keyword argument input_shape (tuple of\n    integers, does not include the samples axis) when using this layer as the\n    first layer in a model.\n\n  Output shape:\n    Specified by `output_shape` argument\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "function",
        "default": null
      },
      {
        "name": "output_shape",
        "default": "None"
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "arguments",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "LayerNormalization",
    "base": "Layer",
    "docstring": "Layer normalization layer (Ba et al., 2016).\n\n  Normalize the activations of the previous layer for each given example in a\n  batch independently, rather than across a batch like Batch Normalization.\n  i.e. applies a transformation that maintains the mean activation within each\n  example close to 0 and the activation standard deviation close to 1.\n\n  Given a tensor `inputs`, moments are calculated and normalization\n  is performed across the axes specified in `axis`.\n\n  Example:\n\n  >>> data = tf.constant(np.arange(10).reshape(5, 2) * 10, dtype=tf.float32)\n  >>> print(data)\n  tf.Tensor(\n  [[ 0. 10.]\n   [20. 30.]\n   [40. 50.]\n   [60. 70.]\n   [80. 90.]], shape=(5, 2), dtype=float32)\n\n  >>> layer = tf.keras.layers.LayerNormalization(axis=1)\n  >>> output = layer(data)\n  >>> print(output)\n  tf.Tensor(\n  [[-1. 1.]\n   [-1. 1.]\n   [-1. 1.]\n   [-1. 1.]\n   [-1. 1.]], shape=(5, 2), dtype=float32)\n\n  Notice that with Layer Normalization the normalization happens across the\n  axes *within* each example, rather than across different examples in the\n  batch.\n\n  If `scale` or `center` are enabled, the layer will scale the normalized\n  outputs by broadcasting them with a trainable variable `gamma`, and center\n  the outputs by broadcasting with a trainable variable `beta`. `gamma` will\n  default to a ones tensor and `beta` will default to a zeros tensor, so that\n  centering and scaling are no-ops before training has begun.\n\n  So, with scaling and centering enabled the normalization equations\n  are as follows:\n    Let the intermediate activations for a mini-batch to be the `inputs`.\n\n    For each sample `x_i` in `inputs` with `k` features, we compute the mean and\n    variance of the sample:\n\n    ```python\n    mean_i = sum(x_i[j] for j in range(k)) / k\n    var_i = sum((x_i[j] - mean_i) ** 2 for j in range(k)) / k\n    ```\n\n    and then compute a normalized `x_i_normalized`, including a small factor\n    `epsilon` for numerical stability.\n\n    ```python\n    x_i_normalized = (x_i - mean_i) / sqrt(var_i + epsilon)\n    ```\n\n    And finally `x_i_normalized ` is linearly transformed by `gamma` and `beta`,\n    which are learned parameters:\n\n    ```python\n    output_i = x_i_normalized * gamma + beta\n    ```\n\n  `gamma` and `beta` will span the axes of `inputs` specified in `axis`, and\n  this part of the inputs' shape must be fully defined.\n\n  For example:\n\n  >>> layer = tf.keras.layers.LayerNormalization(axis=[1, 2, 3])\n  >>> layer.build([5, 20, 30, 40])\n  >>> print(layer.beta.shape)\n  (20, 30, 40)\n  >>> print(layer.gamma.shape)\n  (20, 30, 40)\n\n  Note that other implementations of layer normalization may choose to define\n  `gamma` and `beta` over a separate set of axes from the axes being\n  normalized across. For example, Group Normalization\n  ([Wu et al. 2018](https://arxiv.org/abs/1803.08494)) with group size of 1\n  corresponds to a Layer Normalization that normalizes across height, width,\n  and channel and has `gamma` and `beta` span only the channel dimension.\n  So, this Layer Normalization implementation will not match a Group\n  Normalization layer with group size set to 1.\n\n\n  Arguments:\n    axis: Integer or List/Tuple. The axis or axes to normalize across. Typically\n      this is the features axis/axes. The left-out axes are typically the batch\n      axis/axes. This argument defaults to `-1`, the last dimension in the\n      input.\n    epsilon: Small float added to variance to avoid dividing by zero. Defaults\n      to 1e-3\n    center: If True, add offset of `beta` to normalized tensor. If False, `beta`\n      is ignored. Defaults to True.\n    scale: If True, multiply by `gamma`. If False, `gamma` is not used. Defaults\n      to True. When the next layer is linear (also e.g. `nn.relu`), this can be\n      disabled since the scaling will be done by the next layer.\n    beta_initializer: Initializer for the beta weight. Defaults to zeros.\n    gamma_initializer: Initializer for the gamma weight. Defaults to ones.\n    beta_regularizer: Optional regularizer for the beta weight. None by default.\n    gamma_regularizer: Optional regularizer for the gamma weight. None by\n      default.\n    beta_constraint: Optional constraint for the beta weight. None by default.\n    gamma_constraint: Optional constraint for the gamma weight. None by default.\n    trainable: Boolean, if `True` the variables will be marked as trainable.\n      Defaults to True.\n  Input shape: Arbitrary. Use the keyword argument `input_shape` (tuple of\n    integers, does not include the samples axis) when using this layer as the\n    first layer in a model.\n  Output shape: Same shape as input.\n  Reference:\n    - [Lei Ba et al., 2016](https://arxiv.org/abs/1607.06450).\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "axis",
        "default": -1
      },
      {
        "name": "epsilon",
        "default": 0.001
      },
      {
        "name": "center",
        "default": true
      },
      {
        "name": "scale",
        "default": true
      },
      {
        "name": "beta_initializer",
        "default": "zeros"
      },
      {
        "name": "gamma_initializer",
        "default": "ones"
      },
      {
        "name": "beta_regularizer",
        "default": "None"
      },
      {
        "name": "gamma_regularizer",
        "default": "None"
      },
      {
        "name": "beta_constraint",
        "default": "None"
      },
      {
        "name": "gamma_constraint",
        "default": "None"
      },
      {
        "name": "trainable",
        "default": true
      },
      {
        "name": "name",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/normalization.py",
    "aliases": []
  },
  {
    "name": "LeakyReLU",
    "base": "Layer",
    "docstring": "Leaky version of a Rectified Linear Unit.\n\n  It allows a small gradient when the unit is not active:\n\n  ```\n    f(x) = alpha * x if x < 0\n    f(x) = x if x >= 0\n  ```\n\n  Usage:\n\n  >>> layer = tf.keras.layers.LeakyReLU()\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [-0.9, -0.3, 0.0, 2.0]\n  >>> layer = tf.keras.layers.LeakyReLU(alpha=0.1)\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [-0.3, -0.1, 0.0, 2.0]\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the batch axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as the input.\n\n  Arguments:\n    alpha: Float >= 0. Negative slope coefficient. Default to 0.3.\n\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "alpha",
        "default": 0.3
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/advanced_activations.py",
    "aliases": []
  },
  {
    "name": "LocallyConnected1D",
    "base": "Layer",
    "docstring": "Locally-connected layer for 1D inputs.\n\n  The `LocallyConnected1D` layer works similarly to\n  the `Conv1D` layer, except that weights are unshared,\n  that is, a different set of filters is applied at each different patch\n  of the input.\n\n  Note: layer attributes cannot be modified after the layer has been called\n  once (except the `trainable` attribute).\n\n  Example:\n  ```python\n      # apply a unshared weight convolution 1d of length 3 to a sequence with\n      # 10 timesteps, with 64 output filters\n      model = Sequential()\n      model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n      # now model.output_shape == (None, 8, 64)\n      # add a new conv1d on top\n      model.add(LocallyConnected1D(32, 3))\n      # now model.output_shape == (None, 6, 32)\n  ```\n\n  Arguments:\n      filters: Integer, the dimensionality of the output space\n          (i.e. the number of output filters in the convolution).\n      kernel_size: An integer or tuple/list of a single integer,\n          specifying the length of the 1D convolution window.\n      strides: An integer or tuple/list of a single integer,\n          specifying the stride length of the convolution.\n          Specifying any stride value != 1 is incompatible with specifying\n          any `dilation_rate` value != 1.\n      padding: Currently only supports `\"valid\"` (case-insensitive).\n          `\"same\"` may be supported in the future.\n      data_format: A string,\n          one of `channels_last` (default) or `channels_first`.\n          The ordering of the dimensions in the inputs.\n          `channels_last` corresponds to inputs with shape\n          `(batch, length, channels)` while `channels_first`\n          corresponds to inputs with shape\n          `(batch, channels, length)`.\n          It defaults to the `image_data_format` value found in your\n          Keras config file at `~/.keras/keras.json`.\n          If you never set it, then it will be \"channels_last\".\n      activation: Activation function to use.\n          If you don't specify anything, no activation is applied\n          (ie. \"linear\" activation: `a(x) = x`).\n      use_bias: Boolean, whether the layer uses a bias vector.\n      kernel_initializer: Initializer for the `kernel` weights matrix.\n      bias_initializer: Initializer for the bias vector.\n      kernel_regularizer: Regularizer function applied to\n          the `kernel` weights matrix.\n      bias_regularizer: Regularizer function applied to the bias vector.\n      activity_regularizer: Regularizer function applied to\n          the output of the layer (its \"activation\")..\n      kernel_constraint: Constraint function applied to the kernel matrix.\n      bias_constraint: Constraint function applied to the bias vector.\n      implementation: implementation mode, either `1`, `2`, or `3`.\n          `1` loops over input spatial locations to perform the forward pass.\n          It is memory-efficient but performs a lot of (small) ops.\n\n          `2` stores layer weights in a dense but sparsely-populated 2D matrix\n          and implements the forward pass as a single matrix-multiply. It uses\n          a lot of RAM but performs few (large) ops.\n\n          `3` stores layer weights in a sparse tensor and implements the forward\n          pass as a single sparse matrix-multiply.\n\n          How to choose:\n\n          `1`: large, dense models,\n          `2`: small models,\n          `3`: large, sparse models,\n\n          where \"large\" stands for large input/output activations\n          (i.e. many `filters`, `input_filters`, large `input_size`,\n          `output_size`), and \"sparse\" stands for few connections between inputs\n          and outputs, i.e. small ratio\n          `filters * input_filters * kernel_size / (input_size * strides)`,\n          where inputs to and outputs of the layer are assumed to have shapes\n          `(input_size, input_filters)`, `(output_size, filters)`\n          respectively.\n\n          It is recommended to benchmark each in the setting of interest to pick\n          the most efficient one (in terms of speed and memory usage). Correct\n          choice of implementation can lead to dramatic speed improvements (e.g.\n          50X), potentially at the expense of RAM.\n\n          Also, only `padding=\"valid\"` is supported by `implementation=1`.\n\n  Input shape:\n      3D tensor with shape: `(batch_size, steps, input_dim)`\n\n  Output shape:\n      3D tensor with shape: `(batch_size, new_steps, filters)`\n      `steps` value might have changed due to padding or strides.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": 1
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "implementation",
        "default": 1
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/local.py",
    "aliases": []
  },
  {
    "name": "LocallyConnected2D",
    "base": "Layer",
    "docstring": "Locally-connected layer for 2D inputs.\n\n  The `LocallyConnected2D` layer works similarly\n  to the `Conv2D` layer, except that weights are unshared,\n  that is, a different set of filters is applied at each\n  different patch of the input.\n\n  Note: layer attributes cannot be modified after the layer has been called\n  once (except the `trainable` attribute).\n\n  Examples:\n  ```python\n      # apply a 3x3 unshared weights convolution with 64 output filters on a\n      32x32 image\n      # with `data_format=\"channels_last\"`:\n      model = Sequential()\n      model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3)))\n      # now model.output_shape == (None, 30, 30, 64)\n      # notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64\n      parameters\n\n      # add a 3x3 unshared weights convolution on top, with 32 output filters:\n      model.add(LocallyConnected2D(32, (3, 3)))\n      # now model.output_shape == (None, 28, 28, 32)\n  ```\n\n  Arguments:\n      filters: Integer, the dimensionality of the output space\n          (i.e. the number of output filters in the convolution).\n      kernel_size: An integer or tuple/list of 2 integers, specifying the\n          width and height of the 2D convolution window.\n          Can be a single integer to specify the same value for\n          all spatial dimensions.\n      strides: An integer or tuple/list of 2 integers,\n          specifying the strides of the convolution along the width and height.\n          Can be a single integer to specify the same value for\n          all spatial dimensions.\n      padding: Currently only support `\"valid\"` (case-insensitive).\n          `\"same\"` will be supported in future.\n      data_format: A string,\n          one of `channels_last` (default) or `channels_first`.\n          The ordering of the dimensions in the inputs.\n          `channels_last` corresponds to inputs with shape\n          `(batch, height, width, channels)` while `channels_first`\n          corresponds to inputs with shape\n          `(batch, channels, height, width)`.\n          It defaults to the `image_data_format` value found in your\n          Keras config file at `~/.keras/keras.json`.\n          If you never set it, then it will be \"channels_last\".\n      activation: Activation function to use.\n          If you don't specify anything, no activation is applied\n          (ie. \"linear\" activation: `a(x) = x`).\n      use_bias: Boolean, whether the layer uses a bias vector.\n      kernel_initializer: Initializer for the `kernel` weights matrix.\n      bias_initializer: Initializer for the bias vector.\n      kernel_regularizer: Regularizer function applied to\n          the `kernel` weights matrix.\n      bias_regularizer: Regularizer function applied to the bias vector.\n      activity_regularizer: Regularizer function applied to\n          the output of the layer (its \"activation\").\n      kernel_constraint: Constraint function applied to the kernel matrix.\n      bias_constraint: Constraint function applied to the bias vector.\n      implementation: implementation mode, either `1`, `2`, or `3`.\n          `1` loops over input spatial locations to perform the forward pass.\n          It is memory-efficient but performs a lot of (small) ops.\n\n          `2` stores layer weights in a dense but sparsely-populated 2D matrix\n          and implements the forward pass as a single matrix-multiply. It uses\n          a lot of RAM but performs few (large) ops.\n\n          `3` stores layer weights in a sparse tensor and implements the forward\n          pass as a single sparse matrix-multiply.\n\n          How to choose:\n\n          `1`: large, dense models,\n          `2`: small models,\n          `3`: large, sparse models,\n\n          where \"large\" stands for large input/output activations\n          (i.e. many `filters`, `input_filters`, large `np.prod(input_size)`,\n          `np.prod(output_size)`), and \"sparse\" stands for few connections\n          between inputs and outputs, i.e. small ratio\n          `filters * input_filters * np.prod(kernel_size) / (np.prod(input_size)\n          * np.prod(strides))`, where inputs to and outputs of the layer are\n          assumed to have shapes `input_size + (input_filters,)`,\n          `output_size + (filters,)` respectively.\n\n          It is recommended to benchmark each in the setting of interest to pick\n          the most efficient one (in terms of speed and memory usage). Correct\n          choice of implementation can lead to dramatic speed improvements (e.g.\n          50X), potentially at the expense of RAM.\n\n          Also, only `padding=\"valid\"` is supported by `implementation=1`.\n\n  Input shape:\n      4D tensor with shape:\n      `(samples, channels, rows, cols)` if data_format='channels_first'\n      or 4D tensor with shape:\n      `(samples, rows, cols, channels)` if data_format='channels_last'.\n\n  Output shape:\n      4D tensor with shape:\n      `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n      or 4D tensor with shape:\n      `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n      `rows` and `cols` values might have changed due to padding.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "implementation",
        "default": 1
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/local.py",
    "aliases": []
  },
  {
    "name": "Masking",
    "base": "Layer",
    "docstring": "Masks a sequence by using a mask value to skip timesteps.\n\n  For each timestep in the input tensor (dimension #1 in the tensor),\n  if all values in the input tensor at that timestep\n  are equal to `mask_value`, then the timestep will be masked (skipped)\n  in all downstream layers (as long as they support masking).\n\n  If any downstream layer does not support masking yet receives such\n  an input mask, an exception will be raised.\n\n  Example:\n\n  Consider a Numpy data array `x` of shape `(samples, timesteps, features)`,\n  to be fed to an LSTM layer. You want to mask timestep #3 and #5 because you\n  lack data for these timesteps. You can:\n\n  - Set `x[:, 3, :] = 0.` and `x[:, 5, :] = 0.`\n  - Insert a `Masking` layer with `mask_value=0.` before the LSTM layer:\n\n  ```python\n  samples, timesteps, features = 32, 10, 8\n  inputs = np.random.random([samples, timesteps, features]).astype(np.float32)\n  inputs[:, 3, :] = 0.\n  inputs[:, 5, :] = 0.\n\n  model = tf.keras.models.Sequential()\n  model.add(tf.keras.layers.Masking(mask_value=0.,\n                                    input_shape=(timesteps, features)))\n  model.add(tf.keras.layers.LSTM(32))\n\n  output = model(inputs)\n  # The time step 3 and 5 will be skipped from LSTM calculation.\n  ```\n\n  See [the masking and padding guide](\n    https://www.tensorflow.org/guide/keras/masking_and_padding)\n  for more details.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "mask_value",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "MaxPool1D",
    "base": "Pooling1D",
    "docstring": "Max pooling operation for 1D temporal data.\n\n  Downsamples the input representation by taking the maximum value over the\n  window defined by `pool_size`. The window is shifted by `strides`.  The\n  resulting output when using \"valid\" padding option has a shape of:\n  `output_shape = (input_shape - pool_size + 1) / strides)`\n\n  The resulting output shape when using the \"same\" padding option is:\n  `output_shape = input_shape / strides`\n\n  For example, for strides=1 and padding=\"valid\":\n\n  >>> x = tf.constant([1., 2., 3., 4., 5.])\n  >>> x = tf.reshape(x, [1, 5, 1])\n  >>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,\n  ...    strides=1, padding='valid')\n  >>> max_pool_1d(x)\n  <tf.Tensor: shape=(1, 4, 1), dtype=float32, numpy=\n  array([[[2.],\n          [3.],\n          [4.],\n          [5.]]], dtype=float32)>\n\n  For example, for strides=2 and padding=\"valid\":\n\n  >>> x = tf.constant([1., 2., 3., 4., 5.])\n  >>> x = tf.reshape(x, [1, 5, 1])\n  >>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,\n  ...    strides=2, padding='valid')\n  >>> max_pool_1d(x)\n  <tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=\n  array([[[2.],\n          [4.]]], dtype=float32)>\n\n  For example, for strides=1 and padding=\"same\":\n\n  >>> x = tf.constant([1., 2., 3., 4., 5.])\n  >>> x = tf.reshape(x, [1, 5, 1])\n  >>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,\n  ...    strides=1, padding='same')\n  >>> max_pool_1d(x)\n  <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\n  array([[[2.],\n          [3.],\n          [4.],\n          [5.],\n          [5.]]], dtype=float32)>\n\n  Arguments:\n    pool_size: Integer, size of the max pooling window.\n    strides: Integer, or None. Specifies how much the pooling window moves\n      for each pooling step.\n      If None, it will default to `pool_size`.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n      \"valid\" adds no padding.  \"same\" adds padding such that if the stride\n      is 1, the output shape is the same as the input shape.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, steps, features)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, features, steps)`.\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      3D tensor with shape `(batch_size, steps, features)`.\n    - If `data_format='channels_first'`:\n      3D tensor with shape `(batch_size, features, steps)`.\n\n  Output shape:\n    - If `data_format='channels_last'`:\n      3D tensor with shape `(batch_size, downsampled_steps, features)`.\n    - If `data_format='channels_first'`:\n      3D tensor with shape `(batch_size, features, downsampled_steps)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "pool_size",
        "default": 2
      },
      {
        "name": "strides",
        "default": "None"
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "channels_last"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/pooling.py",
    "aliases": [
      "MaxPooling1D"
    ]
  },
  {
    "name": "MaxPool2D",
    "base": "Pooling2D",
    "docstring": "Max pooling operation for 2D spatial data.\n\n  Downsamples the input representation by taking the maximum value over the\n  window defined by `pool_size` for each dimension along the features axis.\n  The window is shifted by `strides` in each dimension.  The resulting output\n  when using \"valid\" padding option has a shape(number of rows or columns) of:\n  `output_shape = (input_shape - pool_size + 1) / strides)`\n\n  The resulting output shape when using the \"same\" padding option is:\n  `output_shape = input_shape / strides`\n\n  For example, for stride=(1,1) and padding=\"valid\":\n\n  >>> x = tf.constant([[1., 2., 3.],\n  ...                  [4., 5., 6.],\n  ...                  [7., 8., 9.]])\n  >>> x = tf.reshape(x, [1, 3, 3, 1])\n  >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n  ...    strides=(1, 1), padding='valid')\n  >>> max_pool_2d(x)\n  <tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n    array([[[[5.],\n             [6.]],\n            [[8.],\n             [9.]]]], dtype=float32)>\n\n  For example, for stride=(2,2) and padding=\"valid\":\n\n  >>> x = tf.constant([[1., 2., 3., 4.],\n  ...                  [5., 6., 7., 8.],\n  ...                  [9., 10., 11., 12.]])\n  >>> x = tf.reshape(x, [1, 3, 4, 1])\n  >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n  ...    strides=(1, 1), padding='valid')\n  >>> max_pool_2d(x)\n  <tf.Tensor: shape=(1, 2, 3, 1), dtype=float32, numpy=\n    array([[[[ 6.],\n             [ 7.],\n             [ 8.]],\n            [[10.],\n             [11.],\n             [12.]]]], dtype=float32)>\n             \n  Usage Example:\n  \n  >>> input_image = tf.constant([[[[1.], [1.], [2.], [4.]],\n  ...                            [[2.], [2.], [3.], [2.]],\n  ...                            [[4.], [1.], [1.], [1.]],\n  ...                            [[2.], [2.], [1.], [4.]]]]) \n  >>> output = tf.constant([[[[1], [0]],\n  ...                       [[0], [1]]]]) \n  >>> model = tf.keras.models.Sequential()\n  >>> model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), \n  ...    input_shape=(4,4,1)))\n  >>> model.compile('adam', 'mean_squared_error')\n  >>> model.predict(input_image, steps=1)\n  array([[[[2.],\n           [4.]],\n          [[4.],\n           [4.]]]], dtype=float32)\n\n  For example, for stride=(1,1) and padding=\"same\":\n\n  >>> x = tf.constant([[1., 2., 3.],\n  ...                  [4., 5., 6.],\n  ...                  [7., 8., 9.]])\n  >>> x = tf.reshape(x, [1, 3, 3, 1])\n  >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n  ...    strides=(1, 1), padding='same')\n  >>> max_pool_2d(x)\n  <tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n    array([[[[5.],\n             [6.],\n             [6.]],\n            [[8.],\n             [9.],\n             [9.]],\n            [[8.],\n             [9.],\n             [9.]]]], dtype=float32)>\n\n  Arguments:\n    pool_size: integer or tuple of 2 integers,\n      window size over which to take the maximum.\n      `(2, 2)` will take the max value over a 2x2 pooling window.\n      If only one integer is specified, the same window length\n      will be used for both dimensions.\n    strides: Integer, tuple of 2 integers, or None.\n      Strides values.  Specifies how far the pooling window moves\n      for each pooling step. If None, it will default to `pool_size`.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n      \"valid\" adds no zero padding.  \"same\" adds padding such that if the stride\n      is 1, the output shape is the same as input shape.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      4D tensor with shape `(batch_size, rows, cols, channels)`.\n    - If `data_format='channels_first'`:\n      4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n  Output shape:\n    - If `data_format='channels_last'`:\n      4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n    - If `data_format='channels_first'`:\n      4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.\n\n  Returns:\n    A tensor of rank 4 representing the maximum pooled values.  See above for\n    output shape.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "pool_size",
        "default": [
          2,
          2
        ]
      },
      {
        "name": "strides",
        "default": "None"
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/pooling.py",
    "aliases": [
      "MaxPooling2D"
    ]
  },
  {
    "name": "MaxPool3D",
    "base": "Pooling3D",
    "docstring": "Max pooling operation for 3D data (spatial or spatio-temporal).\n\n  Arguments:\n    pool_size: Tuple of 3 integers,\n      factors by which to downscale (dim1, dim2, dim3).\n      `(2, 2, 2)` will halve the size of the 3D input in each dimension.\n    strides: tuple of 3 integers, or None. Strides values.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    - If `data_format='channels_last'`:\n      5D tensor with shape:\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n      5D tensor with shape:\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\n  Output shape:\n    - If `data_format='channels_last'`:\n      5D tensor with shape:\n      `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n    - If `data_format='channels_first'`:\n      5D tensor with shape:\n      `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "pool_size",
        "default": [
          2,
          2,
          2
        ]
      },
      {
        "name": "strides",
        "default": "None"
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/pooling.py",
    "aliases": [
      "MaxPooling3D"
    ]
  },
  {
    "name": "Maximum",
    "base": "_Merge",
    "docstring": "Layer that computes the maximum (element-wise) a list of inputs.\n\n  It takes as input a list of tensors, all of the same shape, and returns\n  a single tensor (also of the same shape).\n\n  >>> tf.keras.layers.Maximum()([np.arange(5).reshape(5, 1),\n  ...                            np.arange(5, 10).reshape(5, 1)])\n  <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n  array([[5],\n       [6],\n       [7],\n       [8],\n       [9]])>\n\n  >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n  >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n  >>> maxed = tf.keras.layers.Maximum()([x1, x2])\n  >>> maxed.shape\n  TensorShape([5, 8])\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "Minimum",
    "base": "_Merge",
    "docstring": "Layer that computes the minimum (element-wise) a list of inputs.\n\n  It takes as input a list of tensors, all of the same shape, and returns\n  a single tensor (also of the same shape).\n\n  >>> tf.keras.layers.Minimum()([np.arange(5).reshape(5, 1),\n  ...                            np.arange(5, 10).reshape(5, 1)])\n  <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n  array([[0],\n       [1],\n       [2],\n       [3],\n       [4]])>\n\n  >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n  >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n  >>> minned = tf.keras.layers.Minimum()([x1, x2])\n  >>> minned.shape\n  TensorShape([5, 8])\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "Multiply",
    "base": "_Merge",
    "docstring": "Layer that multiplies (element-wise) a list of inputs.\n\n  It takes as input a list of tensors, all of the same shape, and returns\n  a single tensor (also of the same shape).\n\n  >>> tf.keras.layers.Multiply()([np.arange(5).reshape(5, 1),\n  ...                             np.arange(5, 10).reshape(5, 1)])\n  <tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n  array([[ 0],\n       [ 6],\n       [14],\n       [24],\n       [36]])>\n\n  >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n  >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n  >>> multiplied = tf.keras.layers.Multiply()([x1, x2])\n  >>> multiplied.shape\n  TensorShape([5, 8])\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "PReLU",
    "base": "Layer",
    "docstring": "Parametric Rectified Linear Unit.\n\n  It follows:\n\n  ```\n    f(x) = alpha * x for x < 0\n    f(x) = x for x >= 0\n  ```\n\n  where `alpha` is a learned array with the same shape as x.\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as the input.\n\n  Arguments:\n    alpha_initializer: Initializer function for the weights.\n    alpha_regularizer: Regularizer for the weights.\n    alpha_constraint: Constraint for the weights.\n    shared_axes: The axes along which to share learnable\n      parameters for the activation function.\n      For example, if the incoming feature maps\n      are from a 2D convolution\n      with output shape `(batch, height, width, channels)`,\n      and you wish to share parameters across space\n      so that each filter only has one set of parameters,\n      set `shared_axes=[1, 2]`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "alpha_initializer",
        "default": "zeros"
      },
      {
        "name": "alpha_regularizer",
        "default": "None"
      },
      {
        "name": "alpha_constraint",
        "default": "None"
      },
      {
        "name": "shared_axes",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/advanced_activations.py",
    "aliases": []
  },
  {
    "name": "Permute",
    "base": "Layer",
    "docstring": "Permutes the dimensions of the input according to a given pattern.\n\n  Useful e.g. connecting RNNs and convnets.\n\n  Example:\n\n  ```python\n  model = Sequential()\n  model.add(Permute((2, 1), input_shape=(10, 64)))\n  # now: model.output_shape == (None, 64, 10)\n  # note: `None` is the batch dimension\n  ```\n\n  Arguments:\n    dims: Tuple of integers. Permutation pattern does not include the\n      samples dimension. Indexing starts at 1.\n      For instance, `(2, 1)` permutes the first and second dimensions\n      of the input.\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same as the input shape, but with the dimensions re-ordered according\n    to the specified pattern.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "dims",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "RNN",
    "base": "Layer",
    "docstring": "Base class for recurrent layers.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  Arguments:\n    cell: A RNN cell instance or a list of RNN cell instances.\n      A RNN cell is a class that has:\n      - A `call(input_at_t, states_at_t)` method, returning\n        `(output_at_t, states_at_t_plus_1)`. The call method of the\n        cell can also take the optional argument `constants`, see\n        section \"Note on passing external constants\" below.\n      - A `state_size` attribute. This can be a single integer\n        (single state) in which case it is the size of the recurrent\n        state. This can also be a list/tuple of integers (one size per state).\n        The `state_size` can also be TensorShape or tuple/list of\n        TensorShape, to represent high dimension state.\n      - A `output_size` attribute. This can be a single integer or a\n        TensorShape, which represent the shape of the output. For backward\n        compatible reason, if this attribute is not available for the\n        cell, the value will be inferred by the first element of the\n        `state_size`.\n      - A `get_initial_state(inputs=None, batch_size=None, dtype=None)`\n        method that creates a tensor meant to be fed to `call()` as the\n        initial state, if the user didn't specify any initial state via other\n        means. The returned initial state should have a shape of\n        [batch_size, cell.state_size]. The cell might choose to create a\n        tensor full of zeros, or full of other values based on the cell's\n        implementation.\n        `inputs` is the input tensor to the RNN layer, which should\n        contain the batch size as its shape[0], and also dtype. Note that\n        the shape[0] might be `None` during the graph construction. Either\n        the `inputs` or the pair of `batch_size` and `dtype` are provided.\n        `batch_size` is a scalar tensor that represents the batch size\n        of the inputs. `dtype` is `tf.DType` that represents the dtype of\n        the inputs.\n        For backward compatible reason, if this method is not implemented\n        by the cell, the RNN layer will create a zero filled tensor with the\n        size of [batch_size, cell.state_size].\n      In the case that `cell` is a list of RNN cell instances, the cells\n      will be stacked on top of each other in the RNN, resulting in an\n      efficient stacked RNN.\n    return_sequences: Boolean (default `False`). Whether to return the last\n      output in the output sequence, or the full sequence.\n    return_state: Boolean (default `False`). Whether to return the last state\n      in addition to the output.\n    go_backwards: Boolean (default `False`).\n      If True, process the input sequence backwards and return the\n      reversed sequence.\n    stateful: Boolean (default `False`). If True, the last state\n      for each sample at index i in a batch will be used as initial\n      state for the sample of index i in the following batch.\n    unroll: Boolean (default `False`).\n      If True, the network will be unrolled, else a symbolic loop will be used.\n      Unrolling can speed-up a RNN, although it tends to be more\n      memory-intensive. Unrolling is only suitable for short sequences.\n    time_major: The shape format of the `inputs` and `outputs` tensors.\n      If True, the inputs and outputs will be in shape\n      `(timesteps, batch, ...)`, whereas in the False case, it will be\n      `(batch, timesteps, ...)`. Using `time_major = True` is a bit more\n      efficient because it avoids transposes at the beginning and end of the\n      RNN calculation. However, most TensorFlow data is batch-major, so by\n      default this function accepts input and emits output in batch-major\n      form.\n    zero_output_for_mask: Boolean (default `False`).\n      Whether the output should use zeros for the masked timesteps. Note that\n      this field is only used when `return_sequences` is True and mask is\n      provided. It can useful if you want to reuse the raw output sequence of\n      the RNN without interference from the masked timesteps, eg, merging\n      bidirectional RNNs.\n\n  Call arguments:\n    inputs: Input tensor.\n    mask: Binary tensor of shape `[batch_size, timesteps]` indicating whether\n      a given timestep should be masked.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the cell\n      when calling it. This is for use with cells that use dropout.\n    initial_state: List of initial state tensors to be passed to the first\n      call of the cell.\n    constants: List of constant tensors to be passed to the cell at each\n      timestep.\n\n  Input shape:\n    N-D tensor with shape `[batch_size, timesteps, ...]` or\n    `[timesteps, batch_size, ...]` when time_major is True.\n\n  Output shape:\n    - If `return_state`: a list of tensors. The first tensor is\n      the output. The remaining tensors are the last states,\n      each with shape `[batch_size, state_size]`, where `state_size` could\n      be a high dimension tensor shape.\n    - If `return_sequences`: N-D tensor with shape\n      `[batch_size, timesteps, output_size]`, where `output_size` could\n      be a high dimension tensor shape, or\n      `[timesteps, batch_size, output_size]` when `time_major` is True.\n    - Else, N-D tensor with shape `[batch_size, output_size]`, where\n      `output_size` could be a high dimension tensor shape.\n\n  Masking:\n    This layer supports masking for input data with a variable number\n    of timesteps. To introduce masks to your data,\n    use an [tf.keras.layers.Embedding] layer with the `mask_zero` parameter\n    set to `True`.\n\n  Note on using statefulness in RNNs:\n    You can set RNN layers to be 'stateful', which means that the states\n    computed for the samples in one batch will be reused as initial states\n    for the samples in the next batch. This assumes a one-to-one mapping\n    between samples in different successive batches.\n\n    To enable statefulness:\n      - Specify `stateful=True` in the layer constructor.\n      - Specify a fixed batch size for your model, by passing\n        If sequential model:\n          `batch_input_shape=(...)` to the first layer in your model.\n        Else for functional model with 1 or more Input layers:\n          `batch_shape=(...)` to all the first layers in your model.\n        This is the expected shape of your inputs\n        *including the batch size*.\n        It should be a tuple of integers, e.g. `(32, 10, 100)`.\n      - Specify `shuffle=False` when calling fit().\n\n    To reset the states of your model, call `.reset_states()` on either\n    a specific layer, or on your entire model.\n\n  Note on specifying the initial state of RNNs:\n    You can specify the initial state of RNN layers symbolically by\n    calling them with the keyword argument `initial_state`. The value of\n    `initial_state` should be a tensor or list of tensors representing\n    the initial state of the RNN layer.\n\n    You can specify the initial state of RNN layers numerically by\n    calling `reset_states` with the keyword argument `states`. The value of\n    `states` should be a numpy array or list of numpy arrays representing\n    the initial state of the RNN layer.\n\n  Note on passing external constants to RNNs:\n    You can pass \"external\" constants to the cell using the `constants`\n    keyword argument of `RNN.__call__` (as well as `RNN.call`) method. This\n    requires that the `cell.call` method accepts the same keyword argument\n    `constants`. Such constants can be used to condition the cell\n    transformation on additional static inputs (not changing over time),\n    a.k.a. an attention mechanism.\n\n  Examples:\n\n  ```python\n  # First, let's define a RNN Cell, as a layer subclass.\n\n  class MinimalRNNCell(keras.layers.Layer):\n\n      def __init__(self, units, **kwargs):\n          self.units = units\n          self.state_size = units\n          super(MinimalRNNCell, self).__init__(**kwargs)\n\n      def build(self, input_shape):\n          self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                        initializer='uniform',\n                                        name='kernel')\n          self.recurrent_kernel = self.add_weight(\n              shape=(self.units, self.units),\n              initializer='uniform',\n              name='recurrent_kernel')\n          self.built = True\n\n      def call(self, inputs, states):\n          prev_output = states[0]\n          h = K.dot(inputs, self.kernel)\n          output = h + K.dot(prev_output, self.recurrent_kernel)\n          return output, [output]\n\n  # Let's use this cell in a RNN layer:\n\n  cell = MinimalRNNCell(32)\n  x = keras.Input((None, 5))\n  layer = RNN(cell)\n  y = layer(x)\n\n  # Here's how to use the cell to build a stacked RNN:\n\n  cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n  x = keras.Input((None, 5))\n  layer = RNN(cells)\n  y = layer(x)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "cell",
        "default": null
      },
      {
        "name": "return_sequences",
        "default": false
      },
      {
        "name": "return_state",
        "default": false
      },
      {
        "name": "go_backwards",
        "default": false
      },
      {
        "name": "stateful",
        "default": false
      },
      {
        "name": "unroll",
        "default": false
      },
      {
        "name": "time_major",
        "default": false
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "initial_state",
        "default": "None"
      },
      {
        "name": "constants",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/recurrent.py",
    "aliases": [
      "RNN"
    ]
  },
  {
    "name": "ReLU",
    "base": "Layer",
    "docstring": "Rectified Linear Unit activation function.\n\n  With default values, it returns element-wise `max(x, 0)`.\n\n  Otherwise, it follows:\n\n  ```\n    f(x) = max_value if x >= max_value\n    f(x) = x if threshold <= x < max_value\n    f(x) = negative_slope * (x - threshold) otherwise\n  ```\n\n  Usage:\n\n  >>> layer = tf.keras.layers.ReLU()\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [0.0, 0.0, 0.0, 2.0]\n  >>> layer = tf.keras.layers.ReLU(max_value=1.0)\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [0.0, 0.0, 0.0, 1.0]\n  >>> layer = tf.keras.layers.ReLU(negative_slope=1.0)\n  >>> output = layer([-3.0, -1.0, 0.0, 2.0])\n  >>> list(output.numpy())\n  [-3.0, -1.0, 0.0, 2.0]\n  >>> layer = tf.keras.layers.ReLU(threshold=1.5)\n  >>> output = layer([-3.0, -1.0, 1.0, 2.0])\n  >>> list(output.numpy())\n  [0.0, 0.0, 0.0, 2.0]\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the batch axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as the input.\n\n  Arguments:\n    max_value: Float >= 0. Maximum activation value. Default to None, which\n      means unlimited.\n    negative_slope: Float >= 0. Negative slope coefficient. Default to 0.\n    threshold: Float. Threshold value for thresholded activation. Default to 0.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "max_value",
        "default": "None"
      },
      {
        "name": "negative_slope",
        "default": 0
      },
      {
        "name": "threshold",
        "default": 0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/advanced_activations.py",
    "aliases": []
  },
  {
    "name": "RepeatVector",
    "base": "Layer",
    "docstring": "Repeats the input n times.\n\n  Example:\n\n  ```python\n  model = Sequential()\n  model.add(Dense(32, input_dim=32))\n  # now: model.output_shape == (None, 32)\n  # note: `None` is the batch dimension\n\n  model.add(RepeatVector(3))\n  # now: model.output_shape == (None, 3, 32)\n  ```\n\n  Arguments:\n    n: Integer, repetition factor.\n\n  Input shape:\n    2D tensor of shape `(num_samples, features)`.\n\n  Output shape:\n    3D tensor of shape `(num_samples, n, features)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "n",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "Reshape",
    "base": "Layer",
    "docstring": "Layer that reshapes inputs into the given shape.\n\n  Input shape:\n    Arbitrary, although all dimensions in the input shape must be known/fixed.\n    Use the keyword argument `input_shape` (tuple of integers, does not include\n    the samples/batch size axis) when using this layer as the first layer\n    in a model.\n\n  Output shape:\n    `(batch_size,) + target_shape`\n\n  Example:\n\n  >>> # as first layer in a Sequential model\n  >>> model = tf.keras.Sequential()\n  >>> model.add(tf.keras.layers.Reshape((3, 4), input_shape=(12,)))\n  >>> # model.output_shape == (None, 3, 4), `None` is the batch size.\n  >>> model.output_shape\n  (None, 3, 4)\n\n  >>> # as intermediate layer in a Sequential model\n  >>> model.add(tf.keras.layers.Reshape((6, 2)))\n  >>> model.output_shape\n  (None, 6, 2)\n\n  >>> # also supports shape inference using `-1` as dimension\n  >>> model.add(tf.keras.layers.Reshape((-1, 2, 2)))\n  >>> model.output_shape\n  (None, 3, 2, 2)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "target_shape",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "SeparableConv1D",
    "base": "SeparableConv",
    "docstring": "Depthwise separable 1D convolution.\n\n  This layer performs a depthwise convolution that acts separately on\n  channels, followed by a pointwise convolution that mixes channels.\n  If `use_bias` is True and a bias initializer is provided,\n  it adds a bias vector to the output.\n  It then optionally applies an activation function to produce the final output.\n\n  Arguments:\n    filters: Integer, the dimensionality of the output space (i.e. the number\n      of filters in the convolution).\n    kernel_size: A single integer specifying the spatial\n      dimensions of the filters.\n    strides: A single integer specifying the strides\n      of the convolution.\n      Specifying any `stride` value != 1 is incompatible with specifying\n      any `dilation_rate` value != 1.\n    padding: One of `\"valid\"`, `\"same\"`, or `\"causal\"` (case-insensitive).\n    data_format: A string, one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, length, channels)` while `channels_first` corresponds to\n      inputs with shape `(batch_size, channels, length)`.\n    dilation_rate: A single integer, specifying\n      the dilation rate to use for dilated convolution.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any stride value != 1.\n    depth_multiplier: The number of depthwise convolution output channels for\n      each input channel. The total number of depthwise convolution output\n      channels will be equal to `num_filters_in * depth_multiplier`.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias.\n    depthwise_initializer: An initializer for the depthwise convolution kernel (\n      see `keras.initializers`).\n    pointwise_initializer: An initializer for the pointwise convolution kernel (\n      see `keras.initializers`).\n    bias_initializer: An initializer for the bias vector. If None, the default\n      initializer will be used (see `keras.initializers`).\n    depthwise_regularizer: Optional regularizer for the depthwise\n      convolution kernel (see `keras.regularizers`).\n    pointwise_regularizer: Optional regularizer for the pointwise\n      convolution kernel (see `keras.regularizers`).\n    bias_regularizer: Optional regularizer for the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Optional regularizer function for the output (\n      see `keras.regularizers`).\n    depthwise_constraint: Optional projection function to be applied to the\n      depthwise kernel after being updated by an `Optimizer` (e.g. used for\n      norm constraints or value constraints for layer weights). The function\n      must take as input the unprojected variable and must return the\n      projected variable (which must have the same shape). Constraints are\n      not safe to use when doing asynchronous distributed training (\n      see `keras.constraints`).\n    pointwise_constraint: Optional projection function to be applied to the\n      pointwise kernel after being updated by an `Optimizer` (\n      see `keras.constraints`).\n    bias_constraint: Optional projection function to be applied to the\n      bias after being updated by an `Optimizer` (\n      see `keras.constraints`).\n    trainable: Boolean, if `True` the weights of this layer will be marked as\n      trainable (and listed in `layer.trainable_weights`).\n    name: A string, the name of the layer.\n\n  Input shape:\n    3D tensor with shape:\n    `(batch_size, channels, steps)` if data_format='channels_first'\n    or 5D tensor with shape:\n    `(batch_size, steps, channels)` if data_format='channels_last'.\n\n  Output shape:\n    3D tensor with shape:\n    `(batch_size, filters, new_steps)` if data_format='channels_first'\n    or 3D tensor with shape:\n    `(batch_size,  new_steps, filters)` if data_format='channels_last'.\n    `new_steps` value might have changed due to padding or strides.\n\n  Returns:\n    A tensor of rank 3 representing\n    `activation(separableconv1d(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": 1
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": 1
      },
      {
        "name": "depth_multiplier",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "depthwise_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "pointwise_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "depthwise_regularizer",
        "default": "None"
      },
      {
        "name": "pointwise_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "depthwise_constraint",
        "default": "None"
      },
      {
        "name": "pointwise_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": [
      "SeparableConvolution1D"
    ]
  },
  {
    "name": "SeparableConv2D",
    "base": "SeparableConv",
    "docstring": "Depthwise separable 2D convolution.\n\n  Separable convolutions consist of first performing\n  a depthwise spatial convolution\n  (which acts on each input channel separately)\n  followed by a pointwise convolution which mixes the resulting\n  output channels. The `depth_multiplier` argument controls how many\n  output channels are generated per input channel in the depthwise step.\n\n  Intuitively, separable convolutions can be understood as\n  a way to factorize a convolution kernel into two smaller kernels,\n  or as an extreme version of an Inception block.\n\n  Arguments:\n    filters: Integer, the dimensionality of the output space\n      (i.e. the number of output filters in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers, specifying the\n      height and width of the 2D convolution window.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n    strides: An integer or tuple/list of 2 integers,\n      specifying the strides of the convolution along the height and width.\n      Can be a single integer to specify the same value for\n      all spatial dimensions.\n      Specifying any stride value != 1 is incompatible with specifying\n      any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n    dilation_rate: An integer or tuple/list of 2 integers, specifying\n      the dilation rate to use for dilated convolution.\n      Currently, specifying any `dilation_rate` value != 1 is\n      incompatible with specifying any `strides` value != 1.\n    depth_multiplier: The number of depthwise convolution output channels\n      for each input channel.\n      The total number of depthwise convolution output\n      channels will be equal to `filters_in * depth_multiplier`.\n    activation: Activation function to use.\n      If you don't specify anything, no activation is applied (\n      see `keras.activations`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n    depthwise_initializer: Initializer for the depthwise kernel matrix (\n      see `keras.initializers`).\n    pointwise_initializer: Initializer for the pointwise kernel matrix (\n      see `keras.initializers`).\n    bias_initializer: Initializer for the bias vector (\n      see `keras.initializers`).\n    depthwise_regularizer: Regularizer function applied to\n      the depthwise kernel matrix (see `keras.regularizers`).\n    pointwise_regularizer: Regularizer function applied to\n      the pointwise kernel matrix (see `keras.regularizers`).\n    bias_regularizer: Regularizer function applied to the bias vector (\n      see `keras.regularizers`).\n    activity_regularizer: Regularizer function applied to\n      the output of the layer (its \"activation\") (\n      see `keras.regularizers`).\n    depthwise_constraint: Constraint function applied to\n      the depthwise kernel matrix (\n      see `keras.constraints`).\n    pointwise_constraint: Constraint function applied to\n      the pointwise kernel matrix (\n      see `keras.constraints`).\n    bias_constraint: Constraint function applied to the bias vector (\n      see `keras.constraints`).\n\n  Input shape:\n    4D tensor with shape:\n    `(batch_size, channels, rows, cols)` if data_format='channels_first'\n    or 4D tensor with shape:\n    `(batch_size, rows, cols, channels)` if data_format='channels_last'.\n\n  Output shape:\n    4D tensor with shape:\n    `(batch_size, filters, new_rows, new_cols)` if data_format='channels_first'\n    or 4D tensor with shape:\n    `(batch_size, new_rows, new_cols, filters)` if data_format='channels_last'.\n    `rows` and `cols` values might have changed due to padding.\n\n  Returns:\n    A tensor of rank 4 representing\n    `activation(separableconv2d(inputs, kernel) + bias)`.\n\n  Raises:\n    ValueError: if `padding` is \"causal\".\n    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "filters",
        "default": null
      },
      {
        "name": "kernel_size",
        "default": null
      },
      {
        "name": "strides",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "padding",
        "default": "valid"
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "dilation_rate",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "depth_multiplier",
        "default": 1
      },
      {
        "name": "activation",
        "default": "None"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "depthwise_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "pointwise_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "depthwise_regularizer",
        "default": "None"
      },
      {
        "name": "pointwise_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "depthwise_constraint",
        "default": "None"
      },
      {
        "name": "pointwise_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": [
      "SeparableConvolution2D"
    ]
  },
  {
    "name": "SimpleRNN",
    "base": "RNN",
    "docstring": "Fully-connected RNN where the output is to be fed back to input.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  Arguments:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n      Default: hyperbolic tangent (`tanh`).\n      If you pass None, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n      used for the linear transformation of the inputs. Default:\n      `glorot_uniform`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n      weights matrix, used for the linear transformation of the recurrent state.\n      Default: `orthogonal`.\n    bias_initializer: Initializer for the bias vector. Default: `zeros`.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector. Default:\n      `None`.\n    activity_regularizer: Regularizer function applied to the output of the\n      layer (its \"activation\"). Default: `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix.  Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector. Default:\n      `None`.\n    dropout: Float between 0 and 1.\n      Fraction of the units to drop for the linear transformation of the inputs.\n      Default: 0.\n    recurrent_dropout: Float between 0 and 1.\n      Fraction of the units to drop for the linear transformation of the\n      recurrent state. Default: 0.\n    return_sequences: Boolean. Whether to return the last output\n      in the output sequence, or the full sequence. Default: `False`.\n    return_state: Boolean. Whether to return the last state\n      in addition to the output. Default: `False`\n    go_backwards: Boolean (default False).\n      If True, process the input sequence backwards and return the\n      reversed sequence.\n    stateful: Boolean (default False). If True, the last state\n      for each sample at index i in a batch will be used as initial\n      state for the sample of index i in the following batch.\n    unroll: Boolean (default False).\n      If True, the network will be unrolled,\n      else a symbolic loop will be used.\n      Unrolling can speed-up a RNN,\n      although it tends to be more memory-intensive.\n      Unrolling is only suitable for short sequences.\n\n  Call arguments:\n    inputs: A 3D tensor, with shape `[batch, timesteps, feature]`.\n    mask: Binary tensor of shape `[batch, timesteps]` indicating whether\n      a given timestep should be masked.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the cell\n      when calling it. This is only relevant if `dropout` or\n      `recurrent_dropout` is used.\n    initial_state: List of initial state tensors to be passed to the first\n      call of the cell.\n\n  Examples:\n\n  ```python\n  inputs = np.random.random([32, 10, 8]).astype(np.float32)\n  simple_rnn = tf.keras.layers.SimpleRNN(4)\n\n  output = simple_rnn(inputs)  # The output has shape `[32, 4]`.\n\n  simple_rnn = tf.keras.layers.SimpleRNN(\n      4, return_sequences=True, return_state=True)\n\n  # whole_sequence_output has shape `[32, 10, 4]`.\n  # final_state has shape `[32, 4]`.\n  whole_sequence_output, final_state = simple_rnn(inputs)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      },
      {
        "name": "return_sequences",
        "default": false
      },
      {
        "name": "return_state",
        "default": false
      },
      {
        "name": "go_backwards",
        "default": false
      },
      {
        "name": "stateful",
        "default": false
      },
      {
        "name": "unroll",
        "default": false
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "initial_state",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/recurrent.py",
    "aliases": []
  },
  {
    "name": "SimpleRNNCell",
    "base": "DropoutRNNCellMixin",
    "docstring": "Cell class for SimpleRNN.\n\n  See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\n  for details about the usage of RNN API.\n\n  This class processes one step within the whole time sequence input, whereas\n  `tf.keras.layer.SimpleRNN` processes the whole sequence.\n\n  Arguments:\n    units: Positive integer, dimensionality of the output space.\n    activation: Activation function to use.\n      Default: hyperbolic tangent (`tanh`).\n      If you pass `None`, no activation is applied\n      (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, (default `True`), whether the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n      used for the linear transformation of the inputs. Default:\n      `glorot_uniform`.\n    recurrent_initializer: Initializer for the `recurrent_kernel`\n      weights matrix, used for the linear transformation of the recurrent state.\n      Default: `orthogonal`.\n    bias_initializer: Initializer for the bias vector. Default: `zeros`.\n    kernel_regularizer: Regularizer function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_regularizer: Regularizer function applied to the\n      `recurrent_kernel` weights matrix. Default: `None`.\n    bias_regularizer: Regularizer function applied to the bias vector. Default:\n      `None`.\n    kernel_constraint: Constraint function applied to the `kernel` weights\n      matrix. Default: `None`.\n    recurrent_constraint: Constraint function applied to the `recurrent_kernel`\n      weights matrix. Default: `None`.\n    bias_constraint: Constraint function applied to the bias vector. Default:\n      `None`.\n    dropout: Float between 0 and 1. Fraction of the units to drop for the linear\n      transformation of the inputs. Default: 0.\n    recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n      the linear transformation of the recurrent state. Default: 0.\n\n  Call arguments:\n    inputs: A 2D tensor, with shape of `[batch, feature]`.\n    states: A 2D tensor with shape of `[batch, units]`, which is the state from\n      the previous time step. For timestep 0, the initial state provided by user\n      will be feed to cell.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. Only relevant when `dropout` or\n      `recurrent_dropout` is used.\n\n  Examples:\n\n  ```python\n  inputs = np.random.random([32, 10, 8]).astype(np.float32)\n  rnn = tf.keras.layers.RNN(tf.keras.layers.SimpleRNNCell(4))\n\n  output = rnn(inputs)  # The output has shape `[32, 4]`.\n\n  rnn = tf.keras.layers.RNN(\n      tf.keras.layers.SimpleRNNCell(4),\n      return_sequences=True,\n      return_state=True)\n\n  # whole_sequence_output has shape `[32, 10, 4]`.\n  # final_state has shape `[32, 4]`.\n  whole_sequence_output, final_state = rnn(inputs)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "activation",
        "default": "tanh"
      },
      {
        "name": "use_bias",
        "default": true
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "dropout",
        "default": 0.0
      },
      {
        "name": "recurrent_dropout",
        "default": 0.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "states",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/recurrent.py",
    "aliases": []
  },
  {
    "name": "Softmax",
    "base": "Layer",
    "docstring": "Softmax activation function.\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as the input.\n\n  Arguments:\n    axis: Integer, axis along which the softmax normalization is applied.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "axis",
        "default": -1
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/advanced_activations.py",
    "aliases": []
  },
  {
    "name": "SpatialDropout1D",
    "base": "Dropout",
    "docstring": "Spatial 1D version of Dropout.\n\n  This version performs the same function as Dropout, however, it drops\n  entire 1D feature maps instead of individual elements. If adjacent frames\n  within feature maps are strongly correlated (as is normally the case in\n  early convolution layers) then regular dropout will not regularize the\n  activations and will otherwise just result in an effective learning rate\n  decrease. In this case, SpatialDropout1D will help promote independence\n  between feature maps and should be used instead.\n\n  Arguments:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n\n  Call arguments:\n    inputs: A 3D tensor.\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n\n  Input shape:\n    3D tensor with shape:\n    `(samples, timesteps, channels)`\n\n  Output shape:\n    Same as input.\n\n  References:\n    - [Efficient Object Localization Using Convolutional\n      Networks](https://arxiv.org/abs/1411.4280)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "SpatialDropout2D",
    "base": "Dropout",
    "docstring": "Spatial 2D version of Dropout.\n\n  This version performs the same function as Dropout, however, it drops\n  entire 2D feature maps instead of individual elements. If adjacent pixels\n  within feature maps are strongly correlated (as is normally the case in\n  early convolution layers) then regular dropout will not regularize the\n  activations and will otherwise just result in an effective learning rate\n  decrease. In this case, SpatialDropout2D will help promote independence\n  between feature maps and should be used instead.\n\n  Arguments:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n    data_format: 'channels_first' or 'channels_last'.\n      In 'channels_first' mode, the channels dimension\n      (the depth) is at index 1,\n      in 'channels_last' mode is it at index 3.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Call arguments:\n    inputs: A 4D tensor.\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n\n  Input shape:\n    4D tensor with shape:\n    `(samples, channels, rows, cols)` if data_format='channels_first'\n    or 4D tensor with shape:\n    `(samples, rows, cols, channels)` if data_format='channels_last'.\n\n  Output shape:\n    Same as input.\n\n  References:\n    - [Efficient Object Localization Using Convolutional\n      Networks](https://arxiv.org/abs/1411.4280)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "SpatialDropout3D",
    "base": "Dropout",
    "docstring": "Spatial 3D version of Dropout.\n\n  This version performs the same function as Dropout, however, it drops\n  entire 3D feature maps instead of individual elements. If adjacent voxels\n  within feature maps are strongly correlated (as is normally the case in\n  early convolution layers) then regular dropout will not regularize the\n  activations and will otherwise just result in an effective learning rate\n  decrease. In this case, SpatialDropout3D will help promote independence\n  between feature maps and should be used instead.\n\n  Arguments:\n    rate: Float between 0 and 1. Fraction of the input units to drop.\n    data_format: 'channels_first' or 'channels_last'.\n        In 'channels_first' mode, the channels dimension (the depth)\n        is at index 1, in 'channels_last' mode is it at index 4.\n        It defaults to the `image_data_format` value found in your\n        Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\".\n\n  Call arguments:\n    inputs: A 5D tensor.\n    training: Python boolean indicating whether the layer should behave in\n      training mode (adding dropout) or in inference mode (doing nothing).\n\n  Input shape:\n    5D tensor with shape:\n    `(samples, channels, dim1, dim2, dim3)` if data_format='channels_first'\n    or 5D tensor with shape:\n    `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'.\n\n  Output shape:\n    Same as input.\n\n  References:\n    - [Efficient Object Localization Using Convolutional\n      Networks](https://arxiv.org/abs/1411.4280)\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "rate",
        "default": null
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/core.py",
    "aliases": []
  },
  {
    "name": "StackedRNNCells",
    "base": "Layer",
    "docstring": "Wrapper allowing a stack of RNN cells to behave as a single cell.\n\n  Used to implement efficient stacked RNNs.\n\n  Arguments:\n    cells: List of RNN cell instances.\n\n  Examples:\n\n  ```python\n  batch_size = 3\n  sentence_max_length = 5\n  n_features = 2\n  new_shape = (batch_size, sentence_max_length, n_features)\n  x = tf.constant(np.reshape(np.arange(30), new_shape), dtype = tf.float32)\n\n  rnn_cells = [tf.keras.layers.LSTMCell(128) for _ in range(2)]\n  stacked_lstm = tf.keras.layers.StackedRNNCells(rnn_cells)\n  lstm_layer = tf.keras.layers.RNN(stacked_lstm)\n\n  result = lstm_layer(x)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "cells",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "states",
        "default": null
      },
      {
        "name": "constants",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/recurrent.py",
    "aliases": []
  },
  {
    "name": "Subtract",
    "base": "_Merge",
    "docstring": "Layer that subtracts two inputs.\n\n  It takes as input a list of tensors of size 2,\n  both of the same shape, and returns a single tensor, (inputs[0] - inputs[1]),\n  also of the same shape.\n\n  Examples:\n\n  ```python\n      import keras\n\n      input1 = keras.layers.Input(shape=(16,))\n      x1 = keras.layers.Dense(8, activation='relu')(input1)\n      input2 = keras.layers.Input(shape=(32,))\n      x2 = keras.layers.Dense(8, activation='relu')(input2)\n      # Equivalent to subtracted = keras.layers.subtract([x1, x2])\n      subtracted = keras.layers.Subtract()([x1, x2])\n\n      out = keras.layers.Dense(4)(subtracted)\n      model = keras.models.Model(inputs=[input1, input2], outputs=out)\n  ```\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/merge.py",
    "aliases": []
  },
  {
    "name": "ThresholdedReLU",
    "base": "Layer",
    "docstring": "Thresholded Rectified Linear Unit.\n\n  It follows:\n\n  ```\n    f(x) = x for x > theta\n    f(x) = 0 otherwise`\n  ```\n\n  Input shape:\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers, does not include the samples axis)\n    when using this layer as the first layer in a model.\n\n  Output shape:\n    Same shape as the input.\n\n  Arguments:\n    theta: Float >= 0. Threshold location of activation.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "theta",
        "default": 1.0
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/advanced_activations.py",
    "aliases": []
  },
  {
    "name": "TimeDistributed",
    "base": "Wrapper",
    "docstring": "This wrapper allows to apply a layer to every temporal slice of an input.\n\n  The input should be at least 3D, and the dimension of index one\n  will be considered to be the temporal dimension.\n\n  Consider a batch of 32 video samples, where each sample is a 128x128 RGB image\n  with `channels_last` data format, across 10 timesteps.\n  The batch input shape is `(32, 10, 128, 128, 3)`.\n\n  You can then use `TimeDistributed` to apply a `Conv2D` layer to each of the\n  10 timesteps, independently:\n\n  >>> inputs = tf.keras.Input(shape=(10, 128, 128, 3))\n  >>> conv_2d_layer = tf.keras.layers.Conv2D(64, (3, 3))\n  >>> outputs = tf.keras.layers.TimeDistributed(conv_2d_layer)(inputs)\n  >>> outputs.shape\n  TensorShape([None, 10, 126, 126, 64])\n\n  Arguments:\n    layer: a `tf.keras.layers.Layer` instance.\n\n  Call arguments:\n    inputs: Input tensor.\n    training: Python boolean indicating whether the layer should behave in\n      training mode or in inference mode. This argument is passed to the\n      wrapped layer (only if the layer supports this argument).\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether\n      a given timestep should be masked. This argument is passed to the\n      wrapped layer (only if the layer supports this argument).\n\n  Raises:\n    ValueError: If not initialized with a `tf.keras.layers.Layer` instance.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "layer",
        "default": null
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "mask",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/wrappers.py",
    "aliases": []
  },
  {
    "name": "UpSampling1D",
    "base": "Layer",
    "docstring": "Upsampling layer for 1D inputs.\n\n  Repeats each temporal step `size` times along the time axis.\n\n  Examples:\n\n  >>> input_shape = (2, 2, 3)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> print(x)\n  [[[ 0  1  2]\n    [ 3  4  5]]\n   [[ 6  7  8]\n    [ 9 10 11]]]\n  >>> y = tf.keras.layers.UpSampling1D(size=2)(x)\n  >>> print(y)\n  tf.Tensor(\n    [[[ 0  1  2]\n      [ 0  1  2]\n      [ 3  4  5]\n      [ 3  4  5]]\n     [[ 6  7  8]\n      [ 6  7  8]\n      [ 9 10 11]\n      [ 9 10 11]]], shape=(2, 4, 3), dtype=int64)\n\n  Arguments:\n    size: Integer. Upsampling factor.\n\n  Input shape:\n    3D tensor with shape: `(batch_size, steps, features)`.\n\n  Output shape:\n    3D tensor with shape: `(batch_size, upsampled_steps, features)`.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "size",
        "default": 2
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "UpSampling2D",
    "base": "Layer",
    "docstring": "Upsampling layer for 2D inputs.\n\n  Repeats the rows and columns of the data\n  by `size[0]` and `size[1]` respectively.\n\n  Examples:\n\n  >>> input_shape = (2, 2, 1, 3)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> print(x)\n  [[[[ 0  1  2]]\n    [[ 3  4  5]]]\n   [[[ 6  7  8]]\n    [[ 9 10 11]]]]\n  >>> y = tf.keras.layers.UpSampling2D(size=(1, 2))(x)\n  >>> print(y)\n  tf.Tensor(\n    [[[[ 0  1  2]\n       [ 0  1  2]]\n      [[ 3  4  5]\n       [ 3  4  5]]]\n     [[[ 6  7  8]\n       [ 6  7  8]]\n      [[ 9 10 11]\n       [ 9 10 11]]]], shape=(2, 2, 2, 3), dtype=int64)\n\n  Arguments:\n    size: Int, or tuple of 2 integers.\n      The upsampling factors for rows and columns.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n    interpolation: A string, one of `nearest` or `bilinear`.\n\n  Input shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, rows, cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, rows, cols)`\n\n  Output shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, upsampled_rows, upsampled_cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, upsampled_rows, upsampled_cols)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "size",
        "default": [
          2,
          2
        ]
      },
      {
        "name": "data_format",
        "default": "None"
      },
      {
        "name": "interpolation",
        "default": "nearest"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "UpSampling3D",
    "base": "Layer",
    "docstring": "Upsampling layer for 3D inputs.\n\n  Repeats the 1st, 2nd and 3rd dimensions\n  of the data by `size[0]`, `size[1]` and `size[2]` respectively.\n\n  Examples:\n\n  >>> input_shape = (2, 1, 2, 1, 3)\n  >>> x = tf.constant(1, shape=input_shape)\n  >>> y = tf.keras.layers.UpSampling3D(size=2)(x)\n  >>> print(y.shape)\n  (2, 2, 4, 2, 3)\n\n  Arguments:\n    size: Int, or tuple of 3 integers.\n      The upsampling factors for dim1, dim2 and dim3.\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, dim1, dim2, dim3, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, dim1, dim2, dim3)`\n\n  Output shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "size",
        "default": [
          2,
          2,
          2
        ]
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "Wrapper",
    "base": "Layer",
    "docstring": "Abstract wrapper base class.\n\n  Wrappers take another layer and augment it in various ways.\n  Do not use this class as a layer, it is only an abstract base class.\n  Two usable wrappers are the `TimeDistributed` and `Bidirectional` wrappers.\n\n  Arguments:\n    layer: The layer to be wrapped.\n  ",
    "arguments": null,
    "abstract": true,
    "outputs": [],
    "inputs": null,
    "file": "tensorflow/python/keras/layers/wrappers.py",
    "aliases": []
  },
  {
    "name": "ZeroPadding1D",
    "base": "Layer",
    "docstring": "Zero-padding layer for 1D input (e.g. temporal sequence).\n\n  Examples:\n\n  >>> input_shape = (2, 2, 3)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> print(x)\n  [[[ 0  1  2]\n    [ 3  4  5]]\n   [[ 6  7  8]\n    [ 9 10 11]]]\n  >>> y = tf.keras.layers.ZeroPadding1D(padding=2)(x)\n  >>> print(y)\n  tf.Tensor(\n    [[[ 0  0  0]\n      [ 0  0  0]\n      [ 0  1  2]\n      [ 3  4  5]\n      [ 0  0  0]\n      [ 0  0  0]]\n     [[ 0  0  0]\n      [ 0  0  0]\n      [ 6  7  8]\n      [ 9 10 11]\n      [ 0  0  0]\n      [ 0  0  0]]], shape=(2, 6, 3), dtype=int64)\n\n  Arguments:\n      padding: Int, or tuple of int (length 2), or dictionary.\n          - If int:\n          How many zeros to add at the beginning and end of\n          the padding dimension (axis 1).\n          - If tuple of int (length 2):\n          How many zeros to add at the beginning and the end of\n          the padding dimension (`(left_pad, right_pad)`).\n\n  Input shape:\n      3D tensor with shape `(batch_size, axis_to_pad, features)`\n\n  Output shape:\n      3D tensor with shape `(batch_size, padded_axis, features)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "padding",
        "default": 1
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "ZeroPadding2D",
    "base": "Layer",
    "docstring": "Zero-padding layer for 2D input (e.g. picture).\n\n  This layer can add rows and columns of zeros\n  at the top, bottom, left and right side of an image tensor.\n\n  Examples:\n\n  >>> input_shape = (1, 1, 2, 2)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> print(x)\n  [[[[0 1]\n     [2 3]]]]\n  >>> y = tf.keras.layers.ZeroPadding2D(padding=1)(x)\n  >>> print(y)\n  tf.Tensor(\n    [[[[0 0]\n       [0 0]\n       [0 0]\n       [0 0]]\n      [[0 0]\n       [0 1]\n       [2 3]\n       [0 0]]\n      [[0 0]\n       [0 0]\n       [0 0]\n       [0 0]]]], shape=(1, 3, 4, 2), dtype=int64)\n\n  Arguments:\n    padding: Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n      - If int: the same symmetric padding\n        is applied to height and width.\n      - If tuple of 2 ints:\n        interpreted as two different\n        symmetric padding values for height and width:\n        `(symmetric_height_pad, symmetric_width_pad)`.\n      - If tuple of 2 tuples of 2 ints:\n        interpreted as\n        `((top_pad, bottom_pad), (left_pad, right_pad))`\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch_size, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, rows, cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, rows, cols)`\n\n  Output shape:\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, padded_rows, padded_cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, channels, padded_rows, padded_cols)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "padding",
        "default": [
          1,
          1
        ]
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "ZeroPadding3D",
    "base": "Layer",
    "docstring": "Zero-padding layer for 3D data (spatial or spatio-temporal).\n\n  Examples:\n\n  >>> input_shape = (1, 1, 2, 2, 3)\n  >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n  >>> y = tf.keras.layers.ZeroPadding3D(padding=2)(x)\n  >>> print(y.shape)\n  (1, 5, 6, 6, 3)\n\n  Arguments:\n    padding: Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n      - If int: the same symmetric padding\n        is applied to height and width.\n      - If tuple of 3 ints:\n        interpreted as two different\n        symmetric padding values for height and width:\n        `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)`.\n      - If tuple of 3 tuples of 2 ints:\n        interpreted as\n        `((left_dim1_pad, right_dim1_pad), (left_dim2_pad,\n          right_dim2_pad), (left_dim3_pad, right_dim3_pad))`\n    data_format: A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n      while `channels_first` corresponds to inputs with shape\n      `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".\n\n  Input shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad,\n          depth)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, depth, first_axis_to_pad, second_axis_to_pad,\n          third_axis_to_pad)`\n\n  Output shape:\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch_size, first_padded_axis, second_padded_axis, third_axis_to_pad,\n          depth)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch_size, depth, first_padded_axis, second_padded_axis,\n          third_axis_to_pad)`\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "padding",
        "default": [
          1,
          1,
          1
        ]
      },
      {
        "name": "data_format",
        "default": "None"
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      }
    ],
    "file": "tensorflow/python/keras/layers/convolutional.py",
    "aliases": []
  },
  {
    "name": "CuDNNGRU",
    "base": "_CuDNNRNN",
    "docstring": "Fast GRU implementation backed by cuDNN.\n\n  More information about cuDNN can be found on the [NVIDIA\n  developer website](https://developer.nvidia.com/cudnn).\n  Can only be run on GPU.\n\n  Arguments:\n      units: Positive integer, dimensionality of the output space.\n      kernel_initializer: Initializer for the `kernel` weights matrix, used for\n        the linear transformation of the inputs.\n      recurrent_initializer: Initializer for the `recurrent_kernel` weights\n        matrix, used for the linear transformation of the recurrent state.\n      bias_initializer: Initializer for the bias vector.\n      kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix.\n      recurrent_regularizer: Regularizer function applied to the\n        `recurrent_kernel` weights matrix.\n      bias_regularizer: Regularizer function applied to the bias vector.\n      activity_regularizer: Regularizer function applied to the output of the\n        layer (its \"activation\").\n      kernel_constraint: Constraint function applied to the `kernel` weights\n        matrix.\n      recurrent_constraint: Constraint function applied to the\n        `recurrent_kernel` weights matrix.\n      bias_constraint: Constraint function applied to the bias vector.\n      return_sequences: Boolean. Whether to return the last output in the output\n        sequence, or the full sequence.\n      return_state: Boolean. Whether to return the last state in addition to the\n        output.\n      go_backwards: Boolean (default False). If True, process the input sequence\n        backwards and return the reversed sequence.\n      stateful: Boolean (default False). If True, the last state for each sample\n        at index i in a batch will be used as initial state for the sample of\n        index i in the following batch.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "return_sequences",
        "default": false
      },
      {
        "name": "return_state",
        "default": false
      },
      {
        "name": "go_backwards",
        "default": false
      },
      {
        "name": "stateful",
        "default": false
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "initial_state",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/cudnn_recurrent.py",
    "aliases": []
  },
  {
    "name": "CuDNNLSTM",
    "base": "_CuDNNRNN",
    "docstring": "Fast LSTM implementation backed by cuDNN.\n\n  More information about cuDNN can be found on the [NVIDIA\n  developer website](https://developer.nvidia.com/cudnn).\n  Can only be run on GPU.\n\n  Arguments:\n      units: Positive integer, dimensionality of the output space.\n      kernel_initializer: Initializer for the `kernel` weights matrix, used for\n        the linear transformation of the inputs.\n      unit_forget_bias: Boolean. If True, add 1 to the bias of the forget gate\n        at initialization. Setting it to true will also force\n        `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et\n        al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n      recurrent_initializer: Initializer for the `recurrent_kernel` weights\n        matrix, used for the linear transformation of the recurrent state.\n      bias_initializer: Initializer for the bias vector.\n      kernel_regularizer: Regularizer function applied to the `kernel` weights\n        matrix.\n      recurrent_regularizer: Regularizer function applied to the\n        `recurrent_kernel` weights matrix.\n      bias_regularizer: Regularizer function applied to the bias vector.\n      activity_regularizer: Regularizer function applied to the output of the\n        layer (its \"activation\").\n      kernel_constraint: Constraint function applied to the `kernel` weights\n        matrix.\n      recurrent_constraint: Constraint function applied to the\n        `recurrent_kernel` weights matrix.\n      bias_constraint: Constraint function applied to the bias vector.\n      return_sequences: Boolean. Whether to return the last output. in the\n        output sequence, or the full sequence.\n      return_state: Boolean. Whether to return the last state in addition to the\n        output.\n      go_backwards: Boolean (default False). If True, process the input sequence\n        backwards and return the reversed sequence.\n      stateful: Boolean (default False). If True, the last state for each sample\n        at index i in a batch will be used as initial state for the sample of\n        index i in the following batch.\n  ",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "units",
        "default": null
      },
      {
        "name": "kernel_initializer",
        "default": "glorot_uniform"
      },
      {
        "name": "recurrent_initializer",
        "default": "orthogonal"
      },
      {
        "name": "bias_initializer",
        "default": "zeros"
      },
      {
        "name": "unit_forget_bias",
        "default": true
      },
      {
        "name": "kernel_regularizer",
        "default": "None"
      },
      {
        "name": "recurrent_regularizer",
        "default": "None"
      },
      {
        "name": "bias_regularizer",
        "default": "None"
      },
      {
        "name": "activity_regularizer",
        "default": "None"
      },
      {
        "name": "kernel_constraint",
        "default": "None"
      },
      {
        "name": "recurrent_constraint",
        "default": "None"
      },
      {
        "name": "bias_constraint",
        "default": "None"
      },
      {
        "name": "return_sequences",
        "default": false
      },
      {
        "name": "return_state",
        "default": false
      },
      {
        "name": "go_backwards",
        "default": false
      },
      {
        "name": "stateful",
        "default": false
      }
    ],
    "abstract": false,
    "outputs": [],
    "inputs": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "inputs",
        "default": null
      },
      {
        "name": "mask",
        "default": "None"
      },
      {
        "name": "training",
        "default": "None"
      },
      {
        "name": "initial_state",
        "default": "None"
      }
    ],
    "file": "tensorflow/python/keras/layers/cudnn_recurrent.py",
    "aliases": []
  },
  {
    "name": "_CuDNNRNN",
    "base": "RNN",
    "docstring": "Private base class for CuDNNGRU and CuDNNLSTM layers.\n\n  Arguments:\n    return_sequences: Boolean. Whether to return the last output\n        in the output sequence, or the full sequence.\n    return_state: Boolean. Whether to return the last state\n        in addition to the output.\n    go_backwards: Boolean (default False).\n        If True, process the input sequence backwards and return the\n        reversed sequence.\n    stateful: Boolean (default False). If True, the last state\n        for each sample at index i in a batch will be used as initial\n        state for the sample of index i in the following batch.\n    time_major: Boolean (default False). If true, the inputs and outputs will be\n        in shape `(timesteps, batch, ...)`, whereas in the False case, it will\n        be `(batch, timesteps, ...)`.\n  ",
    "arguments": null,
    "abstract": true,
    "outputs": [],
    "inputs": null,
    "file": "tensorflow/python/keras/layers/cudnn_recurrent.py",
    "aliases": []
  }
]