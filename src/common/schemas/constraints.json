[
  {
    "name": "MaxNorm",
    "base": "Constraint",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "max_value",
        "default": 2
      },
      {
        "name": "axis",
        "default": 0
      }
    ],
    "abstract": false,
    "aliases": [
      "max_norm"
    ],
    "docstring": "MaxNorm weight constraint.\n\n    Constrains the weights incident to each hidden unit\n    to have a norm less than or equal to a desired value.\n\n    # Arguments\n        m: the maximum norm for the incoming weights.\n        axis: integer, axis along which to calculate weight norms.\n            For instance, in a `Dense` layer the weight matrix\n            has shape `(input_dim, output_dim)`,\n            set `axis` to `0` to constrain each weight vector\n            of length `(input_dim,)`.\n            In a `Conv2D` layer with `data_format=\"channels_last\"`,\n            the weight tensor has shape\n            `(rows, cols, input_depth, output_depth)`,\n            set `axis` to `[0, 1, 2]`\n            to constrain the weights of each filter tensor of size\n            `(rows, cols, input_depth)`.\n\n    # References\n        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n    ",
    "file": "keras/constraints.py"
  },
  {
    "name": "NonNeg",
    "base": "Constraint",
    "arguments": [],
    "abstract": false,
    "aliases": [
      "non_neg"
    ],
    "docstring": "Constrains the weights to be non-negative.\n    ",
    "file": "keras/constraints.py"
  },
  {
    "name": "UnitNorm",
    "base": "Constraint",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "axis",
        "default": 0
      }
    ],
    "abstract": false,
    "aliases": [
      "unit_norm"
    ],
    "docstring": "Constrains the weights incident to each hidden unit to have unit norm.\n\n    # Arguments\n        axis: integer, axis along which to calculate weight norms.\n            For instance, in a `Dense` layer the weight matrix\n            has shape `(input_dim, output_dim)`,\n            set `axis` to `0` to constrain each weight vector\n            of length `(input_dim,)`.\n            In a `Conv2D` layer with `data_format=\"channels_last\"`,\n            the weight tensor has shape\n            `(rows, cols, input_depth, output_depth)`,\n            set `axis` to `[0, 1, 2]`\n            to constrain the weights of each filter tensor of size\n            `(rows, cols, input_depth)`.\n    ",
    "file": "keras/constraints.py"
  },
  {
    "name": "MinMaxNorm",
    "base": "Constraint",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "min_value",
        "default": 0
      },
      {
        "name": "max_value",
        "default": 1
      },
      {
        "name": "rate",
        "default": 1
      },
      {
        "name": "axis",
        "default": 0
      }
    ],
    "abstract": false,
    "aliases": [
      "min_max_norm"
    ],
    "docstring": "MinMaxNorm weight constraint.\n\n    Constrains the weights incident to each hidden unit\n    to have the norm between a lower bound and an upper bound.\n\n    # Arguments\n        min_value: the minimum norm for the incoming weights.\n        max_value: the maximum norm for the incoming weights.\n        rate: rate for enforcing the constraint: weights will be\n            rescaled to yield\n            `(1 - rate) * norm + rate * norm.clip(min_value, max_value)`.\n            Effectively, this means that rate=1.0 stands for strict\n            enforcement of the constraint, while rate<1.0 means that\n            weights will be rescaled at each step to slowly move\n            towards a value inside the desired interval.\n        axis: integer, axis along which to calculate weight norms.\n            For instance, in a `Dense` layer the weight matrix\n            has shape `(input_dim, output_dim)`,\n            set `axis` to `0` to constrain each weight vector\n            of length `(input_dim,)`.\n            In a `Conv2D` layer with `data_format=\"channels_last\"`,\n            the weight tensor has shape\n            `(rows, cols, input_depth, output_depth)`,\n            set `axis` to `[0, 1, 2]`\n            to constrain the weights of each filter tensor of size\n            `(rows, cols, input_depth)`.\n    ",
    "file": "keras/constraints.py"
  }
]