[
  {
    "name": "Zeros",
    "base": "Initializer",
    "arguments": null,
    "inputs": null,
    "outputs": null,
    "abstract": false,
    "aliases": [
      "zero",
      "zeros"
    ],
    "docstring": "Initializer that generates tensors initialized to 0.\n    ",
    "file": "keras/initializers.py"
  },
  {
    "name": "Ones",
    "base": "Initializer",
    "arguments": null,
    "inputs": null,
    "outputs": null,
    "abstract": false,
    "aliases": [
      "one",
      "ones"
    ],
    "docstring": "Initializer that generates tensors initialized to 1.\n    ",
    "file": "keras/initializers.py"
  },
  {
    "name": "Constant",
    "base": "Initializer",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "value",
        "default": 0
      }
    ],
    "inputs": null,
    "outputs": null,
    "abstract": false,
    "aliases": [
      "constant"
    ],
    "docstring": "Initializer that generates tensors initialized to a constant value.\n\n    # Arguments\n        value: float; the value of the generator tensors.\n    ",
    "file": "keras/initializers.py"
  },
  {
    "name": "RandomNormal",
    "base": "Initializer",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "mean",
        "default": 0
      },
      {
        "name": "stddev",
        "default": 0.05
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "inputs": null,
    "outputs": null,
    "abstract": false,
    "aliases": [
      "normal",
      "random_normal"
    ],
    "docstring": "Initializer that generates tensors with a normal distribution.\n\n    # Arguments\n        mean: a python scalar or a scalar tensor. Mean of the random values\n          to generate.\n        stddev: a python scalar or a scalar tensor. Standard deviation of the\n          random values to generate.\n        seed: A Python integer. Used to seed the random generator.\n    ",
    "file": "keras/initializers.py"
  },
  {
    "name": "RandomUniform",
    "base": "Initializer",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "minval",
        "default": -0.05
      },
      {
        "name": "maxval",
        "default": 0.05
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "inputs": null,
    "outputs": null,
    "abstract": false,
    "aliases": [
      "uniform",
      "random_uniform"
    ],
    "docstring": "Initializer that generates tensors with a uniform distribution.\n\n    # Arguments\n        minval: A python scalar or a scalar tensor. Lower bound of the range\n          of random values to generate.\n        maxval: A python scalar or a scalar tensor. Upper bound of the range\n          of random values to generate.  Defaults to 1 for float types.\n        seed: A Python integer. Used to seed the random generator.\n    ",
    "file": "keras/initializers.py"
  },
  {
    "name": "TruncatedNormal",
    "base": "Initializer",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "mean",
        "default": 0
      },
      {
        "name": "stddev",
        "default": 0.05
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "inputs": null,
    "outputs": null,
    "abstract": false,
    "aliases": [
      "truncated_normal"
    ],
    "docstring": "Initializer that generates a truncated normal distribution.\n\n    These values are similar to values from a `RandomNormal`\n    except that values more than two standard deviations from the mean\n    are discarded and re-drawn. This is the recommended initializer for\n    neural network weights and filters.\n\n    # Arguments\n        mean: a python scalar or a scalar tensor. Mean of the random values\n          to generate.\n        stddev: a python scalar or a scalar tensor. Standard deviation of the\n          random values to generate.\n        seed: A Python integer. Used to seed the random generator.\n    ",
    "file": "keras/initializers.py"
  },
  {
    "name": "VarianceScaling",
    "base": "Initializer",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "scale",
        "default": 1
      },
      {
        "name": "mode",
        "default": "fan_in"
      },
      {
        "name": "distribution",
        "default": "normal"
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "inputs": null,
    "outputs": null,
    "abstract": false,
    "aliases": [],
    "docstring": "Initializer capable of adapting its scale to the shape of weights.\n\n    With `distribution=\"normal\"`, samples are drawn from a truncated normal\n    distribution centered on zero, with `stddev = sqrt(scale / n)` where n is:\n\n        - number of input units in the weight tensor, if mode = \"fan_in\"\n        - number of output units, if mode = \"fan_out\"\n        - average of the numbers of input and output units, if mode = \"fan_avg\"\n\n    With `distribution=\"uniform\"`,\n    samples are drawn from a uniform distribution\n    within [-limit, limit], with `limit = sqrt(3 * scale / n)`.\n\n    # Arguments\n        scale: Scaling factor (positive float).\n        mode: One of \"fan_in\", \"fan_out\", \"fan_avg\".\n        distribution: Random distribution to use. One of \"normal\", \"uniform\".\n        seed: A Python integer. Used to seed the random generator.\n\n    # Raises\n        ValueError: In case of an invalid value for the \"scale\", mode\" or\n          \"distribution\" arguments.\n    ",
    "file": "keras/initializers.py"
  },
  {
    "name": "Orthogonal",
    "base": "Initializer",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "gain",
        "default": 1
      },
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "inputs": null,
    "outputs": null,
    "abstract": false,
    "aliases": [
      "orthogonal"
    ],
    "docstring": "Initializer that generates a random orthogonal matrix.\n\n    # Arguments\n        gain: Multiplicative factor to apply to the orthogonal matrix.\n        seed: A Python integer. Used to seed the random generator.\n\n    # References\n        Saxe et al., http://arxiv.org/abs/1312.6120\n    ",
    "file": "keras/initializers.py"
  },
  {
    "name": "Identity",
    "base": "Initializer",
    "arguments": [
      {
        "name": "self",
        "default": null
      },
      {
        "name": "gain",
        "default": 1
      }
    ],
    "inputs": null,
    "outputs": null,
    "abstract": false,
    "aliases": [
      "identity"
    ],
    "docstring": "Initializer that generates the identity matrix.\n\n    Only use for square 2D matrices.\n\n    # Arguments\n        gain: Multiplicative factor to apply to the identity matrix.\n    ",
    "file": "keras/initializers.py"
  },
  {
    "name": "lecun_uniform",
    "arguments": [
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "docstring": "LeCun uniform initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(3 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        LeCun 98, Efficient Backprop,\n        http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf\n    ",
    "aliases": [],
    "file": "keras/initializers.py"
  },
  {
    "name": "glorot_normal",
    "arguments": [
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "docstring": "Glorot normal initializer, also called Xavier normal initializer.\n\n    It draws samples from a truncated normal distribution centered on 0\n    with `stddev = sqrt(2 / (fan_in + fan_out))`\n    where `fan_in` is the number of input units in the weight tensor\n    and `fan_out` is the number of output units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        Glorot & Bengio, AISTATS 2010\n        http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf\n    ",
    "aliases": [],
    "file": "keras/initializers.py"
  },
  {
    "name": "glorot_uniform",
    "arguments": [
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "docstring": "Glorot uniform initializer, also called Xavier uniform initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(6 / (fan_in + fan_out))`\n    where `fan_in` is the number of input units in the weight tensor\n    and `fan_out` is the number of output units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        Glorot & Bengio, AISTATS 2010\n        http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf\n    ",
    "aliases": [],
    "file": "keras/initializers.py"
  },
  {
    "name": "he_normal",
    "arguments": [
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "docstring": "He normal initializer.\n\n    It draws samples from a truncated normal distribution centered on 0\n    with `stddev = sqrt(2 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        He et al., http://arxiv.org/abs/1502.01852\n    ",
    "aliases": [],
    "file": "keras/initializers.py"
  },
  {
    "name": "lecun_normal",
    "arguments": [
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "docstring": "LeCun normal initializer.\n\n    It draws samples from a truncated normal distribution centered on 0\n    with `stddev = sqrt(1 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n        - [Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n    ",
    "aliases": [],
    "file": "keras/initializers.py"
  },
  {
    "name": "he_uniform",
    "arguments": [
      {
        "name": "seed",
        "default": "None"
      }
    ],
    "docstring": "He uniform variance scaling initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(6 / fan_in)`\n    where `fan_in` is the number of input units in the weight tensor.\n\n    # Arguments\n        seed: A Python integer. Used to seed the random generator.\n\n    # Returns\n        An initializer.\n\n    # References\n        He et al., http://arxiv.org/abs/1502.01852\n    ",
    "aliases": [],
    "file": "keras/initializers.py"
  }
]